

<!DOCTYPE html>
<html class="writer-html5" lang="Chinese" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tensorflow.python.ops.ragged.ragged_tensor &mdash; tensorflow 0.1.3 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/graphviz.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../../../../_static/GCC.png"/>
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
        <script src="../../../../../_static/language_data.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #343131" >
          

          
            <a href="../../../../../index.html" class="icon icon-home" alt="Documentation Home"> tensorflow
          

          
            
            <img src="../../../../../_static/GCC.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.1.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">从TensorFlow开始 (Getting Started)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../01_Introduction/index.html">TensorFlow如何工作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../01_Introduction/index.html#id1">变量和张量的声明</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../01_Introduction/index.html#id2">使用占位符和变量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../01_Introduction/index.html#id3">矩阵</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../01_Introduction/index.html#id4">操作符的声明</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../01_Introduction/index.html#id5">载入激活函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../01_Introduction/index.html#id6">数据资源</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../01_Introduction/index.html#id7">资源库</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../01_Introduction/index.html#id8">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">TensorFlow方式 (TensorFlow Way)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../02_TensorFlow_Way/index.html">计算图</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../02_TensorFlow_Way/index.html#id2">分层嵌套操作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../02_TensorFlow_Way/index.html#id3">多层操作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../02_TensorFlow_Way/index.html#id4">载入损失函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../02_TensorFlow_Way/index.html#id5">载入反向传播</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../02_TensorFlow_Way/index.html#id6">随机和批量训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../02_TensorFlow_Way/index.html#id7">结合训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../02_TensorFlow_Way/index.html#id8">模型评估</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../02_TensorFlow_Way/index.html#id9">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">线性回归 (Linear Regression)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../03_Linear_Regression/index.html">矩阵转置</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../03_Linear_Regression/index.html#id2">矩阵分解法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../03_Linear_Regression/index.html#tensorflow">TensorFLow的线性回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../03_Linear_Regression/index.html#id3">线性回归的损失函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../03_Linear_Regression/index.html#deming">Deming回归(全回归)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../03_Linear_Regression/index.html#lasso-ridge">套索(Lasso)回归和岭(Ridge)回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../03_Linear_Regression/index.html#elastic-net">弹性网(Elastic Net)回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../03_Linear_Regression/index.html#logistic">逻辑(Logistic)回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../03_Linear_Regression/index.html#id4">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">支持向量机(Support Vector Machines)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../04_Support_Vector_Machines/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../04_Support_Vector_Machines/index.html#id2">线性支持向量机</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../04_Support_Vector_Machines/index.html#id3">回归线性回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../04_Support_Vector_Machines/index.html#tensorflow">TensorFlow中的核</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../04_Support_Vector_Machines/index.html#id4">非线性支持向量机</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../04_Support_Vector_Machines/index.html#id5">多类支持向量机</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../04_Support_Vector_Machines/index.html#id6">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">最近邻法 (Nearest Neighbor Methods)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../05_Nearest_Neighbor_Methods/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../05_Nearest_Neighbor_Methods/index.html#id2">最近邻法的使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../05_Nearest_Neighbor_Methods/index.html#id3">文本距离函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../05_Nearest_Neighbor_Methods/index.html#id4">计算混合距离函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../05_Nearest_Neighbor_Methods/index.html#id5">地址匹配</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../05_Nearest_Neighbor_Methods/index.html#id6">图像处理的近邻法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../05_Nearest_Neighbor_Methods/index.html#id7">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">神经元网络 (Neural Networks)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../06_Neural_Networks/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../06_Neural_Networks/index.html#id2">载入操作门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../06_Neural_Networks/index.html#id3">门运算和激活函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../06_Neural_Networks/index.html#id4">载入一层神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../06_Neural_Networks/index.html#id5">载入多层神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../06_Neural_Networks/index.html#id6">使用多层神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../06_Neural_Networks/index.html#id7">线性模型预测改善</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../06_Neural_Networks/index.html#id8">神经网络学习井字棋</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../06_Neural_Networks/index.html#id9">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">自然语言处理(NLP)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../07_Natural_Language_Processing/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../07_Natural_Language_Processing/index.html#bag-of-words">词袋 (Bag of Words)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../07_Natural_Language_Processing/index.html#tf-idf">词频-逆文本频率 (TF-IDF)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../07_Natural_Language_Processing/index.html#skip-gram">运用Skip-Gram</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../07_Natural_Language_Processing/index.html#cbow-continuous-bag-fo-words">CBOW (Continuous Bag fo Words)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../07_Natural_Language_Processing/index.html#word2vec">Word2Vec应用实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../07_Natural_Language_Processing/index.html#doc2vec-sentiment-analysis">Doc2Vec情感分析 (Sentiment Analysis)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../07_Natural_Language_Processing/index.html#id2">神经网络学习井字棋</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../07_Natural_Language_Processing/index.html#id3">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">卷积神经网络(CNN)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../08_Convolutional_Neural_Networks/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../08_Convolutional_Neural_Networks/index.html#simple-cnns">简单卷积神经网络 (Simple CNNs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../08_Convolutional_Neural_Networks/index.html#advanced-cnns">高级卷积神经网络 (Advanced CNNs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../08_Convolutional_Neural_Networks/index.html#id2">重新训练一个存在架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../08_Convolutional_Neural_Networks/index.html#stylenet-neural-style">使用Stylenet/Neural-Style</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../08_Convolutional_Neural_Networks/index.html#deep-dream">运用Deep Dream</a></li>
</ul>
<p class="caption"><span class="caption-text">递归神经网络(RNN)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../09_Recurrent_Neural_Networks/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../09_Recurrent_Neural_Networks/index.html#id2">卷积神经网络模型用于垃圾信息检测</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../09_Recurrent_Neural_Networks/index.html#lstm">LSTM模型用于文本生成</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../09_Recurrent_Neural_Networks/index.html#id3">堆叠多层LSTM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../09_Recurrent_Neural_Networks/index.html#seq2seq">创建段对段模型翻译 (Seq2Seq)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../09_Recurrent_Neural_Networks/index.html#siamese">训练Siamese相似度测量</a></li>
</ul>
<p class="caption"><span class="caption-text">TensorFlow的应用技巧</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../10_Taking_TensorFlow_to_Production/index.html">单元测试</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../10_Taking_TensorFlow_to_Production/index.html#id2">使用多个执行器 (设备)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../10_Taking_TensorFlow_to_Production/index.html#tensorflow">TensorFlow平行化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../10_Taking_TensorFlow_to_Production/index.html#id3">TensorFlow开发贴士</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../10_Taking_TensorFlow_to_Production/index.html#id4">TensorFlow开发实例</a></li>
</ul>
<p class="caption"><span class="caption-text">TensorFlow的更多功能</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../11_More_with_TensorFlow/index.html">计算图可视化(用Tensorboard)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../11_More_with_TensorFlow/index.html#id1">遗传算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../11_More_with_TensorFlow/index.html#k-means">K-means聚类分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../11_More_with_TensorFlow/index.html#id2">解决体系常微分方程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../11_More_with_TensorFlow/index.html#id3">随机森林</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../11_More_with_TensorFlow/index.html#tensorflowkeras">TensorFlow中的Keras</a></li>
</ul>
<p class="caption"><span class="caption-text">TF Cookbook</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../bookindex.html">书籍介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../bookindex.html#id2">第一章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../bookindex.html#id3">第二章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../bookindex.html#id4">第三章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../bookindex.html#id5">第四章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../bookindex.html#id6">第五章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../bookindex.html#id7">第六章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../bookindex.html#id8">第七章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../bookindex.html#id9">第八章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../bookindex.html#id10">第九章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../bookindex.html#id11">第十章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../bookindex.html#id12">第十一章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../bookindex.html#id13">索引</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">tensorflow</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../../index.html">Module code</a> &raquo;</li>
        
      <li>tensorflow.python.ops.ragged.ragged_tensor</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for tensorflow.python.ops.ragged.ragged_tensor</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2018 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;Classes for storing ragged tensors and their values.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">operator</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">tensorflow.python</span> <span class="k">import</span> <span class="n">tf2</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.client</span> <span class="k">import</span> <span class="n">session</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">composite_tensor</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">constant_op</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">dtypes</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">sparse_tensor</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">tensor_shape</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">tensor_spec</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">tensor_util</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">type_spec</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">array_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">check_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">control_flow_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">gen_ragged_conversion_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">math_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops.ragged</span> <span class="k">import</span> <span class="n">ragged_config</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops.ragged</span> <span class="k">import</span> <span class="n">ragged_tensor_value</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops.ragged</span> <span class="k">import</span> <span class="n">ragged_util</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops.ragged</span> <span class="k">import</span> <span class="n">segment_id_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util.tf_export</span> <span class="k">import</span> <span class="n">tf_export</span>

<span class="c1"># pylint: disable=protected-access</span>
<span class="n">_eval_using_default_session</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">_eval_using_default_session</span>
<span class="c1"># pylint: enable=protected-access</span>

<span class="c1">#===============================================================================</span>
<span class="c1"># RaggedTensor</span>
<span class="c1">#===============================================================================</span>


<div class="viewcode-block" id="RaggedTensor"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor">[docs]</a><span class="nd">@tf_export</span><span class="p">(</span><span class="s2">&quot;RaggedTensor&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">RaggedTensor</span><span class="p">(</span><span class="n">composite_tensor</span><span class="o">.</span><span class="n">CompositeTensor</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Represents a ragged tensor.</span>

<span class="sd">  A `RaggedTensor` is a tensor with one or more *ragged dimensions*, which are</span>
<span class="sd">  dimensions whose slices may have different lengths.  For example, the inner</span>
<span class="sd">  (column) dimension of `rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]` is ragged,</span>
<span class="sd">  since the column slices (`rt[0, :]`, ..., `rt[4, :]`) have different lengths.</span>
<span class="sd">  Dimensions whose slices all have the same length are called *uniform</span>
<span class="sd">  dimensions*.  The outermost dimension of a `RaggedTensor` is always uniform,</span>
<span class="sd">  since it consists of a single slice (and so there is no possibility for</span>
<span class="sd">  differing slice lengths).</span>

<span class="sd">  The total number of dimensions in a `RaggedTensor` is called its *rank*,</span>
<span class="sd">  and the number of ragged dimensions in a `RaggedTensor` is called its</span>
<span class="sd">  *ragged-rank*.  A `RaggedTensor`&#39;s ragged-rank is fixed at graph creation</span>
<span class="sd">  time: it can&#39;t depend on the runtime values of `Tensor`s, and can&#39;t vary</span>
<span class="sd">  dynamically for different session runs.</span>

<span class="sd">  ### Potentially Ragged Tensors</span>

<span class="sd">  Many ops support both `Tensor`s and `RaggedTensor`s.  The term &quot;potentially</span>
<span class="sd">  ragged tensor&quot; may be used to refer to a tensor that might be either a</span>
<span class="sd">  `Tensor` or a `RaggedTensor`.  The ragged-rank of a `Tensor` is zero.</span>

<span class="sd">  ### Documenting RaggedTensor Shapes</span>

<span class="sd">  When documenting the shape of a RaggedTensor, ragged dimensions can be</span>
<span class="sd">  indicated by enclosing them in parentheses.  For example, the shape of</span>
<span class="sd">  a 3-D `RaggedTensor` that stores the fixed-size word embedding for each</span>
<span class="sd">  word in a sentence, for each sentence in a batch, could be written as</span>
<span class="sd">  `[num_sentences, (num_words), embedding_size]`.  The parentheses around</span>
<span class="sd">  `(num_words)` indicate that dimension is ragged, and that the length</span>
<span class="sd">  of each element list in that dimension may vary for each item.</span>

<span class="sd">  ### Component Tensors</span>

<span class="sd">  Internally, a `RaggedTensor` consists of a concatenated list of values that</span>
<span class="sd">  are partitioned into variable-length rows.  In particular, each `RaggedTensor`</span>
<span class="sd">  consists of:</span>

<span class="sd">    * A `values` tensor, which concatenates the variable-length rows into a</span>
<span class="sd">      flattened list.  For example, the `values` tensor for</span>
<span class="sd">      `[[3, 1, 4, 1], [], [5, 9, 2], [6], []]` is `[3, 1, 4, 1, 5, 9, 2, 6]`.</span>

<span class="sd">    * A `row_splits` vector, which indicates how those flattened values are</span>
<span class="sd">      divided into rows.  In particular, the values for row `rt[i]` are stored</span>
<span class="sd">      in the slice `rt.values[rt.row_splits[i]:rt.row_splits[i+1]]`.</span>

<span class="sd">  Example:</span>

<span class="sd">  &gt;&gt;&gt; print(tf.RaggedTensor.from_row_splits(</span>
<span class="sd">  ...       values=[3, 1, 4, 1, 5, 9, 2, 6],</span>
<span class="sd">  ...       row_splits=[0, 4, 4, 7, 8, 8]))</span>
<span class="sd">  &lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;</span>

<span class="sd">  ### Alternative Row-Partitioning Schemes</span>

<span class="sd">  In addition to `row_splits`, ragged tensors provide support for four other</span>
<span class="sd">  row-partitioning schemes:</span>

<span class="sd">    * `row_lengths`: a vector with shape `[nrows]`, which specifies the length</span>
<span class="sd">      of each row.</span>

<span class="sd">    * `value_rowids` and `nrows`: `value_rowids` is a vector with shape</span>
<span class="sd">      `[nvals]`, corresponding one-to-one with `values`, which specifies</span>
<span class="sd">      each value&#39;s row index.  In particular, the row `rt[row]` consists of the</span>
<span class="sd">      values `rt.values[j]` where `value_rowids[j]==row`.  `nrows` is an</span>
<span class="sd">      integer scalar that specifies the number of rows in the</span>
<span class="sd">      `RaggedTensor`. (`nrows` is used to indicate trailing empty rows.)</span>

<span class="sd">    * `row_starts`: a vector with shape `[nrows]`, which specifies the start</span>
<span class="sd">      offset of each row.  Equivalent to `row_splits[:-1]`.</span>

<span class="sd">    * `row_limits`: a vector with shape `[nrows]`, which specifies the stop</span>
<span class="sd">      offset of each row.  Equivalent to `row_splits[1:]`.</span>

<span class="sd">    * `uniform_row_length`: A scalar tensor, specifying the length of every</span>
<span class="sd">      row.  This row-partitioning scheme may only be used if all rows have</span>
<span class="sd">      the same length.</span>

<span class="sd">  Example: The following ragged tensors are equivalent, and all represent the</span>
<span class="sd">  nested list `[[3, 1, 4, 1], [], [5, 9, 2], [6], []]`.</span>

<span class="sd">  &gt;&gt;&gt; values = [3, 1, 4, 1, 5, 9, 2, 6]</span>
<span class="sd">  &gt;&gt;&gt; rt1 = RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8])</span>
<span class="sd">  &gt;&gt;&gt; rt2 = RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0])</span>
<span class="sd">  &gt;&gt;&gt; rt3 = RaggedTensor.from_value_rowids(</span>
<span class="sd">  ...     values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5)</span>
<span class="sd">  &gt;&gt;&gt; rt4 = RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8])</span>
<span class="sd">  &gt;&gt;&gt; rt5 = RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8])</span>

<span class="sd">  ### Multiple Ragged Dimensions</span>

<span class="sd">  `RaggedTensor`s with multiple ragged dimensions can be defined by using</span>
<span class="sd">  a nested `RaggedTensor` for the `values` tensor.  Each nested `RaggedTensor`</span>
<span class="sd">  adds a single ragged dimension.</span>

<span class="sd">  &gt;&gt;&gt; inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above</span>
<span class="sd">  ...     values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8])</span>
<span class="sd">  &gt;&gt;&gt; outer_rt = RaggedTensor.from_row_splits(</span>
<span class="sd">  ...     values=inner_rt, row_splits=[0, 3, 3, 5])</span>
<span class="sd">  &gt;&gt;&gt; print(outer_rt.to_list())</span>
<span class="sd">  [[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]</span>
<span class="sd">  &gt;&gt;&gt; print(outer_rt.ragged_rank)</span>
<span class="sd">  2</span>

<span class="sd">  The factory function `RaggedTensor.from_nested_row_splits` may be used to</span>
<span class="sd">  construct a `RaggedTensor` with multiple ragged dimensions directly, by</span>
<span class="sd">  providing a list of `row_splits` tensors:</span>

<span class="sd">  &gt;&gt;&gt; RaggedTensor.from_nested_row_splits(</span>
<span class="sd">  ...     flat_values=[3, 1, 4, 1, 5, 9, 2, 6],</span>
<span class="sd">  ...     nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list()</span>
<span class="sd">  [[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]</span>

<span class="sd">  ### Uniform Inner Dimensions</span>

<span class="sd">  `RaggedTensor`s with uniform inner dimensions can be defined</span>
<span class="sd">  by using a multidimensional `Tensor` for `values`.</span>

<span class="sd">  &gt;&gt;&gt; rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3], tf.int32),</span>
<span class="sd">  ...                                   row_splits=[0, 2, 5])</span>
<span class="sd">  &gt;&gt;&gt; print(rt.to_list())</span>
<span class="sd">  [[[1, 1, 1], [1, 1, 1]],</span>
<span class="sd">   [[1, 1, 1], [1, 1, 1], [1, 1, 1]]]</span>
<span class="sd">  &gt;&gt;&gt; print(rt.shape)</span>
<span class="sd">  (2, None, 3)</span>

<span class="sd">  ### Uniform Outer Dimensions</span>

<span class="sd">  `RaggedTensor`s with uniform outer dimensions can be defined by using</span>
<span class="sd">  one or more `RaggedTensor` with a `uniform_row_length` row-partitioning</span>
<span class="sd">  tensor.  For example, a `RaggedTensor` with shape `[2, 2, None]` can be</span>
<span class="sd">  constructed with this method from a `RaggedTensor` values with shape</span>
<span class="sd">  `[4, None]`:</span>

<span class="sd">  &gt;&gt;&gt; values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])</span>
<span class="sd">  &gt;&gt;&gt; print(values.shape)</span>
<span class="sd">  (4, None)</span>
<span class="sd">  &gt;&gt;&gt; rt6 = tf.RaggedTensor.from_uniform_row_length(values, 2)</span>
<span class="sd">  &gt;&gt;&gt; print(rt6)</span>
<span class="sd">  &lt;tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]&gt;</span>
<span class="sd">  &gt;&gt;&gt; print(rt6.shape)</span>
<span class="sd">  (2, 2, None)</span>

<span class="sd">  Note that `rt6` only contains one ragged dimension (the innermost</span>
<span class="sd">  dimension). In contrast, if `from_row_splits` is used to construct a similar</span>
<span class="sd">  `RaggedTensor`, then that `RaggedTensor` will have two ragged dimensions:</span>

<span class="sd">  &gt;&gt;&gt; rt7 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])</span>
<span class="sd">  &gt;&gt;&gt; print(rt7.shape)</span>
<span class="sd">  (2, None, None)</span>

<span class="sd">  Uniform and ragged outer dimensions may be interleaved, meaning that a</span>
<span class="sd">  tensor with any combination of ragged and uniform dimensions may be created.</span>
<span class="sd">  For example, a RaggedTensor `t4` with shape `[3, None, 4, 8, None, 2]` could</span>
<span class="sd">  be constructed as follows:</span>

<span class="sd">  ```python</span>
<span class="sd">  t0 = tf.zeros([1000, 2])                           # Shape:         [1000, 2]</span>
<span class="sd">  t1 = RaggedTensor.from_row_lengths(t0, [...])      #           [160, None, 2]</span>
<span class="sd">  t2 = RaggedTensor.from_uniform_row_length(t1, 8)   #         [20, 8, None, 2]</span>
<span class="sd">  t3 = RaggedTensor.from_uniform_row_length(t2, 4)   #       [5, 4, 8, None, 2]</span>
<span class="sd">  t4 = RaggedTensor.from_row_lengths(t3, [...])      # [3, None, 4, 8, None, 2]</span>
<span class="sd">  ```</span>

<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1">#=============================================================================</span>
  <span class="c1"># Constructor (private)</span>
  <span class="c1">#=============================================================================</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">values</span><span class="p">,</span>
               <span class="n">row_splits</span><span class="p">,</span>
               <span class="n">cached_row_lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">cached_value_rowids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">cached_nrows</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">internal</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">uniform_row_length</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a `RaggedTensor` with a specified partitioning for `values`.</span>

<span class="sd">    This constructor is private -- please use one of the following ops to</span>
<span class="sd">    build `RaggedTensor`s:</span>

<span class="sd">      * `tf.RaggedTensor.from_row_lengths`</span>
<span class="sd">      * `tf.RaggedTensor.from_value_rowids`</span>
<span class="sd">      * `tf.RaggedTensor.from_row_splits`</span>
<span class="sd">      * `tf.RaggedTensor.from_row_starts`</span>
<span class="sd">      * `tf.RaggedTensor.from_row_limits`</span>
<span class="sd">      * `tf.RaggedTensor.from_nested_row_splits`</span>
<span class="sd">      * `tf.RaggedTensor.from_nested_row_lengths`</span>
<span class="sd">      * `tf.RaggedTensor.from_nested_value_rowids`</span>

<span class="sd">    Args:</span>
<span class="sd">      values: A potentially ragged tensor of any dtype and shape `[nvals, ...]`.</span>
<span class="sd">      row_splits: A 1-D integer tensor with shape `[nrows+1]`.</span>
<span class="sd">      cached_row_lengths: A 1-D integer tensor with shape `[nrows]`</span>
<span class="sd">      cached_value_rowids: A 1-D integer tensor with shape `[nvals]`.</span>
<span class="sd">      cached_nrows: A 1-D integer scalar tensor.</span>
<span class="sd">      internal: True if the constructor is being called by one of the factory</span>
<span class="sd">        methods.  If false, an exception will be raised.</span>
<span class="sd">      uniform_row_length: A scalar tensor.</span>

<span class="sd">    Raises:</span>
<span class="sd">      TypeError: If a row partitioning tensor has an inappropriate dtype.</span>
<span class="sd">      TypeError: If exactly one row partitioning argument was not specified.</span>
<span class="sd">      ValueError: If a row partitioning tensor has an inappropriate shape.</span>
<span class="sd">      ValueError: If multiple partitioning arguments are specified.</span>
<span class="sd">      ValueError: If nrows is specified but value_rowids is not None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">internal</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;RaggedTensor constructor is private; please use one &quot;</span>
                       <span class="s2">&quot;of the factory methods instead (e.g., &quot;</span>
                       <span class="s2">&quot;RaggedTensor.from_row_lengths())&quot;</span><span class="p">)</span>

    <span class="c1"># Validate the arguments.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">row_splits</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Row-partitioning argument must be a Tensor, got </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span>
                      <span class="n">row_splits</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="n">RaggedTensor</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;values must be a Tensor or RaggedTensor, got </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span>
                      <span class="n">values</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">row_splits</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Row-partitioning argument must be int32 or int64&quot;</span><span class="p">)</span>

    <span class="c1"># Validate shapes &amp; dtypes.</span>
    <span class="n">row_splits</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">assert_has_rank</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">with_rank_at_least</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">row_splits</span><span class="o">.</span><span class="n">set_shape</span><span class="p">([</span><span class="kc">None</span><span class="p">])</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
      <span class="k">assert</span> <span class="n">row_splits</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">values</span><span class="o">.</span><span class="n">row_splits</span><span class="o">.</span><span class="n">dtype</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_values</span> <span class="o">=</span> <span class="n">values</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits</span> <span class="o">=</span> <span class="n">row_splits</span>

    <span class="c1"># Store any cached tensors.  These are used to avoid unnecessary</span>
    <span class="c1"># round-trip conversions when a RaggedTensor is constructed from</span>
    <span class="c1"># lengths or rowids, and we later want those lengths/rowids back.</span>
    <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="p">[</span><span class="n">cached_row_lengths</span><span class="p">,</span> <span class="n">cached_value_rowids</span><span class="p">,</span> <span class="n">cached_nrows</span><span class="p">]:</span>
      <span class="k">if</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
          <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Cached value must be a Tensor or None.&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">tensor</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
          <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Cached value must be int32 or int64.&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_cached_row_lengths</span> <span class="o">=</span> <span class="n">cached_row_lengths</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_cached_value_rowids</span> <span class="o">=</span> <span class="n">cached_value_rowids</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_cached_nrows</span> <span class="o">=</span> <span class="n">cached_nrows</span>

    <span class="k">if</span> <span class="n">uniform_row_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">uniform_row_length</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;uniform_row_length must be a Tensor or None.&quot;</span><span class="p">)</span>
      <span class="k">elif</span> <span class="n">uniform_row_length</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;uniform_row_length must be int32 or int64.&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_uniform_row_length</span> <span class="o">=</span> <span class="n">uniform_row_length</span>

  <span class="c1">#=============================================================================</span>
  <span class="c1"># Factory Methods</span>
  <span class="c1">#=============================================================================</span>

<div class="viewcode-block" id="RaggedTensor.from_value_rowids"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.from_value_rowids">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">from_value_rowids</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span>
                        <span class="n">values</span><span class="p">,</span>
                        <span class="n">value_rowids</span><span class="p">,</span>
                        <span class="n">nrows</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a `RaggedTensor` with rows partitioned by `value_rowids`.</span>

<span class="sd">    The returned `RaggedTensor` corresponds with the python list defined by:</span>

<span class="sd">    ```python</span>
<span class="sd">    result = [[values[i] for i in range(len(values)) if value_rowids[i] == row]</span>
<span class="sd">              for row in range(nrows)]</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      values: A potentially ragged tensor with shape `[nvals, ...]`.</span>
<span class="sd">      value_rowids: A 1-D integer tensor with shape `[nvals]`, which corresponds</span>
<span class="sd">        one-to-one with `values`, and specifies each value&#39;s row index.  Must be</span>
<span class="sd">        nonnegative, and must be sorted in ascending order.</span>
<span class="sd">      nrows: An integer scalar specifying the number of rows.  This should be</span>
<span class="sd">        specified if the `RaggedTensor` may containing empty training rows. Must</span>
<span class="sd">        be greater than `value_rowids[-1]` (or zero if `value_rowids` is empty).</span>
<span class="sd">        Defaults to `value_rowids[-1]` (or zero if `value_rowids` is empty).</span>
<span class="sd">      name: A name prefix for the RaggedTensor (optional).</span>
<span class="sd">      validate: If true, then use assertions to check that the arguments form</span>
<span class="sd">        a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,</span>
<span class="sd">        since they must be checked for each tensor value.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `RaggedTensor`.  `result.rank = values.rank + 1`.</span>
<span class="sd">      `result.ragged_rank = values.ragged_rank + 1`.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If `nrows` is incompatible with `value_rowids`.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; print(tf.RaggedTensor.from_value_rowids(</span>
<span class="sd">    ...     values=[3, 1, 4, 1, 5, 9, 2, 6],</span>
<span class="sd">    ...     value_rowids=[0, 0, 0, 0, 2, 2, 2, 3],</span>
<span class="sd">    ...     nrows=5))</span>
<span class="sd">    &lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">validate</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;validate must have type bool&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedFromValueRowIds&quot;</span><span class="p">,</span>
                        <span class="p">[</span><span class="n">values</span><span class="p">,</span> <span class="n">value_rowids</span><span class="p">,</span> <span class="n">nrows</span><span class="p">]):</span>
      <span class="n">values</span><span class="p">,</span> <span class="n">value_rowids</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_convert_values_and_row_partition</span><span class="p">(</span>
          <span class="n">values</span><span class="p">,</span> <span class="n">value_rowids</span><span class="p">,</span> <span class="s2">&quot;value_rowids&quot;</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">nrows</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">const_rowids</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">value_rowids</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">const_rowids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">nrows</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">value_rowids</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
          <span class="n">const_nrows</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">const_nrows</span> <span class="o">=</span> <span class="n">const_rowids</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">const_rowids</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
          <span class="n">nrows</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">const_nrows</span><span class="p">,</span> <span class="n">value_rowids</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                                        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;nrows&quot;</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">nrows</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span> <span class="n">value_rowids</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;nrows&quot;</span><span class="p">)</span>
        <span class="n">const_nrows</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">nrows</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">const_nrows</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">const_nrows</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Expected nrows &gt;= 0; got </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">const_nrows</span><span class="p">)</span>
          <span class="n">const_rowids</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">value_rowids</span><span class="p">)</span>
          <span class="k">if</span> <span class="n">const_rowids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">const_rowids</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">const_nrows</span> <span class="o">&gt;=</span> <span class="n">const_rowids</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
              <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                  <span class="s2">&quot;Expected nrows &gt;= value_rowids[-1] + 1; got nrows=</span><span class="si">%d</span><span class="s2">, &quot;</span>
                  <span class="s2">&quot;value_rowids[-1]=</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">const_nrows</span><span class="p">,</span> <span class="n">const_rowids</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

      <span class="n">value_rowids</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">assert_has_rank</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">nrows</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">assert_has_rank</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
      <span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">assert_is_compatible_with</span><span class="p">(</span><span class="n">value_rowids</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">validate</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Arguments to from_value_rowids do not form a valid RaggedTensor&quot;</span>
        <span class="n">nvals1</span> <span class="o">=</span> <span class="n">_nrows</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
        <span class="n">nvals2</span> <span class="o">=</span> <span class="n">_nrows</span><span class="p">(</span><span class="n">value_rowids</span><span class="p">)</span>
        <span class="n">checks</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_rank</span><span class="p">(</span><span class="n">value_rowids</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_rank</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span><span class="n">nvals1</span><span class="p">,</span> <span class="n">nvals2</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_non_negative</span><span class="p">(</span><span class="n">value_rowids</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">_assert_monotonic_increasing</span><span class="p">(</span><span class="n">value_rowids</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_less</span><span class="p">(</span><span class="n">value_rowids</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span> <span class="n">nrows</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
          <span class="n">checks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">check_ops</span><span class="o">.</span><span class="n">assert_rank_at_least</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">value_rowids</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">checks</span><span class="p">,</span> <span class="n">value_rowids</span><span class="p">)</span>

      <span class="c1"># Convert value_rowids &amp; nrows to row_splits.</span>
      <span class="c1"># Note: we don&#39;t use segment_ids_to_row_splits() here because we want</span>
      <span class="c1"># to save the intermediate value `row_lengths`, so we can cache it.</span>
      <span class="c1"># TODO(b/116708836) Upgrade bincount to accept int64 so we can skip the</span>
      <span class="c1"># cast.</span>
      <span class="n">value_rowids_int32</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">value_rowids</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
      <span class="n">nrows_int32</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
      <span class="n">row_lengths</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span>
          <span class="n">value_rowids_int32</span><span class="p">,</span>
          <span class="n">minlength</span><span class="o">=</span><span class="n">nrows_int32</span><span class="p">,</span>
          <span class="n">maxlength</span><span class="o">=</span><span class="n">nrows_int32</span><span class="p">,</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">value_rowids</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">row_splits</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">row_lengths</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">const_nrows</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">row_lengths</span><span class="o">.</span><span class="n">set_shape</span><span class="p">([</span><span class="n">const_nrows</span><span class="p">])</span>
        <span class="n">row_splits</span><span class="o">.</span><span class="n">set_shape</span><span class="p">([</span><span class="n">const_nrows</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>

      <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
          <span class="n">values</span><span class="p">,</span>
          <span class="n">row_splits</span><span class="p">,</span>
          <span class="n">cached_row_lengths</span><span class="o">=</span><span class="n">row_lengths</span><span class="p">,</span>
          <span class="n">cached_value_rowids</span><span class="o">=</span><span class="n">value_rowids</span><span class="p">,</span>
          <span class="n">cached_nrows</span><span class="o">=</span><span class="n">nrows</span><span class="p">,</span>
          <span class="n">internal</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.from_row_splits"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.from_row_splits">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">from_row_splits</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">row_splits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a `RaggedTensor` with rows partitioned by `row_splits`.</span>

<span class="sd">    The returned `RaggedTensor` corresponds with the python list defined by:</span>

<span class="sd">    ```python</span>
<span class="sd">    result = [values[row_splits[i]:row_splits[i + 1]]</span>
<span class="sd">              for i in range(len(row_splits) - 1)]</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      values: A potentially ragged tensor with shape `[nvals, ...]`.</span>
<span class="sd">      row_splits: A 1-D integer tensor with shape `[nrows+1]`.  Must not be</span>
<span class="sd">        empty, and must be sorted in ascending order.  `row_splits[0]` must be</span>
<span class="sd">        zero and `row_splits[-1]` must be `nvals`.</span>
<span class="sd">      name: A name prefix for the RaggedTensor (optional).</span>
<span class="sd">      validate: If true, then use assertions to check that the arguments form</span>
<span class="sd">        a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,</span>
<span class="sd">        since they must be checked for each tensor value.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `RaggedTensor`.  `result.rank = values.rank + 1`.</span>
<span class="sd">      `result.ragged_rank = values.ragged_rank + 1`.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If `row_splits` is an empty list.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; print(tf.RaggedTensor.from_row_splits(</span>
<span class="sd">    ...     values=[3, 1, 4, 1, 5, 9, 2, 6],</span>
<span class="sd">    ...     row_splits=[0, 4, 4, 7, 8, 8]))</span>
<span class="sd">    &lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">validate</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;validate must have type bool&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">row_splits</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">row_splits</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;row_splits tensor may not be empty.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">row_splits</span><span class="p">,</span> <span class="n">tensor_spec</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">row_splits</span><span class="o">=</span><span class="n">row_splits</span><span class="p">,</span> <span class="n">internal</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedFromRowSplits&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">values</span><span class="p">,</span> <span class="n">row_splits</span><span class="p">]):</span>
      <span class="n">values</span><span class="p">,</span> <span class="n">row_splits</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_convert_values_and_row_partition</span><span class="p">(</span>
          <span class="n">values</span><span class="p">,</span> <span class="n">row_splits</span><span class="p">,</span> <span class="s2">&quot;row_splits&quot;</span><span class="p">)</span>
      <span class="n">row_splits</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">assert_has_rank</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">validate</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Arguments to from_row_splits do not form a valid RaggedTensor&quot;</span>
        <span class="n">nvals</span> <span class="o">=</span> <span class="n">_nrows</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">row_splits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">checks</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_rank</span><span class="p">(</span><span class="n">row_splits</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">_assert_zero</span><span class="p">(</span><span class="n">row_splits</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">_assert_monotonic_increasing</span><span class="p">(</span><span class="n">row_splits</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span><span class="n">row_splits</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">nvals</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
          <span class="n">checks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">check_ops</span><span class="o">.</span><span class="n">assert_rank_at_least</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">row_splits</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">checks</span><span class="p">,</span> <span class="n">row_splits</span><span class="p">)</span>

      <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">row_splits</span><span class="o">=</span><span class="n">row_splits</span><span class="p">,</span> <span class="n">internal</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.from_row_lengths"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.from_row_lengths">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">from_row_lengths</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">row_lengths</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a `RaggedTensor` with rows partitioned by `row_lengths`.</span>

<span class="sd">    The returned `RaggedTensor` corresponds with the python list defined by:</span>

<span class="sd">    ```python</span>
<span class="sd">    result = [[values.pop(0) for i in range(length)]</span>
<span class="sd">              for length in row_lengths]</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      values: A potentially ragged tensor with shape `[nvals, ...]`.</span>
<span class="sd">      row_lengths: A 1-D integer tensor with shape `[nrows]`.  Must be</span>
<span class="sd">        nonnegative.  `sum(row_lengths)` must be `nvals`.</span>
<span class="sd">      name: A name prefix for the RaggedTensor (optional).</span>
<span class="sd">      validate: If true, then use assertions to check that the arguments form</span>
<span class="sd">        a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,</span>
<span class="sd">        since they must be checked for each tensor value.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `RaggedTensor`.  `result.rank = values.rank + 1`.</span>
<span class="sd">      `result.ragged_rank = values.ragged_rank + 1`.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; print(tf.RaggedTensor.from_row_lengths(</span>
<span class="sd">    ...     values=[3, 1, 4, 1, 5, 9, 2, 6],</span>
<span class="sd">    ...     row_lengths=[4, 0, 3, 1, 0]))</span>
<span class="sd">    &lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">validate</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;validate must have type bool&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedFromRowLengths&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">values</span><span class="p">,</span> <span class="n">row_lengths</span><span class="p">]):</span>
      <span class="n">values</span><span class="p">,</span> <span class="n">row_lengths</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_convert_values_and_row_partition</span><span class="p">(</span>
          <span class="n">values</span><span class="p">,</span> <span class="n">row_lengths</span><span class="p">,</span> <span class="s2">&quot;row_lengths&quot;</span><span class="p">)</span>
      <span class="n">row_lengths</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">assert_has_rank</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">validate</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Arguments to from_row_lengths do not form a valid RaggedTensor&quot;</span>
        <span class="n">nvals1</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">row_lengths</span><span class="p">)</span>
        <span class="n">nvals2</span> <span class="o">=</span> <span class="n">_nrows</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">row_lengths</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">checks</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_rank</span><span class="p">(</span><span class="n">row_lengths</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_non_negative</span><span class="p">(</span><span class="n">row_lengths</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span><span class="n">nvals1</span><span class="p">,</span> <span class="n">nvals2</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
          <span class="n">checks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">check_ops</span><span class="o">.</span><span class="n">assert_rank_at_least</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">row_lengths</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">checks</span><span class="p">,</span> <span class="n">row_lengths</span><span class="p">)</span>

      <span class="n">row_limits</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">row_lengths</span><span class="p">)</span>
      <span class="n">row_splits</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="n">row_limits</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
          <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span>
          <span class="n">row_splits</span><span class="o">=</span><span class="n">row_splits</span><span class="p">,</span>
          <span class="n">cached_row_lengths</span><span class="o">=</span><span class="n">row_lengths</span><span class="p">,</span>
          <span class="n">internal</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.from_row_starts"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.from_row_starts">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">from_row_starts</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">row_starts</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a `RaggedTensor` with rows partitioned by `row_starts`.</span>

<span class="sd">    Equivalent to: `from_row_splits(values, concat([row_starts, nvals]))`.</span>

<span class="sd">    Args:</span>
<span class="sd">      values: A potentially ragged tensor with shape `[nvals, ...]`.</span>
<span class="sd">      row_starts: A 1-D integer tensor with shape `[nrows]`.  Must be</span>
<span class="sd">        nonnegative and sorted in ascending order.  If `nrows&gt;0`, then</span>
<span class="sd">        `row_starts[0]` must be zero.</span>
<span class="sd">      name: A name prefix for the RaggedTensor (optional).</span>
<span class="sd">      validate: If true, then use assertions to check that the arguments form</span>
<span class="sd">        a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,</span>
<span class="sd">        since they must be checked for each tensor value.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `RaggedTensor`.  `result.rank = values.rank + 1`.</span>
<span class="sd">      `result.ragged_rank = values.ragged_rank + 1`.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; print(tf.RaggedTensor.from_row_starts(</span>
<span class="sd">    ...     values=[3, 1, 4, 1, 5, 9, 2, 6],</span>
<span class="sd">    ...     row_starts=[0, 4, 4, 7, 8]))</span>
<span class="sd">    &lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">validate</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;validate must have type bool&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedFromRowStarts&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">values</span><span class="p">,</span> <span class="n">row_starts</span><span class="p">]):</span>
      <span class="n">values</span><span class="p">,</span> <span class="n">row_starts</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_convert_values_and_row_partition</span><span class="p">(</span>
          <span class="n">values</span><span class="p">,</span> <span class="n">row_starts</span><span class="p">,</span> <span class="s2">&quot;row_starts&quot;</span><span class="p">)</span>
      <span class="n">row_starts</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">assert_has_rank</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">nvals</span> <span class="o">=</span> <span class="n">_nrows</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">row_starts</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">validate</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Arguments to from_row_starts do not form a valid RaggedTensor&quot;</span>
        <span class="n">checks</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_rank</span><span class="p">(</span><span class="n">row_starts</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">_assert_zero</span><span class="p">(</span><span class="n">row_starts</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">_assert_monotonic_increasing</span><span class="p">(</span><span class="n">row_starts</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_less_equal</span><span class="p">(</span><span class="n">row_starts</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span> <span class="n">nvals</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
          <span class="n">checks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">check_ops</span><span class="o">.</span><span class="n">assert_rank_at_least</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">row_starts</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">checks</span><span class="p">,</span> <span class="n">row_starts</span><span class="p">)</span>

      <span class="n">row_splits</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">row_starts</span><span class="p">,</span> <span class="p">[</span><span class="n">nvals</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">row_splits</span><span class="o">=</span><span class="n">row_splits</span><span class="p">,</span> <span class="n">internal</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.from_row_limits"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.from_row_limits">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">from_row_limits</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">row_limits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a `RaggedTensor` with rows partitioned by `row_limits`.</span>

<span class="sd">    Equivalent to: `from_row_splits(values, concat([0, row_limits]))`.</span>

<span class="sd">    Args:</span>
<span class="sd">      values: A potentially ragged tensor with shape `[nvals, ...]`.</span>
<span class="sd">      row_limits: A 1-D integer tensor with shape `[nrows]`.  Must be sorted in</span>
<span class="sd">        ascending order.  If `nrows&gt;0`, then `row_limits[-1]` must be `nvals`.</span>
<span class="sd">      name: A name prefix for the RaggedTensor (optional).</span>
<span class="sd">      validate: If true, then use assertions to check that the arguments form</span>
<span class="sd">        a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,</span>
<span class="sd">        since they must be checked for each tensor value.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `RaggedTensor`.  `result.rank = values.rank + 1`.</span>
<span class="sd">      `result.ragged_rank = values.ragged_rank + 1`.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; print(tf.RaggedTensor.from_row_limits(</span>
<span class="sd">    ...     values=[3, 1, 4, 1, 5, 9, 2, 6],</span>
<span class="sd">    ...     row_limits=[4, 4, 7, 8, 8]))</span>
<span class="sd">    &lt;tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]&gt;</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">validate</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;validate must have type bool&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedFromRowLimits&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">values</span><span class="p">,</span> <span class="n">row_limits</span><span class="p">]):</span>
      <span class="n">values</span><span class="p">,</span> <span class="n">row_limits</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_convert_values_and_row_partition</span><span class="p">(</span>
          <span class="n">values</span><span class="p">,</span> <span class="n">row_limits</span><span class="p">,</span> <span class="s2">&quot;row_limits&quot;</span><span class="p">)</span>
      <span class="n">row_limits</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">assert_has_rank</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">validate</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Arguments to from_row_limits do not form a valid RaggedTensor&quot;</span>
        <span class="n">nvals</span> <span class="o">=</span> <span class="n">_nrows</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">row_limits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">checks</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_rank</span><span class="p">(</span><span class="n">row_limits</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_non_negative</span><span class="p">(</span><span class="n">row_limits</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">_assert_monotonic_increasing</span><span class="p">(</span><span class="n">row_limits</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">),</span>
            <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span><span class="n">row_limits</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:],</span> <span class="n">nvals</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">msg</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
          <span class="n">checks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">check_ops</span><span class="o">.</span><span class="n">assert_rank_at_least</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">row_limits</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">checks</span><span class="p">,</span> <span class="n">row_limits</span><span class="p">)</span>

      <span class="n">zero</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">row_limits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">row_splits</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">zero</span><span class="p">,</span> <span class="n">row_limits</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">row_splits</span><span class="o">=</span><span class="n">row_splits</span><span class="p">,</span> <span class="n">internal</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.from_uniform_row_length"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.from_uniform_row_length">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">from_uniform_row_length</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span>
                              <span class="n">values</span><span class="p">,</span>
                              <span class="n">uniform_row_length</span><span class="p">,</span>
                              <span class="n">nrows</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                              <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                              <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a `RaggedTensor` with rows partitioned by `uniform_row_length`.</span>

<span class="sd">    This method can be used to create `RaggedTensor`s with multiple uniform</span>
<span class="sd">    outer dimensions.  For example, a `RaggedTensor` with shape `[2, 2, None]`</span>
<span class="sd">    can be constructed with this method from a `RaggedTensor` values with shape</span>
<span class="sd">    `[4, None]`:</span>

<span class="sd">    &gt;&gt;&gt; values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])</span>
<span class="sd">    &gt;&gt;&gt; print(values.shape)</span>
<span class="sd">    (4, None)</span>
<span class="sd">    &gt;&gt;&gt; rt1 = tf.RaggedTensor.from_uniform_row_length(values, 2)</span>
<span class="sd">    &gt;&gt;&gt; print(rt1)</span>
<span class="sd">    &lt;tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]&gt;</span>
<span class="sd">    &gt;&gt;&gt; print(rt1.shape)</span>
<span class="sd">    (2, 2, None)</span>

<span class="sd">    Note that `rt1` only contains one ragged dimension (the innermost</span>
<span class="sd">    dimension). In contrast, if `from_row_splits` is used to construct a similar</span>
<span class="sd">    `RaggedTensor`, then that `RaggedTensor` will have two ragged dimensions:</span>

<span class="sd">    &gt;&gt;&gt; rt2 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])</span>
<span class="sd">    &gt;&gt;&gt; print(rt2.shape)</span>
<span class="sd">    (2, None, None)</span>

<span class="sd">    Args:</span>
<span class="sd">      values: A potentially ragged tensor with shape `[nvals, ...]`.</span>
<span class="sd">      uniform_row_length: A scalar integer tensor.  Must be nonnegative.</span>
<span class="sd">        The size of the outer axis of `values` must be evenly divisible by</span>
<span class="sd">        `uniform_row_length`.</span>
<span class="sd">      nrows: The number of rows in the constructed RaggedTensor.  If not</span>
<span class="sd">        specified, then it defaults to `nvals/uniform_row_length` (or `0` if</span>
<span class="sd">        `uniform_row_length==0`).  `nrows` only needs to be specified if</span>
<span class="sd">        `uniform_row_length` might be zero.  `uniform_row_length*nrows` must</span>
<span class="sd">        be `nvals`.</span>
<span class="sd">      validate: If true, then use assertions to check that the arguments form</span>
<span class="sd">        a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,</span>
<span class="sd">        since they must be checked for each tensor value.</span>
<span class="sd">      name: A name prefix for the RaggedTensor (optional).</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `RaggedTensor` that corresponds with the python list defined by:</span>

<span class="sd">      ```python</span>
<span class="sd">      result = [[values.pop(0) for i in range(uniform_row_length)]</span>
<span class="sd">                for _ in range(nrows)]</span>
<span class="sd">      ```</span>

<span class="sd">      `result.rank = values.rank + 1`.</span>
<span class="sd">      `result.ragged_rank = values.ragged_rank + 1`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">validate</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;validate must have type bool&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedFromUniformRowLength&quot;</span><span class="p">,</span>
                        <span class="p">[</span><span class="n">values</span><span class="p">,</span> <span class="n">uniform_row_length</span><span class="p">,</span> <span class="n">nrows</span><span class="p">]):</span>
      <span class="n">values</span><span class="p">,</span> <span class="n">uniform_row_length</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_convert_values_and_row_partition</span><span class="p">(</span>
          <span class="n">values</span><span class="p">,</span> <span class="n">uniform_row_length</span><span class="p">,</span> <span class="s2">&quot;uniform_row_length&quot;</span><span class="p">)</span>
      <span class="n">uniform_row_length</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">assert_has_rank</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

      <span class="c1"># Find nvals.</span>
      <span class="n">const_nvals</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_at_index</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">value</span>
      <span class="k">if</span> <span class="n">const_nvals</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">nvals</span> <span class="o">=</span> <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">const_nvals</span><span class="p">,</span> <span class="n">uniform_row_length</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
        <span class="n">nvals</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">nrows</span><span class="p">(</span><span class="n">out_type</span><span class="o">=</span><span class="n">uniform_row_length</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">nvals</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">uniform_row_length</span><span class="o">.</span><span class="n">dtype</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

      <span class="c1"># Find nrows.</span>
      <span class="n">const_row_length</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">uniform_row_length</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">nrows</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">const_row_length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
          <span class="c1"># Avoid division by zero if uniform_row_length==0 (and nvals==0).</span>
          <span class="n">rowlen_or_1</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
              <span class="n">math_ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">uniform_row_length</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
              <span class="k">lambda</span><span class="p">:</span> <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">uniform_row_length</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
              <span class="k">lambda</span><span class="p">:</span> <span class="n">uniform_row_length</span><span class="p">)</span>
          <span class="n">nrows</span> <span class="o">=</span> <span class="n">nvals</span> <span class="o">//</span> <span class="n">rowlen_or_1</span>
        <span class="k">elif</span> <span class="n">const_row_length</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
          <span class="n">nrows</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">nrows</span> <span class="o">=</span> <span class="n">nvals</span> <span class="o">//</span> <span class="n">const_row_length</span>
      <span class="n">nrows</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
          <span class="n">nrows</span><span class="p">,</span> <span class="n">uniform_row_length</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;nrows&quot;</span><span class="p">)</span>
      <span class="n">const_nrows</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">nrows</span><span class="p">)</span>

      <span class="c1"># Find row_splits.</span>
      <span class="k">if</span> <span class="n">const_nrows</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">const_row_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">row_splits</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="o">*</span> <span class="n">const_row_length</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">const_nrows</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="n">row_splits</span> <span class="o">=</span> <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">row_splits</span><span class="p">,</span> <span class="n">uniform_row_length</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">row_splits</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">nrows</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">uniform_row_length</span>

      <span class="k">if</span> <span class="n">validate</span><span class="p">:</span>
        <span class="n">checks</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">const_nrows</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">const_row_length</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span>
            <span class="n">const_nvals</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
          <span class="n">checks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">check_ops</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span>
              <span class="n">nrows</span> <span class="o">*</span> <span class="n">uniform_row_length</span><span class="p">,</span>
              <span class="n">nvals</span><span class="p">,</span>
              <span class="p">(</span><span class="s2">&quot;uniform_row_length&quot;</span><span class="p">,</span> <span class="n">uniform_row_length</span><span class="p">,</span> <span class="s2">&quot;times nrows&quot;</span><span class="p">,</span>
               <span class="n">nrows</span><span class="p">,</span> <span class="s2">&quot;must equal nvals&quot;</span><span class="p">,</span> <span class="n">nvals</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">const_nrows</span> <span class="o">*</span> <span class="n">const_row_length</span> <span class="o">!=</span> <span class="n">const_nvals</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;uniform_row_length=</span><span class="si">%d</span><span class="s2"> times nrows=</span><span class="si">%d</span><span class="s2"> must equal nvals=</span><span class="si">%d</span><span class="s2">&quot;</span>
                <span class="o">%</span> <span class="p">(</span><span class="n">const_row_length</span><span class="p">,</span> <span class="n">const_nrows</span><span class="p">,</span> <span class="n">const_nvals</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">uniform_row_length</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">rank</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">checks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
              <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_rank</span><span class="p">(</span>
                  <span class="n">uniform_row_length</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
                  <span class="n">message</span><span class="o">=</span><span class="s2">&quot;uniform_row_length must be a scalar.&quot;</span><span class="p">))</span>

        <span class="n">const_row_length</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="n">uniform_row_length</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">const_row_length</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">checks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
              <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_greater_equal</span><span class="p">(</span>
                  <span class="n">uniform_row_length</span><span class="p">,</span>
                  <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">uniform_row_length</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                  <span class="n">message</span><span class="o">=</span><span class="s2">&quot;uniform_row_length must be &gt;= 0.&quot;</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">const_row_length</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;uniform_row_length must be &gt;= 0.&quot;</span><span class="p">)</span>

        <span class="n">row_splits</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">checks</span><span class="p">,</span> <span class="n">row_splits</span><span class="p">)</span>

      <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
          <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span>
          <span class="n">row_splits</span><span class="o">=</span><span class="n">row_splits</span><span class="p">,</span>
          <span class="n">uniform_row_length</span><span class="o">=</span><span class="n">uniform_row_length</span><span class="p">,</span>
          <span class="n">cached_nrows</span><span class="o">=</span><span class="n">nrows</span><span class="p">,</span>
          <span class="n">internal</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.from_nested_value_rowids"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.from_nested_value_rowids">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">from_nested_value_rowids</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span>
                               <span class="n">flat_values</span><span class="p">,</span>
                               <span class="n">nested_value_rowids</span><span class="p">,</span>
                               <span class="n">nested_nrows</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                               <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                               <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a `RaggedTensor` from a nested list of `value_rowids` tensors.</span>

<span class="sd">    Equivalent to:</span>

<span class="sd">    ```python</span>
<span class="sd">    result = flat_values</span>
<span class="sd">    for (rowids, nrows) in reversed(zip(nested_value_rowids, nested_nrows)):</span>
<span class="sd">      result = from_value_rowids(result, rowids, nrows)</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      flat_values: A potentially ragged tensor.</span>
<span class="sd">      nested_value_rowids: A list of 1-D integer tensors.  The `i`th tensor is</span>
<span class="sd">        used as the `value_rowids` for the `i`th ragged dimension.</span>
<span class="sd">      nested_nrows: A list of integer scalars.  The `i`th scalar is used as the</span>
<span class="sd">        `nrows` for the `i`th ragged dimension.</span>
<span class="sd">      name: A name prefix for the RaggedTensor (optional).</span>

<span class="sd">      validate: If true, then use assertions to check that the arguments form</span>
<span class="sd">        a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,</span>
<span class="sd">        since they must be checked for each tensor value.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `RaggedTensor` (or `flat_values` if `nested_value_rowids` is empty).</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If `len(nested_values_rowids) != len(nested_nrows)`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">validate</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;validate must have type bool&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">nested_value_rowids</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;nested_value_rowids must be a list of Tensors&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">nested_nrows</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">nested_nrows</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">nested_value_rowids</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">nested_nrows</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;nested_nrows must be a list of Tensors&quot;</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nested_nrows</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nested_value_rowids</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;nested_nrows must have the same length as &quot;</span>
                         <span class="s2">&quot;nested_value_rowids&quot;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span>
        <span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedFromNestedValueRowIds&quot;</span><span class="p">,</span>
        <span class="p">[</span><span class="n">flat_values</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">nested_value_rowids</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">nested_nrows</span><span class="p">)):</span>
      <span class="n">result</span> <span class="o">=</span> <span class="n">flat_values</span>
      <span class="k">for</span> <span class="n">value_rowids</span><span class="p">,</span> <span class="n">nrows</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span>
          <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">nested_value_rowids</span><span class="p">,</span> <span class="n">nested_nrows</span><span class="p">))):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">value_rowids</span><span class="p">,</span> <span class="n">nrows</span><span class="p">,</span>
                                       <span class="n">validate</span><span class="o">=</span><span class="n">validate</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="RaggedTensor.from_nested_row_splits"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.from_nested_row_splits">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">from_nested_row_splits</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span>
                             <span class="n">flat_values</span><span class="p">,</span>
                             <span class="n">nested_row_splits</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a `RaggedTensor` from a nested list of `row_splits` tensors.</span>

<span class="sd">    Equivalent to:</span>

<span class="sd">    ```python</span>
<span class="sd">    result = flat_values</span>
<span class="sd">    for row_splits in reversed(nested_row_splits):</span>
<span class="sd">      result = from_row_splits(result, row_splits)</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      flat_values: A potentially ragged tensor.</span>
<span class="sd">      nested_row_splits: A list of 1-D integer tensors.  The `i`th tensor is</span>
<span class="sd">        used as the `row_splits` for the `i`th ragged dimension.</span>
<span class="sd">      name: A name prefix for the RaggedTensor (optional).</span>
<span class="sd">      validate: If true, then use assertions to check that the arguments form</span>
<span class="sd">        a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,</span>
<span class="sd">        since they must be checked for each tensor value.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `RaggedTensor` (or `flat_values` if `nested_row_splits` is empty).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">validate</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;validate must have type bool&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">nested_row_splits</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;nested_row_splits must be a list of Tensors&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedFromNestedRowSplits&quot;</span><span class="p">,</span>
                        <span class="p">[</span><span class="n">flat_values</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">nested_row_splits</span><span class="p">)):</span>
      <span class="n">result</span> <span class="o">=</span> <span class="n">flat_values</span>
      <span class="k">for</span> <span class="n">splits</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">nested_row_splits</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_row_splits</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">splits</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="n">validate</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="RaggedTensor.from_nested_row_lengths"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.from_nested_row_lengths">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">from_nested_row_lengths</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span>
                              <span class="n">flat_values</span><span class="p">,</span>
                              <span class="n">nested_row_lengths</span><span class="p">,</span>
                              <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                              <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a `RaggedTensor` from a nested list of `row_lengths` tensors.</span>

<span class="sd">    Equivalent to:</span>

<span class="sd">    ```python</span>
<span class="sd">    result = flat_values</span>
<span class="sd">    for row_lengths in reversed(nested_row_lengths):</span>
<span class="sd">      result = from_row_lengths(result, row_lengths)</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      flat_values: A potentially ragged tensor.</span>
<span class="sd">      nested_row_lengths: A list of 1-D integer tensors.  The `i`th tensor is</span>
<span class="sd">        used as the `row_lengths` for the `i`th ragged dimension.</span>
<span class="sd">      name: A name prefix for the RaggedTensor (optional).</span>
<span class="sd">      validate: If true, then use assertions to check that the arguments form</span>
<span class="sd">        a valid `RaggedTensor`.  Note: these assertions incur a runtime cost,</span>
<span class="sd">        since they must be checked for each tensor value.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `RaggedTensor` (or `flat_values` if `nested_row_lengths` is empty).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">validate</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;validate must have type bool&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">nested_row_lengths</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;nested_row_lengths must be a list of Tensors&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedFromNestedRowlengths&quot;</span><span class="p">,</span>
                        <span class="p">[</span><span class="n">flat_values</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">nested_row_lengths</span><span class="p">)):</span>
      <span class="n">result</span> <span class="o">=</span> <span class="n">flat_values</span>
      <span class="k">for</span> <span class="n">lengths</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">nested_row_lengths</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_row_lengths</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="n">validate</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">result</span></div>

  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">_convert_values_and_row_partition</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">partition</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts `values` and `partition` to Tensors.</span>

<span class="sd">    If `values` is a `RaggedTensor`, then converts `values` and `partition`</span>
<span class="sd">    to have compatible row-partitioning dtypes.  In particular, if any of the</span>
<span class="sd">    row partitioning tensors are `int64`, then all of the other row</span>
<span class="sd">    partitioning tensors wil be cast to `int64` (if auto_cast_partition_dtype()</span>
<span class="sd">    is true) or an error will be raised (if auto_cast_partition_dtype() is</span>
<span class="sd">    false).</span>

<span class="sd">    Args:</span>
<span class="sd">      values: The `values` for the `RaggedTensor` being constructed.</span>
<span class="sd">      partition: A row-partitioning tensor for the `RaggedTensor` being</span>
<span class="sd">        constructed.  I.e., one of: row_splits, row_lengths, row_starts,</span>
<span class="sd">        row_limits, value_rowids.</span>
<span class="sd">      name: The name of the row-partitioning tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A tuple (values, partition).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">partition</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">partition</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> must have dtype int32 or int64&quot;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">values</span><span class="o">.</span><span class="n">row_splits</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">partition</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
          <span class="k">if</span> <span class="ow">not</span> <span class="n">ragged_config</span><span class="o">.</span><span class="n">auto_cast_partition_dtype</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;dtype mismatch: </span><span class="si">%s</span><span class="s2"> (</span><span class="si">%s</span><span class="s2">) vs values.row_splits (</span><span class="si">%s</span><span class="s2">)&quot;</span>
                             <span class="o">%</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">partition</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">values</span><span class="o">.</span><span class="n">row_splits</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
          <span class="n">partition</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">partition</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
          <span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">with_row_splits_dtype</span><span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">partition</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">partition</span><span class="p">,</span> <span class="n">values</span><span class="o">.</span><span class="n">row_splits</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                                          <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">values</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">partition</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">partition</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">:</span>
        <span class="n">partition</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">partition</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">partition</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
            <span class="n">partition</span><span class="p">,</span> <span class="n">preferred_dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">partition</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> must have dtype int32 or int64&quot;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">partition</span><span class="p">)</span>

  <span class="c1">#=============================================================================</span>
  <span class="c1"># Accessors</span>
  <span class="c1">#=============================================================================</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The `DType` of values in this tensor.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_values</span><span class="o">.</span><span class="n">dtype</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The statically known shape of this ragged tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `TensorShape` containing the statically known shape of this ragged</span>
<span class="sd">      tensor.  Ragged dimensions have a size of `None`.</span>

<span class="sd">    Examples:</span>

<span class="sd">    &gt;&gt;&gt; tf.ragged.constant([[0], [1, 2]]).shape</span>
<span class="sd">    TensorShape([2, None])</span>

<span class="sd">    &gt;&gt;&gt; tf.ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).shape</span>
<span class="sd">    TensorShape([2, None, 2])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nrows</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_at_index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_row_splits</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uniform_row_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">row_length</span> <span class="o">=</span> <span class="n">tensor_util</span><span class="o">.</span><span class="n">constant_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_uniform_row_length</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">row_length</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">values_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_values</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">value_shape</span> <span class="o">=</span> <span class="n">values_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="k">return</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="n">nrows</span><span class="p">,</span>
                                     <span class="n">row_length</span><span class="p">])</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">value_shape</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">ragged_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The number of ragged dimensions in this ragged tensor.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A Python `int` indicating the number of ragged dimensions in this ragged</span>
<span class="sd">      tensor.  The outermost dimension is not considered ragged.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">values_is_ragged</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_values</span><span class="o">.</span><span class="n">ragged_rank</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">values_is_ragged</span> <span class="k">else</span> <span class="mi">1</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The concatenated rows for this ragged tensor.</span>

<span class="sd">    `rt.values` is a potentially ragged tensor formed by flattening the two</span>
<span class="sd">    outermost dimensions of `rt` into a single dimension.</span>

<span class="sd">    `rt.values.shape = [nvals] + rt.shape[2:]` (where `nvals` is the</span>
<span class="sd">    number of items in the outer two dimensions of `rt`).</span>

<span class="sd">    `rt.ragged_rank = self.ragged_rank - 1`</span>

<span class="sd">    Returns:</span>
<span class="sd">      A potentially ragged tensor.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])</span>
<span class="sd">    &gt;&gt;&gt; print(rt.values)</span>
<span class="sd">    tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_values</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">row_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The row-split indices for this ragged tensor&#39;s `values`.</span>

<span class="sd">    `rt.row_splits` specifies where the values for each row begin and end in</span>
<span class="sd">    `rt.values`.  In particular, the values for row `rt[i]` are stored in</span>
<span class="sd">    the slice `rt.values[rt.row_splits[i]:rt.row_splits[i+1]]`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A 1-D integer `Tensor` with shape `[self.nrows+1]`.</span>
<span class="sd">      The returned tensor is non-empty, and is sorted in ascending order.</span>
<span class="sd">      `self.row_splits[0]` is zero, and `self.row_splits[-1]` is equal to</span>
<span class="sd">      `self.values.shape[0]`.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])</span>
<span class="sd">    &gt;&gt;&gt; print(rt.row_splits)  # indices of row splits in rt.values</span>
<span class="sd">    tf.Tensor([0 4 4 7 8 8], shape=(6,), dtype=int64)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">uniform_row_length</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The length of each row in this ragged tensor, or None if rows are ragged.</span>

<span class="sd">    &gt;&gt;&gt; rt1 = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])</span>
<span class="sd">    &gt;&gt;&gt; print(rt1.uniform_row_length)  # rows are ragged.</span>
<span class="sd">    None</span>

<span class="sd">    &gt;&gt;&gt; rt2 = tf.RaggedTensor.from_uniform_row_length(</span>
<span class="sd">    ...     values=rt1, uniform_row_length=2)</span>
<span class="sd">    &gt;&gt;&gt; print(rt2)</span>
<span class="sd">    &lt;tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]&gt;</span>
<span class="sd">    &gt;&gt;&gt; print(rt2.uniform_row_length)  # rows are not ragged (all have size 2).</span>
<span class="sd">    tf.Tensor(2, shape=(), dtype=int64)</span>

<span class="sd">    A RaggedTensor&#39;s rows are only considered to be uniform (i.e. non-ragged)</span>
<span class="sd">    if it can be determined statically (at graph construction time) that the</span>
<span class="sd">    rows all have the same length.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A scalar integer `Tensor`, specifying the length of every row in this</span>
<span class="sd">      ragged tensor (for ragged tensors whose rows are uniform); or `None`</span>
<span class="sd">      (for ragged tensors whose rows are ragged).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uniform_row_length</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">flat_values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The innermost `values` tensor for this ragged tensor.</span>

<span class="sd">    Concretely, if `rt.values` is a `Tensor`, then `rt.flat_values` is</span>
<span class="sd">    `rt.values`; otherwise, `rt.flat_values` is `rt.values.flat_values`.</span>

<span class="sd">    Conceptually, `flat_values` is the tensor formed by flattening the</span>
<span class="sd">    outermost dimension and all of the ragged dimensions into a single</span>
<span class="sd">    dimension.</span>

<span class="sd">    `rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:]`</span>
<span class="sd">    (where `nvals` is the number of items in the flattened dimensions).</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `Tensor`.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]])</span>
<span class="sd">    &gt;&gt;&gt; print(rt.flat_values)</span>
<span class="sd">    tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rt_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">values</span>
    <span class="k">while</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rt_values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
      <span class="n">rt_values</span> <span class="o">=</span> <span class="n">rt_values</span><span class="o">.</span><span class="n">values</span>
    <span class="k">return</span> <span class="n">rt_values</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">nested_row_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A tuple containing the row_splits for all ragged dimensions.</span>

<span class="sd">    `rt.nested_row_splits` is a tuple containing the `row_splits` tensors for</span>
<span class="sd">    all ragged dimensions in `rt`, ordered from outermost to innermost.  In</span>
<span class="sd">    particular, `rt.nested_row_splits = (rt.row_splits,) + value_splits` where:</span>

<span class="sd">        * `value_splits = ()` if `rt.values` is a `Tensor`.</span>
<span class="sd">        * `value_splits = rt.values.nested_row_splits` otherwise.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `tuple` of 1-D integer `Tensor`s.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant(</span>
<span class="sd">    ...     [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])</span>
<span class="sd">    &gt;&gt;&gt; for i, splits in enumerate(rt.nested_row_splits):</span>
<span class="sd">    ...   print(&#39;Splits for dimension %d: %s&#39; % (i+1, splits.numpy()))</span>
<span class="sd">    Splits for dimension 1: [0 3]</span>
<span class="sd">    Splits for dimension 2: [0 3 3 5]</span>
<span class="sd">    Splits for dimension 3: [0 4 4 7 8 8]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rt_nested_splits</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">row_splits</span><span class="p">]</span>
    <span class="n">rt_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">values</span>
    <span class="k">while</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rt_values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
      <span class="n">rt_nested_splits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rt_values</span><span class="o">.</span><span class="n">row_splits</span><span class="p">)</span>
      <span class="n">rt_values</span> <span class="o">=</span> <span class="n">rt_values</span><span class="o">.</span><span class="n">values</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">rt_nested_splits</span><span class="p">)</span>

<div class="viewcode-block" id="RaggedTensor.value_rowids"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.value_rowids">[docs]</a>  <span class="k">def</span> <span class="nf">value_rowids</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the row indices for the `values` in this ragged tensor.</span>

<span class="sd">    `rt.value_rowids()` corresponds one-to-one with the outermost dimension of</span>
<span class="sd">    `rt.values`, and specifies the row containing each value.  In particular,</span>
<span class="sd">    the row `rt[row]` consists of the values `rt.values[j]` where</span>
<span class="sd">    `rt.value_rowids()[j] == row`.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: A name prefix for the returned tensor (optional).</span>

<span class="sd">    Returns:</span>
<span class="sd">      A 1-D integer `Tensor` with shape `self.values.shape[:1]`.</span>
<span class="sd">      The returned tensor is nonnegative, and is sorted in ascending order.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])</span>
<span class="sd">    &gt;&gt;&gt; print(rt.values)</span>
<span class="sd">    tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)</span>
<span class="sd">    &gt;&gt;&gt; print(rt.value_rowids())  # corresponds 1:1 with rt.values</span>
<span class="sd">    tf.Tensor([0 0 0 0 2 2 2 3], shape=(8,), dtype=int64)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_value_rowids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_value_rowids</span>

    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedValueRowIds&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="p">]):</span>
      <span class="k">return</span> <span class="n">segment_id_ops</span><span class="o">.</span><span class="n">row_splits_to_segment_ids</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_splits</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.nested_value_rowids"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.nested_value_rowids">[docs]</a>  <span class="k">def</span> <span class="nf">nested_value_rowids</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a tuple containing the value_rowids for all ragged dimensions.</span>

<span class="sd">    `rt.nested_value_rowids` is a tuple containing the `value_rowids` tensors</span>
<span class="sd">    for</span>
<span class="sd">    all ragged dimensions in `rt`, ordered from outermost to innermost.  In</span>
<span class="sd">    particular, `rt.nested_value_rowids = (rt.value_rowids(),) + value_ids`</span>
<span class="sd">    where:</span>

<span class="sd">        * `value_ids = ()` if `rt.values` is a `Tensor`.</span>
<span class="sd">        * `value_ids = rt.values.nested_value_rowids` otherwise.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: A name prefix for the returned tensors (optional).</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `tuple` of 1-D integer `Tensor`s.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant(</span>
<span class="sd">    ...     [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])</span>
<span class="sd">    &gt;&gt;&gt; for i, ids in enumerate(rt.nested_value_rowids()):</span>
<span class="sd">    ...   print(&#39;row ids for dimension %d: %s&#39; % (i+1, ids.numpy()))</span>
<span class="sd">    row ids for dimension 1: [0 0 0]</span>
<span class="sd">    row ids for dimension 2: [0 0 0 2 2]</span>
<span class="sd">    row ids for dimension 3: [0 0 0 0 2 2 2 3]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedNestedValueRowIds&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="p">]):</span>
      <span class="n">rt_nested_ids</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">value_rowids</span><span class="p">()]</span>
      <span class="n">rt_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">values</span>
      <span class="k">while</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rt_values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
        <span class="n">rt_nested_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rt_values</span><span class="o">.</span><span class="n">value_rowids</span><span class="p">())</span>
        <span class="n">rt_values</span> <span class="o">=</span> <span class="n">rt_values</span><span class="o">.</span><span class="n">values</span>
      <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">rt_nested_ids</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.nrows"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.nrows">[docs]</a>  <span class="k">def</span> <span class="nf">nrows</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the number of rows in this ragged tensor.</span>

<span class="sd">    I.e., the size of the outermost dimension of the tensor.</span>

<span class="sd">    Args:</span>
<span class="sd">      out_type: `dtype` for the returned tensor.  Defaults to</span>
<span class="sd">        `self.row_splits.dtype`.</span>
<span class="sd">      name: A name prefix for the returned tensor (optional).</span>

<span class="sd">    Returns:</span>
<span class="sd">      A scalar `Tensor` with dtype `out_type`.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])</span>
<span class="sd">    &gt;&gt;&gt; print(rt.nrows())  # rt has 5 rows.</span>
<span class="sd">    tf.Tensor(5, shape=(), dtype=int64)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">out_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">out_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">out_type</span> <span class="o">=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">out_type</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_nrows</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cached_nrows</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedNRows&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="p">]):</span>
      <span class="n">nsplits</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_at_index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_splits</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">nsplits</span><span class="o">.</span><span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_splits</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">nsplits</span><span class="o">.</span><span class="n">value</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">out_type</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.row_starts"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.row_starts">[docs]</a>  <span class="k">def</span> <span class="nf">row_starts</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the start indices for rows in this ragged tensor.</span>

<span class="sd">    These indices specify where the values for each row begin in</span>
<span class="sd">    `self.values`.  `rt.row_starts()` is equal to `rt.row_splits[:-1]`.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: A name prefix for the returned tensor (optional).</span>

<span class="sd">    Returns:</span>
<span class="sd">      A 1-D integer Tensor with shape `[nrows]`.</span>
<span class="sd">      The returned tensor is nonnegative, and is sorted in ascending order.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])</span>
<span class="sd">    &gt;&gt;&gt; print(rt.values)</span>
<span class="sd">    tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)</span>
<span class="sd">    &gt;&gt;&gt; print(rt.row_starts())  # indices of row starts in rt.values</span>
<span class="sd">    tf.Tensor([0 4 4 7 8], shape=(5,), dtype=int64)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedRowStarts&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="p">]):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_splits</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span></div>

<div class="viewcode-block" id="RaggedTensor.row_limits"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.row_limits">[docs]</a>  <span class="k">def</span> <span class="nf">row_limits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the limit indices for rows in this ragged tensor.</span>

<span class="sd">    These indices specify where the values for each row end in</span>
<span class="sd">    `self.values`.  `rt.row_limits(self)` is equal to `rt.row_splits[:-1]`.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: A name prefix for the returned tensor (optional).</span>

<span class="sd">    Returns:</span>
<span class="sd">      A 1-D integer Tensor with shape `[nrows]`.</span>
<span class="sd">      The returned tensor is nonnegative, and is sorted in ascending order.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])</span>
<span class="sd">    &gt;&gt;&gt; print(rt.values)</span>
<span class="sd">    tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)</span>
<span class="sd">    &gt;&gt;&gt; print(rt.row_limits())  # indices of row limits in rt.values</span>
<span class="sd">    tf.Tensor([4 4 7 8 8], shape=(5,), dtype=int64)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedRowLimits&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="p">]):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_splits</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span></div>

<div class="viewcode-block" id="RaggedTensor.row_lengths"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.row_lengths">[docs]</a>  <span class="k">def</span> <span class="nf">row_lengths</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the lengths of the rows in this ragged tensor.</span>

<span class="sd">    `rt.row_lengths()[i]` indicates the number of values in the</span>
<span class="sd">    `i`th row of `rt`.</span>

<span class="sd">    Args:</span>
<span class="sd">      axis: An integer constant indicating the axis whose row lengths should be</span>
<span class="sd">        returned.</span>
<span class="sd">      name: A name prefix for the returned tensor (optional).</span>

<span class="sd">    Returns:</span>
<span class="sd">      A potentially ragged integer Tensor with shape `self.shape[:axis]`.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If `axis` is out of bounds.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant(</span>
<span class="sd">    ...     [[[3, 1, 4], [1]], [], [[5, 9], [2]], [[6]], []])</span>
<span class="sd">    &gt;&gt;&gt; print(rt.row_lengths())  # lengths of rows in rt</span>
<span class="sd">    tf.Tensor([2 0 2 1 0], shape=(5,), dtype=int64)</span>
<span class="sd">    &gt;&gt;&gt; print(rt.row_lengths(axis=2))  # lengths of axis=2 rows.</span>
<span class="sd">    &lt;tf.RaggedTensor [[3, 1], [], [2, 1], [1], []]&gt;</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_row_lengths</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_row_lengths</span>

    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedRowLengths&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="p">]):</span>
      <span class="n">axis</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">get_positive_axis</span><span class="p">(</span>
          <span class="n">axis</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="n">ndims_name</span><span class="o">=</span><span class="s2">&quot;rank(self)&quot;</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">nrows</span><span class="p">()</span>
      <span class="k">elif</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">splits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">row_splits</span>
        <span class="k">return</span> <span class="n">splits</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">splits</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_values</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">row_lengths</span><span class="p">(</span><span class="n">axis</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_row_splits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_values</span><span class="p">(</span>
            <span class="n">array_ops</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">[:</span><span class="n">axis</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span>
            <span class="n">shape</span><span class="p">[</span><span class="n">axis</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span></div>

<div class="viewcode-block" id="RaggedTensor.nested_row_lengths"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.nested_row_lengths">[docs]</a>  <span class="k">def</span> <span class="nf">nested_row_lengths</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a tuple containing the row_lengths for all ragged dimensions.</span>

<span class="sd">    `rt.nested_row_lengths()` is a tuple containing the `row_lengths` tensors</span>
<span class="sd">    for all ragged dimensions in `rt`, ordered from outermost to innermost.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: A name prefix for the returned tensors (optional).</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `tuple` of 1-D integer `Tensors`.  The length of the tuple is equal to</span>
<span class="sd">      `self.ragged_rank`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedNestedRowLengths&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="p">]):</span>
      <span class="n">rt_nested_row_lengths</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">rt</span> <span class="o">=</span> <span class="bp">self</span>
      <span class="k">while</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rt</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
        <span class="n">rt_nested_row_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rt</span><span class="o">.</span><span class="n">row_lengths</span><span class="p">())</span>
        <span class="n">rt</span> <span class="o">=</span> <span class="n">rt</span><span class="o">.</span><span class="n">values</span>
      <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">rt_nested_row_lengths</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.bounding_shape"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.bounding_shape">[docs]</a>  <span class="k">def</span> <span class="nf">bounding_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the tight bounding box shape for this `RaggedTensor`.</span>

<span class="sd">    Args:</span>
<span class="sd">      axis: An integer scalar or vector indicating which axes to return the</span>
<span class="sd">        bounding box for.  If not specified, then the full bounding box is</span>
<span class="sd">        returned.</span>
<span class="sd">      name: A name prefix for the returned tensor (optional).</span>
<span class="sd">      out_type: `dtype` for the returned tensor.  Defaults to</span>
<span class="sd">        `self.row_splits.dtype`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      An integer `Tensor` (`dtype=self.row_splits.dtype`).  If `axis` is not</span>
<span class="sd">      specified, then `output` is a vector with</span>
<span class="sd">      `output.shape=[self.shape.ndims]`.  If `axis` is a scalar, then the</span>
<span class="sd">      `output` is a scalar.  If `axis` is a vector, then `output` is a vector,</span>
<span class="sd">      where `output[i]` is the bounding size for dimension `axis[i]`.</span>

<span class="sd">    #### Example:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant([[1, 2, 3, 4], [5], [], [6, 7, 8, 9], [10]])</span>
<span class="sd">    &gt;&gt;&gt; rt.bounding_shape().numpy()</span>
<span class="sd">    array([5, 4])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">out_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">out_type</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">out_type</span> <span class="o">=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">out_type</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedBoundingBox&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">]):</span>
      <span class="n">nested_splits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nested_row_splits</span>
      <span class="n">rt_flat_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span>

      <span class="c1"># Optimized special cases for when axis=0 or axis=1:</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">nested_splits</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">axis</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_lengths</span><span class="p">()),</span> <span class="mi">0</span><span class="p">)</span>

      <span class="n">splits_shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">row_splits</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">)</span>
      <span class="n">flat_values_shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">rt_flat_values</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">)</span>

      <span class="n">ragged_dimensions</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">splits_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
          <span class="n">math_ops</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">splits</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">splits</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="mi">0</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">splits</span> <span class="ow">in</span> <span class="n">nested_splits</span>
      <span class="p">])</span>
      <span class="n">inner_dimensions</span> <span class="o">=</span> <span class="n">flat_values_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

      <span class="n">bbox</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">ragged_dimensions</span><span class="p">,</span> <span class="n">inner_dimensions</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">bbox</span> <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">bbox</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span></div>

  <span class="c1">#=============================================================================</span>
  <span class="c1"># Transformation</span>
  <span class="c1">#=============================================================================</span>

<div class="viewcode-block" id="RaggedTensor.with_values"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.with_values">[docs]</a>  <span class="k">def</span> <span class="nf">with_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_values</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a copy of `self` with `values` replaced by `new_value`.</span>

<span class="sd">    Preserves cached row-partitioning tensors such as `self.cached_nrows` and</span>
<span class="sd">    `self.cached_value_rowids` if they have values.</span>

<span class="sd">    Args:</span>
<span class="sd">      new_values: Potentially ragged tensor to use as the `values` for the</span>
<span class="sd">        returned `RaggedTensor`.  Must have `rank &gt; 0`, and must have the same</span>
<span class="sd">        number of rows as `self.values`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `RaggedTensor`.  `result.rank = 1 + new_values.rank`.</span>
<span class="sd">      `result.ragged_rank = 1 + new_values.ragged_rank`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_values</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">with_rank_at_least</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">assert_is_compatible_with</span><span class="p">(</span><span class="n">new_values</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">new_values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">)</span> <span class="ow">and</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">new_values</span><span class="o">.</span><span class="n">row_splits</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">ragged_config</span><span class="o">.</span><span class="n">auto_cast_partition_dtype</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;self and new_values have mismatched row_splits &quot;</span>
                         <span class="s2">&quot;dtypes; use RaggedTensor.with_row_splits_dtype() to &quot;</span>
                         <span class="s2">&quot;convert them to compatible dtypes.&quot;</span><span class="p">)</span>
      <span class="n">new_values</span> <span class="o">=</span> <span class="n">new_values</span><span class="o">.</span><span class="n">with_row_splits_dtype</span><span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_row_splits_dtype</span><span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">with_values</span><span class="p">(</span><span class="n">new_values</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">RaggedTensor</span><span class="p">(</span>
        <span class="n">values</span><span class="o">=</span><span class="n">new_values</span><span class="p">,</span>
        <span class="n">row_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_row_splits</span><span class="p">,</span>
        <span class="n">cached_row_lengths</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cached_row_lengths</span><span class="p">,</span>
        <span class="n">cached_value_rowids</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cached_value_rowids</span><span class="p">,</span>
        <span class="n">cached_nrows</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_cached_nrows</span><span class="p">,</span>
        <span class="n">internal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">uniform_row_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_uniform_row_length</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.with_flat_values"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.with_flat_values">[docs]</a>  <span class="k">def</span> <span class="nf">with_flat_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_values</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a copy of `self` with `flat_values` replaced by `new_value`.</span>

<span class="sd">    Preserves cached row-partitioning tensors such as `self.cached_nrows` and</span>
<span class="sd">    `self.cached_value_rowids` if they have values.</span>

<span class="sd">    Args:</span>
<span class="sd">      new_values: Potentially ragged tensor that should replace</span>
<span class="sd">      `self.flat_values`.  Must have `rank &gt; 0`, and must have the same</span>
<span class="sd">      number of rows as `self.flat_values`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `RaggedTensor`.</span>
<span class="sd">      `result.rank = self.ragged_rank + new_values.rank`.</span>
<span class="sd">      `result.ragged_rank = self.ragged_rank + new_values.ragged_rank`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_values</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_values</span><span class="p">(</span><span class="n">new_values</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_values</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">with_flat_values</span><span class="p">(</span><span class="n">new_values</span><span class="p">))</span></div>

<div class="viewcode-block" id="RaggedTensor.with_row_splits_dtype"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.with_row_splits_dtype">[docs]</a>  <span class="k">def</span> <span class="nf">with_row_splits_dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a copy of this RaggedTensor with the given `row_splits` dtype.</span>

<span class="sd">    For RaggedTensors with multiple ragged dimensions, the `row_splits` for all</span>
<span class="sd">    nested `RaggedTensor` objects are cast to the given dtype.</span>

<span class="sd">    Args:</span>
<span class="sd">      dtype: The dtype for `row_splits`.  One of `tf.int32` or `tf.int64`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A copy of this RaggedTensor, with the `row_splits` cast to the given</span>
<span class="sd">      type.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;dtype must be int32 or int64&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">dtype</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span>

    <span class="n">row_splits</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_row_splits</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>

    <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_values</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
      <span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">with_row_splits_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">cached_row_lengths</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_row_lengths</span>
    <span class="k">if</span> <span class="n">cached_row_lengths</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">cached_row_lengths</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">cached_row_lengths</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">cached_value_rowids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_value_rowids</span>
    <span class="k">if</span> <span class="n">cached_value_rowids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">cached_value_rowids</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">cached_value_rowids</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">cached_nrows</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_nrows</span>
    <span class="k">if</span> <span class="n">cached_value_rowids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">cached_value_rowids</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">cached_value_rowids</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">uniform_row_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uniform_row_length</span>
    <span class="k">if</span> <span class="n">uniform_row_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">uniform_row_length</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">uniform_row_length</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">RaggedTensor</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">row_splits</span><span class="p">,</span> <span class="n">cached_row_lengths</span><span class="p">,</span>
                        <span class="n">cached_value_rowids</span><span class="p">,</span> <span class="n">cached_nrows</span><span class="p">,</span> <span class="n">internal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">uniform_row_length</span><span class="o">=</span><span class="n">uniform_row_length</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.merge_dims"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.merge_dims">[docs]</a>  <span class="k">def</span> <span class="nf">merge_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outer_axis</span><span class="p">,</span> <span class="n">inner_axis</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Merges outer_axis...inner_axis into a single dimension.</span>

<span class="sd">    Returns a copy of this RaggedTensor with the specified range of dimensions</span>
<span class="sd">    flattened into a single dimension, with elements in row-major order.</span>

<span class="sd">    #### Examples:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant([[[1, 2], [3]], [[4, 5, 6]]])</span>
<span class="sd">    &gt;&gt;&gt; print(rt.merge_dims(0, 1))</span>
<span class="sd">    &lt;tf.RaggedTensor [[1, 2], [3], [4, 5, 6]]&gt;</span>
<span class="sd">    &gt;&gt;&gt; print(rt.merge_dims(1, 2))</span>
<span class="sd">    &lt;tf.RaggedTensor [[1, 2, 3], [4, 5, 6]]&gt;</span>
<span class="sd">    &gt;&gt;&gt; print(rt.merge_dims(0, 2))</span>
<span class="sd">    tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32)</span>

<span class="sd">    To mimic the behavior of `np.flatten` (which flattens all dimensions), use</span>
<span class="sd">    `rt.merge_dims(0, -1).  To mimic the behavior of `tf.layers.Flatten` (which</span>
<span class="sd">    flattens all dimensions except the outermost batch dimension), use</span>
<span class="sd">    `rt.merge_dims(1, -1)`.</span>

<span class="sd">    Args:</span>
<span class="sd">      outer_axis: `int`: The first dimension in the range of dimensions to</span>
<span class="sd">        merge. May be negative if `self.shape.rank` is statically known.</span>
<span class="sd">      inner_axis: `int`: The last dimension in the range of dimensions to</span>
<span class="sd">        merge. May be negative if `self.shape.rank` is statically known.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A copy of this tensor, with the specified dimensions merged into a</span>
<span class="sd">      single dimension.  The shape of the returned tensor will be</span>
<span class="sd">      `self.shape[:outer_axis] + [N] + self.shape[inner_axis + 1:]`, where `N`</span>
<span class="sd">      is the total number of slices in the merged dimensions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">outer_axis</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">get_positive_axis</span><span class="p">(</span>
        <span class="n">outer_axis</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span>
        <span class="n">axis_name</span><span class="o">=</span><span class="s2">&quot;outer_axis&quot;</span><span class="p">,</span>
        <span class="n">ndims_name</span><span class="o">=</span><span class="s2">&quot;rank(self)&quot;</span><span class="p">)</span>
    <span class="n">inner_axis</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">get_positive_axis</span><span class="p">(</span>
        <span class="n">inner_axis</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span>
        <span class="n">axis_name</span><span class="o">=</span><span class="s2">&quot;inner_axis&quot;</span><span class="p">,</span>
        <span class="n">ndims_name</span><span class="o">=</span><span class="s2">&quot;rank(self)&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">outer_axis</span> <span class="o">&lt;</span> <span class="n">inner_axis</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Expected outer_axis (</span><span class="si">%d</span><span class="s2">) to be less than &quot;</span>
                       <span class="s2">&quot;inner_axis (</span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">outer_axis</span><span class="p">,</span> <span class="n">inner_axis</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">_merge_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outer_axis</span><span class="p">,</span> <span class="n">inner_axis</span><span class="p">)</span></div>


<span class="c1">#=============================================================================</span>
<span class="c1"># Tensor Type Conversions</span>
<span class="c1">#=============================================================================</span>

<div class="viewcode-block" id="RaggedTensor.from_tensor"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.from_tensor">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">from_tensor</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span>
                  <span class="n">tensor</span><span class="p">,</span>
                  <span class="n">lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">padding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">ragged_rank</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                  <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                  <span class="n">row_splits_dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts a `tf.Tensor` into a `RaggedTensor`.</span>

<span class="sd">    The set of absent/default values may be specified using a vector of lengths</span>
<span class="sd">    or a padding value (but not both).  If `lengths` is specified, then the</span>
<span class="sd">    output tensor will satisfy `output[row] = tensor[row][:lengths[row]]`. If</span>
<span class="sd">    &#39;lengths&#39; is a list of lists or tuple of lists, those lists will be used</span>
<span class="sd">    as nested row lengths. If `padding` is specified, then any row *suffix*</span>
<span class="sd">    consisting entirely of `padding` will be excluded from the returned</span>
<span class="sd">    `RaggedTensor`.  If neither `lengths` nor `padding` is specified, then the</span>
<span class="sd">    returned `RaggedTensor` will have no absent/default values.</span>

<span class="sd">    Examples:</span>

<span class="sd">    &gt;&gt;&gt; dt = tf.constant([[5, 7, 0], [0, 3, 0], [6, 0, 0]])</span>
<span class="sd">    &gt;&gt;&gt; tf.RaggedTensor.from_tensor(dt)</span>
<span class="sd">    &lt;tf.RaggedTensor [[5, 7, 0], [0, 3, 0], [6, 0, 0]]&gt;</span>
<span class="sd">    &gt;&gt;&gt; tf.RaggedTensor.from_tensor(dt, lengths=[1, 0, 3])</span>
<span class="sd">    &lt;tf.RaggedTensor [[5], [], [6, 0, 0]]&gt;</span>

<span class="sd">    &gt;&gt;&gt; tf.RaggedTensor.from_tensor(dt, padding=0)</span>
<span class="sd">    &lt;tf.RaggedTensor [[5, 7], [0, 3], [6]]&gt;</span>

<span class="sd">    &gt;&gt;&gt; dt = tf.constant([[[5, 0], [7, 0], [0, 0]],</span>
<span class="sd">    ...                   [[0, 0], [3, 0], [0, 0]],</span>
<span class="sd">    ...                   [[6, 0], [0, 0], [0, 0]]])</span>
<span class="sd">    &gt;&gt;&gt; tf.RaggedTensor.from_tensor(dt, lengths=([2, 0, 3], [1, 1, 2, 0, 1]))</span>
<span class="sd">    &lt;tf.RaggedTensor [[[5], [7]], [], [[6, 0], [], [0]]]&gt;</span>

<span class="sd">    Args:</span>
<span class="sd">      tensor: The `Tensor` to convert.  Must have rank `ragged_rank + 1` or</span>
<span class="sd">        higher.</span>
<span class="sd">      lengths: An optional set of row lengths, specified using a 1-D integer</span>
<span class="sd">        `Tensor` whose length is equal to `tensor.shape[0]` (the number of rows</span>
<span class="sd">        in `tensor`).  If specified, then `output[row]` will contain</span>
<span class="sd">        `tensor[row][:lengths[row]]`.  Negative lengths are treated as zero. You</span>
<span class="sd">        may optionally pass a list or tuple of lengths to this argument, which</span>
<span class="sd">        will be used as nested row lengths to construct a ragged tensor with</span>
<span class="sd">        multiple ragged dimensions.</span>
<span class="sd">      padding: An optional padding value.  If specified, then any row suffix</span>
<span class="sd">        consisting entirely of `padding` will be excluded from the returned</span>
<span class="sd">        RaggedTensor.  `padding` is a `Tensor` with the same dtype as `tensor`</span>
<span class="sd">        and with `shape=tensor.shape[ragged_rank + 1:]`.</span>
<span class="sd">      ragged_rank: Integer specifying the ragged rank for the returned</span>
<span class="sd">        `RaggedTensor`.  Must be greater than zero.</span>
<span class="sd">      name: A name prefix for the returned tensors (optional).</span>
<span class="sd">      row_splits_dtype: `dtype` for the returned `RaggedTensor`&#39;s `row_splits`</span>
<span class="sd">        tensor.  One of `tf.int32` or `tf.int64`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `RaggedTensor` with the specified `ragged_rank`.  The shape of the</span>
<span class="sd">      returned ragged tensor is compatible with the shape of `tensor`.</span>
<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If both `lengths` and `padding` are specified.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">row_splits_dtype</span> <span class="o">=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">row_splits_dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">lengths</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">padding</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Specify lengths or padding, but not both&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ragged_rank</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;ragged_rank expected int, got </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">ragged_rank</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ragged_rank</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s2">&quot;ragged_rank must be greater than 0; got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">ragged_rank</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedFromTensor&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">tensor</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">padding</span><span class="p">]):</span>
      <span class="n">tensor</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;tensor&quot;</span><span class="p">)</span>
      <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">with_rank_at_least</span><span class="p">(</span><span class="n">ragged_rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">input_shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">row_splits_dtype</span><span class="p">)</span>
      <span class="n">ncols</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

      <span class="c1"># Handle nested row lengths.</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">lengths</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span>
          <span class="nb">len</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lengths</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">))):</span>
        <span class="k">if</span> <span class="n">ragged_rank</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lengths</span><span class="p">)):</span>
          <span class="c1"># Note: we accept `ragged_rank=1` here because it&#39;s the default value;</span>
          <span class="c1"># i.e., if the user passes in a tuple of lengths, but doesn&#39;t specify</span>
          <span class="c1"># ragged_rank, then we should use that tuple to determine ragged_rank.</span>
          <span class="c1"># We only want to complain if they pass in an explicit ragged_rank</span>
          <span class="c1"># that doesn&#39;t match len(lengths).</span>
          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;If lengths is a tuple of row_lengths, then &quot;</span>
                           <span class="s2">&quot;ragged_rank must be len(lengths).&quot;</span><span class="p">)</span>
        <span class="c1"># Rather than reconstructing the tensor mask directly, we can</span>
        <span class="c1"># recreate it as a boolean RaggedTensor, then densify that and use</span>
        <span class="c1"># that as the mask to clear out the unused data in the passed tensor.</span>
        <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">with_rank_at_least</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">num_tokens</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">lengths</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">ones_mask</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">num_tokens</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
        <span class="n">ragged_mask</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_nested_row_lengths</span><span class="p">(</span>
            <span class="n">ones_mask</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">dense_ragged_mask</span> <span class="o">=</span> <span class="n">ragged_mask</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">default_value</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">masked_data</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dense_ragged_mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_nested_row_lengths</span><span class="p">(</span>
            <span class="n">masked_data</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

      <span class="c1"># Handle ragged_rank&gt;1 via recursion:</span>
      <span class="c1"># If the output should have multiple ragged dimensions, then first</span>
      <span class="c1"># flatten the tensor to eliminate all but the last ragged dimension,</span>
      <span class="c1"># and recursively convert that flattened tensor.  Then add on the splits</span>
      <span class="c1"># for the dimensions that we flattened out.</span>
      <span class="k">if</span> <span class="n">ragged_rank</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">is_fully_defined</span><span class="p">():</span>
          <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
          <span class="n">new_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">input_shape</span><span class="p">[</span><span class="n">ragged_rank</span><span class="p">:]</span>
          <span class="c1"># The total number of elements in each  dimension.  E.g., if</span>
          <span class="c1"># input_shape=[3, 4, 5, 6], then dim[2] has 3*4*5 elements in total.</span>
          <span class="n">dim_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">neg_one</span> <span class="o">=</span> <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">row_splits_dtype</span><span class="p">)</span>
          <span class="n">new_shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">neg_one</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">[</span><span class="n">ragged_rank</span><span class="p">:]],</span>
                                       <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
          <span class="n">dim_size</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
        <span class="n">flattened</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_tensor</span><span class="p">(</span><span class="n">flattened</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span>
                                 <span class="n">row_splits_dtype</span><span class="o">=</span><span class="n">row_splits_dtype</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ragged_rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
          <span class="n">dim_len</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_at_index</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span><span class="o">.</span><span class="n">value</span>
          <span class="k">if</span> <span class="n">dim_len</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dim_len</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">dim_len</span> <span class="o">=</span> <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">dim_len</span><span class="p">,</span> <span class="n">row_splits_dtype</span><span class="p">)</span>
          <span class="n">result</span> <span class="o">=</span> <span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_uniform_row_length</span><span class="p">(</span>
              <span class="n">values</span><span class="o">=</span><span class="n">result</span><span class="p">,</span>
              <span class="n">uniform_row_length</span><span class="o">=</span><span class="n">dim_len</span><span class="p">,</span>
              <span class="n">nrows</span><span class="o">=</span><span class="n">dim_size</span><span class="p">[</span><span class="n">axis</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span>
              <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span>

      <span class="c1"># If padding was specified, then use it to find row lengths.</span>
      <span class="k">if</span> <span class="n">padding</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
            <span class="n">padding</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;padding&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">padding</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">assert_is_compatible_with</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>

        <span class="c1"># Find places where the padding is equal to the tensor.  (This will</span>
        <span class="c1"># broadcast `padding` across the outermost 2 dimensions of `tensor`,</span>
        <span class="c1"># so `has_default_value.shape = tensor.shape`.)</span>
        <span class="n">has_default_value</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>

        <span class="c1"># If the padding isn&#39;t a scalar, then require that all values in the</span>
        <span class="c1"># padding match each item in the tensor.  After this block of code,</span>
        <span class="c1"># `has_default.shape = tensor.shape[:2]`.  (Unfortunately, we can&#39;t just</span>
        <span class="c1"># use reduce_all for both cases, because when you pass an empty `axis`</span>
        <span class="c1"># list to reduce_all, it reduces all axes; but we want it to reduce no</span>
        <span class="c1"># axes -- i.e., to be a no-op.)</span>
        <span class="n">tensor_rank</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
        <span class="n">reduce_axis</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">tensor_rank</span><span class="p">)</span>
        <span class="n">has_default</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span>
            <span class="n">tensor_rank</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">,</span>
            <span class="k">lambda</span><span class="p">:</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">has_default_value</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">reduce_axis</span><span class="p">),</span>
            <span class="k">lambda</span><span class="p">:</span> <span class="n">has_default_value</span><span class="p">)</span>
        <span class="n">has_default</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]))</span>
        <span class="n">has_default</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>

        <span class="c1"># Use has_default to find the length of each row: for each</span>
        <span class="c1"># non-default item in a row, calculate the length that the row needs to</span>
        <span class="c1"># have to include that item; and then take the max of those values</span>
        <span class="c1"># (across each row).</span>
        <span class="n">has_nondefault</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">has_default</span><span class="p">)</span>
        <span class="n">has_nondefault</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">has_nondefault</span><span class="p">,</span> <span class="n">row_splits_dtype</span><span class="p">)</span>
        <span class="n">length_for_nondefault_value</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">has_nondefault</span> <span class="o">*</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
                <span class="n">math_ops</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">))</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">length_for_nondefault_value</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">lengths</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># If we have lengths (either directly supplied, or computed from</span>
        <span class="c1"># paddings), then use those to construct splits; and then use masking</span>
        <span class="c1"># to get the corresponding values.</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">ragged_util</span><span class="o">.</span><span class="n">convert_to_int_tensor</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="s2">&quot;lengths&quot;</span><span class="p">,</span>
                                                    <span class="n">row_splits_dtype</span><span class="p">)</span>
        <span class="n">lengths</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">assert_has_rank</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">ncols</span><span class="p">)</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">limits</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>
        <span class="n">splits</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">array_ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">row_splits_dtype</span><span class="p">),</span> <span class="n">limits</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">sequence_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">ncols</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_row_splits</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">splits</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

      <span class="c1"># If neither padding nor lengths were specified, then create a splits</span>
      <span class="c1"># vector that contains no default values, and reshape the input tensor</span>
      <span class="c1"># to form the values for the RaggedTensor.</span>
      <span class="n">values_shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="n">values</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">values_shape</span><span class="p">)</span>
      <span class="n">const_nrows</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_at_index</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">value</span>
      <span class="n">const_ncols</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_at_index</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">value</span>
      <span class="k">if</span> <span class="n">const_nrows</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">nrows</span> <span class="o">=</span> <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">const_nrows</span><span class="p">,</span> <span class="n">row_splits_dtype</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">nrows</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">const_ncols</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ncols</span> <span class="o">=</span> <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">const_ncols</span><span class="p">,</span> <span class="n">row_splits_dtype</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">ncols</span> <span class="o">=</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
      <span class="k">return</span> <span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_uniform_row_length</span><span class="p">(</span>
          <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">uniform_row_length</span><span class="o">=</span><span class="n">ncols</span><span class="p">,</span>
          <span class="n">nrows</span><span class="o">=</span><span class="n">nrows</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.to_tensor"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.to_tensor">[docs]</a>  <span class="k">def</span> <span class="nf">to_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">default_value</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts this `RaggedTensor` into a `tf.Tensor`.</span>

<span class="sd">    If `shape` is specified, then the result is padded and/or truncated to</span>
<span class="sd">    the specified shape.</span>

<span class="sd">    Examples:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant([[9, 8, 7], [], [6, 5], [4]])</span>
<span class="sd">    &gt;&gt;&gt; print(rt.to_tensor())</span>
<span class="sd">    tf.Tensor(</span>
<span class="sd">        [[9 8 7] [0 0 0] [6 5 0] [4 0 0]], shape=(4, 3), dtype=int32)</span>
<span class="sd">    &gt;&gt;&gt; print(rt.to_tensor(shape=[5, 2]))</span>
<span class="sd">    tf.Tensor(</span>
<span class="sd">        [[9 8] [0 0] [6 5] [4 0] [0 0]], shape=(5, 2), dtype=int32)</span>

<span class="sd">    Args:</span>
<span class="sd">      default_value: Value to set for indices not specified in `self`. Defaults</span>
<span class="sd">        to zero.  `default_value` must be broadcastable to</span>
<span class="sd">        `self.shape[self.ragged_rank + 1:]`.</span>
<span class="sd">      name: A name prefix for the returned tensors (optional).</span>
<span class="sd">      shape: The shape of the resulting dense tensor.  In particular,</span>
<span class="sd">        `result.shape[i]` is `shape[i]` (if `shape[i]` is not None), or</span>
<span class="sd">        `self.bounding_shape(i)` (otherwise).`shape.rank` must be `None` or</span>
<span class="sd">        equal to `self.rank`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `Tensor` with shape `ragged.bounding_shape(self)` and the</span>
<span class="sd">      values specified by the non-empty values in `self`.  Empty values are</span>
<span class="sd">      assigned `default_value`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedToTensor&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="p">,</span> <span class="n">default_value</span><span class="p">,</span> <span class="n">shape</span><span class="p">]):</span>
      <span class="k">if</span> <span class="n">default_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">default_value</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
            <span class="n">default_value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;default_value&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">type_tensor_pairs</span> <span class="o">=</span> <span class="n">_get_row_partition_type_tensor_pairs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
      <span class="n">row_partition_types</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">type_tensor_pairs</span><span class="p">]</span>
      <span class="n">row_partition_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">type_tensor_pairs</span><span class="p">]</span>
      <span class="k">if</span> <span class="n">default_value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">default_value</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

      <span class="n">shape_tensor</span> <span class="o">=</span> <span class="n">_shape_as_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">row_partition_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">gen_ragged_conversion_ops</span><span class="o">.</span><span class="n">ragged_tensor_to_tensor</span><span class="p">(</span>
          <span class="n">shape</span><span class="o">=</span><span class="n">shape_tensor</span><span class="p">,</span>
          <span class="n">values</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span><span class="p">,</span>
          <span class="n">default_value</span><span class="o">=</span><span class="n">default_value</span><span class="p">,</span>
          <span class="n">row_partition_types</span><span class="o">=</span><span class="n">row_partition_types</span><span class="p">,</span>
          <span class="n">row_partition_tensors</span><span class="o">=</span><span class="n">row_partition_tensors</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.from_sparse"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.from_sparse">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">from_sparse</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">st_input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">row_splits_dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts a 2D `tf.SparseTensor` to a `RaggedTensor`.</span>

<span class="sd">    Each row of the `output` `RaggedTensor` will contain the explicit values</span>
<span class="sd">    from the same row in `st_input`.  `st_input` must be ragged-right.  If not</span>
<span class="sd">    it is not ragged-right, then an error will be generated.</span>

<span class="sd">    Example:</span>

<span class="sd">    &gt;&gt;&gt; st = tf.SparseTensor(indices=[[0, 0], [0, 1], [0, 2], [1, 0], [3, 0]],</span>
<span class="sd">    ...                      values=[1, 2, 3, 4, 5],</span>
<span class="sd">    ...                      dense_shape=[4, 3])</span>
<span class="sd">    &gt;&gt;&gt; tf.RaggedTensor.from_sparse(st).to_list()</span>
<span class="sd">    [[1, 2, 3], [4], [], [5]]</span>

<span class="sd">    Currently, only two-dimensional `SparseTensors` are supported.</span>

<span class="sd">    Args:</span>
<span class="sd">      st_input: The sparse tensor to convert.  Must have rank 2.</span>
<span class="sd">      name: A name prefix for the returned tensors (optional).</span>
<span class="sd">      row_splits_dtype: `dtype` for the returned `RaggedTensor`&#39;s `row_splits`</span>
<span class="sd">        tensor.  One of `tf.int32` or `tf.int64`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `RaggedTensor` with the same values as `st_input`.</span>
<span class="sd">      `output.ragged_rank = rank(st_input) - 1`.</span>
<span class="sd">      `output.shape = [st_input.dense_shape[0], None]`.</span>
<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If the number of dimensions in `st_input` is not known</span>
<span class="sd">        statically, or is not two.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">row_splits_dtype</span> <span class="o">=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">row_splits_dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">sparse_tensor</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">(</span><span class="n">st_input</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Expected SparseTensor, got </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">st_input</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedFromSparse&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">st_input</span><span class="p">]):</span>
      <span class="n">st_input</span> <span class="o">=</span> <span class="n">sparse_tensor</span><span class="o">.</span><span class="n">convert_to_tensor_or_sparse_tensor</span><span class="p">(</span>
          <span class="n">st_input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;st_input&quot;</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">st_input</span><span class="o">.</span><span class="n">dense_shape</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">static_rank_from_dense_shape</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">static_rank_from_dense_shape</span> <span class="o">=</span> <span class="n">st_input</span><span class="o">.</span><span class="n">dense_shape</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>

      <span class="k">if</span> <span class="n">st_input</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">static_rank_from_indices</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">static_rank_from_indices</span> <span class="o">=</span> <span class="n">st_input</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">dims</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>

      <span class="k">if</span> <span class="n">static_rank_from_dense_shape</span> <span class="o">!=</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">static_rank_from_indices</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;rank(st_input) must be 2&quot;</span><span class="p">)</span>

      <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span>
          <span class="n">_assert_sparse_indices_are_ragged_right</span><span class="p">(</span><span class="n">st_input</span><span class="o">.</span><span class="n">indices</span><span class="p">)):</span>
        <span class="c1"># Treat sparse row indices as segment ids to generate a splits tensor</span>
        <span class="c1"># thta we can pair with the sparse tensor values.  (Ignore sparse column</span>
        <span class="c1"># indices.)</span>
        <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">st_input</span><span class="o">.</span><span class="n">indices</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">row_splits_dtype</span><span class="p">)</span>
        <span class="n">num_segments</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">st_input</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">row_splits_dtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_value_rowids</span><span class="p">(</span>
            <span class="n">st_input</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.to_sparse"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.to_sparse">[docs]</a>  <span class="k">def</span> <span class="nf">to_sparse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts this `RaggedTensor` into a `tf.SparseTensor`.</span>

<span class="sd">    Example:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant([[1, 2, 3], [4], [], [5, 6]])</span>
<span class="sd">    &gt;&gt;&gt; print(rt.to_sparse())</span>
<span class="sd">    SparseTensor(indices=tf.Tensor(</span>
<span class="sd">                     [[0 0] [0 1] [0 2] [1 0] [3 0] [3 1]],</span>
<span class="sd">                     shape=(6, 2), dtype=int64),</span>
<span class="sd">                 values=tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32),</span>
<span class="sd">                 dense_shape=tf.Tensor([4 3], shape=(2,), dtype=int64))</span>

<span class="sd">    Args:</span>
<span class="sd">      name: A name prefix for the returned tensors (optional).</span>

<span class="sd">    Returns:</span>
<span class="sd">      A SparseTensor with the same values as `self`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedToSparse&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="p">]):</span>
      <span class="n">result</span> <span class="o">=</span> <span class="n">gen_ragged_conversion_ops</span><span class="o">.</span><span class="n">ragged_tensor_to_sparse</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">nested_row_splits</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">sparse_tensor</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">sparse_indices</span><span class="p">,</span>
                                        <span class="n">result</span><span class="o">.</span><span class="n">sparse_values</span><span class="p">,</span>
                                        <span class="n">result</span><span class="o">.</span><span class="n">sparse_dense_shape</span><span class="p">)</span></div>

  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">_from_variant</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span>
                    <span class="n">variant</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="p">,</span>
                    <span class="n">output_ragged_rank</span><span class="p">,</span>
                    <span class="n">input_ragged_rank</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">row_splits_dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts a `variant` Tensor into a `RaggedTensor`.</span>

<span class="sd">    The input `variant` could be a scalar, meaning it encodes a single</span>
<span class="sd">    `RaggedTensor` with ragged_rank `output_ragged_rank`. Alternatively it could</span>
<span class="sd">    have an arbitrary rank, in which case each element is decoded into a</span>
<span class="sd">    `RaggedTensor` with ragged_rank `input_ragged_rank` and these are then</span>
<span class="sd">    stacked according to the input shape to output a single `RaggedTensor`</span>
<span class="sd">    with ragged_rank `output_ragged_rank`. If `input_ragged_rank` is not</span>
<span class="sd">    provided, it is inferred dynamically as `output_ragged_rank` -</span>
<span class="sd">    `rank(variant)`. If `input_ragged_rank` is provided, the following must be</span>
<span class="sd">    true: `output_ragged_rank` = `input_ragged_rank` + `rank(variant)`.</span>

<span class="sd">    Example:</span>

<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant([[0], [1, 2]])</span>
<span class="sd">    &gt;&gt;&gt; et = rt._to_variant()</span>
<span class="sd">    &gt;&gt;&gt; stacked_et = tf.stack([et, et])</span>
<span class="sd">    &gt;&gt;&gt; tf.RaggedTensor._from_variant(  # scalar input.</span>
<span class="sd">    ...     et, dtype=tf.int32, output_ragged_rank=1).to_list()</span>
<span class="sd">    [[0], [1, 2]]</span>
<span class="sd">    &gt;&gt;&gt; tf.RaggedTensor._from_variant(  # batched input.</span>
<span class="sd">    ...     stacked_et, dtype=tf.int32, output_ragged_rank=2).to_list()</span>
<span class="sd">    [[[0], [1, 2]], [[0], [1, 2]]]</span>

<span class="sd">    Args:</span>
<span class="sd">      variant: A `variant` Tensor representing an encoded (possibly</span>
<span class="sd">        nested-batched) `RaggedTensor`.</span>
<span class="sd">      dtype: The dtype of the encoded `RaggedTensor`.</span>
<span class="sd">      output_ragged_rank: The expected ragged rank of the output `RaggedTensor`.</span>
<span class="sd">      input_ragged_rank: The ragged rank of each encoded `RaggedTensor`. This</span>
<span class="sd">        is optional and inferred dynamically if not provided.</span>
<span class="sd">      row_splits_dtype: `dtype` for the RaggedTensor&#39;s `row_splits` tensor.</span>
<span class="sd">        One of `tf.int32` or `tf.int64`.</span>
<span class="sd">      name: A name prefix for the returned tensors (optional).</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `RaggedTensor` of dtype `dtype` and ragged rank `output_ragged_rank`.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If the input rank is known, `input_ragged_rank` is provided</span>
<span class="sd">          and `output_ragged_rank` = `input_ragged_rank` + `rank(variant)` does</span>
<span class="sd">          not hold.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">variant</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
        <span class="n">variant</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;variant&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">variant</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">variant</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">input_ragged_rank</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span>
        <span class="n">output_ragged_rank</span> <span class="o">!=</span> <span class="n">input_ragged_rank</span> <span class="o">+</span> <span class="n">variant</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s2">&quot;output_ragged_rank must be equal to input_ragged_rank +&quot;</span>
          <span class="s2">&quot;variant.shape.ndims, found variant.shape.ndims: </span><span class="si">%d</span><span class="s2">, &quot;</span>
          <span class="s2">&quot;input_ragged_rank: </span><span class="si">%d</span><span class="s2">, output_ragged_rank: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span>
          <span class="p">(</span><span class="n">variant</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span><span class="p">,</span> <span class="n">input_ragged_rank</span><span class="p">,</span> <span class="n">output_ragged_rank</span><span class="p">))</span>
    <span class="n">input_ragged_rank</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">input_ragged_rank</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">input_ragged_rank</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span>
        <span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedFromVariant&quot;</span><span class="p">,</span>
        <span class="p">[</span><span class="n">variant</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">input_ragged_rank</span><span class="p">,</span> <span class="n">output_ragged_rank</span><span class="p">]):</span>
      <span class="n">result</span> <span class="o">=</span> <span class="n">gen_ragged_conversion_ops</span><span class="o">.</span><span class="n">ragged_tensor_from_variant</span><span class="p">(</span>
          <span class="n">variant</span><span class="p">,</span> <span class="n">input_ragged_rank</span><span class="p">,</span> <span class="n">output_ragged_rank</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span>
          <span class="n">row_splits_dtype</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
      <span class="k">return</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_nested_row_splits</span><span class="p">(</span>
          <span class="n">result</span><span class="o">.</span><span class="n">output_dense_values</span><span class="p">,</span>
          <span class="n">result</span><span class="o">.</span><span class="n">output_nested_splits</span><span class="p">,</span>
          <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_to_variant</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batched_input</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts this `RaggedTensor` into a `variant` Tensor.</span>

<span class="sd">    If `batched_input` is `True`, then the `RaggedTensor` is unbatched along the</span>
<span class="sd">    zero-th dimension, each component `RaggedTensor` is encoded into a scalar</span>
<span class="sd">    `variant` Tensor, and these are stacked to return a 1-D `variant` Tensor.</span>
<span class="sd">    If `batched_input` is `False`, then the `RaggedTensor` is encoded as is and</span>
<span class="sd">    a scalar `variant` Tensor is returned.</span>

<span class="sd">    Example:</span>
<span class="sd">    &gt;&gt;&gt; rt = tf.ragged.constant([[[0]], [[1]], [[2]]])</span>
<span class="sd">    &gt;&gt;&gt; rt._to_variant().shape.as_list()</span>
<span class="sd">    []</span>
<span class="sd">    &gt;&gt;&gt; rt._to_variant(batched_input=True).shape.as_list()</span>
<span class="sd">    [3]</span>

<span class="sd">    Args:</span>
<span class="sd">      batched_input: If `True`, the `RaggedTensor` is unbatched and converted to</span>
<span class="sd">        a `variant` vector. Set to `False` by default.</span>
<span class="sd">      name: A name prefix for the returned tensors (optional).</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `variant` Tensor that encodes this `RaggedTensor`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;RaggedToVariant&quot;</span><span class="p">,</span> <span class="p">[</span><span class="bp">self</span><span class="p">,</span> <span class="n">batched_input</span><span class="p">]):</span>
      <span class="k">return</span> <span class="n">gen_ragged_conversion_ops</span><span class="o">.</span><span class="n">ragged_tensor_to_variant</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">nested_row_splits</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span><span class="p">,</span> <span class="n">batched_input</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

  <span class="c1">#=============================================================================</span>
  <span class="c1"># String Encoding</span>
  <span class="c1">#=============================================================================</span>
  <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_eager</span><span class="p">():</span>
      <span class="k">return</span> <span class="s2">&quot;&lt;tf.RaggedTensor </span><span class="si">%s</span><span class="s2">&gt;&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="s2">&quot;tf.RaggedTensor(values=</span><span class="si">%s</span><span class="s2">, row_splits=</span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_values</span><span class="p">,</span>
                                                            <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits</span><span class="p">)</span>

  <span class="c1">#=============================================================================</span>
  <span class="c1"># Eager Execution Mode</span>
  <span class="c1">#=============================================================================</span>

<div class="viewcode-block" id="RaggedTensor.numpy"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.numpy">[docs]</a>  <span class="k">def</span> <span class="nf">numpy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a numpy `array` with the values for this `RaggedTensor`.</span>

<span class="sd">    Requires that this `RaggedTensor` was constructed in eager execution mode.</span>

<span class="sd">    Ragged dimensions are encoded using numpy `arrays` with `dtype=object` and</span>
<span class="sd">    `rank=1`, where each element is a single row.</span>

<span class="sd">    #### Examples</span>

<span class="sd">    In the following example, the value returned by `RaggedTensor.numpy()`</span>
<span class="sd">    contains three numpy `array` objects: one for each row (with `rank=1` and</span>
<span class="sd">    `dtype=int64`), and one to combine them (with `rank=1` and `dtype=object`):</span>

<span class="sd">    &gt;&gt;&gt; tf.ragged.constant([[1, 2, 3], [4, 5]], dtype=tf.int64).numpy()</span>
<span class="sd">    array([array([1, 2, 3]), array([4, 5])], dtype=object)</span>

<span class="sd">    Uniform dimensions are encoded using multidimensional numpy `array`s.  In</span>
<span class="sd">    the following example, the value returned by `RaggedTensor.numpy()` contains</span>
<span class="sd">    a single numpy `array` object, with `rank=2` and `dtype=int64`:</span>

<span class="sd">    &gt;&gt;&gt; tf.ragged.constant([[1, 2, 3], [4, 5, 6]], dtype=tf.int64).numpy()</span>
<span class="sd">    array([[1, 2, 3], [4, 5, 6]])</span>

<span class="sd">    Returns:</span>
<span class="sd">      A numpy `array`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_eager</span><span class="p">():</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;RaggedTensor.numpy() is only supported in eager mode.&quot;</span><span class="p">)</span>
    <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_values</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">splits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="p">[</span><span class="n">values</span><span class="p">[</span><span class="n">splits</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span><span class="n">splits</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">splits</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">rows</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">values</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="c1"># Note: if `rows` have ragged lengths, then they will be stored in a</span>
    <span class="c1"># np.ndarray with dtype=object and rank=1.  If they have uniform lengths,</span>
    <span class="c1"># they will be combined into a single np.ndarray with dtype=row.dtype and</span>
    <span class="c1"># rank=row.rank+1.</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span></div>

<div class="viewcode-block" id="RaggedTensor.to_list"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.to_list">[docs]</a>  <span class="k">def</span> <span class="nf">to_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a nested Python `list` with the values for this `RaggedTensor`.</span>

<span class="sd">    Requires that `rt` was constructed in eager execution mode.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A nested Python `list`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_eager</span><span class="p">():</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eager_value</span><span class="p">()</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;RaggedTensor.to_list() is only supported in eager &quot;</span>
                       <span class="s2">&quot;mode; in graph mode, evaluate the RaggedTensor first &quot;</span>
                       <span class="s2">&quot;and then use RaggedTensorValue.to_list().&quot;</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="nf">_eager_value</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a RaggedTensorValue for self.  Requires self._is_eager()=true.&quot;&quot;&quot;</span>
    <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">row_splits</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nested_row_splits</span><span class="p">):</span>
      <span class="n">value</span> <span class="o">=</span> <span class="n">ragged_tensor_value</span><span class="o">.</span><span class="n">RaggedTensorValue</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">row_splits</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">value</span>

  <span class="k">def</span> <span class="nf">_is_eager</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns True if values &amp; row_splits Tensors are all `EagerTensor`s.&quot;&quot;&quot;</span>
    <span class="n">rt</span> <span class="o">=</span> <span class="bp">self</span>
    <span class="k">while</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rt</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rt</span><span class="o">.</span><span class="n">row_splits</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">EagerTensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>
      <span class="n">rt</span> <span class="o">=</span> <span class="n">rt</span><span class="o">.</span><span class="n">values</span>
    <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rt</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">EagerTensor</span><span class="p">)</span>

  <span class="c1">#=============================================================================</span>
  <span class="c1"># Indexing &amp; Slicing</span>
  <span class="c1">#=============================================================================</span>
  <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the specified piece of this RaggedTensor.&quot;&quot;&quot;</span>
    <span class="c1"># See ragged_getitem.py for the documentation and implementation of this</span>
    <span class="c1"># method.</span>
    <span class="c1">#</span>
    <span class="c1"># Note: the imports in ragged/__init__.py ensure that this method always</span>
    <span class="c1"># gets overridden before it is called.</span>

  <span class="c1">#=============================================================================</span>
  <span class="c1"># Name Scope</span>
  <span class="c1">#=============================================================================</span>

  <span class="c1"># This private function is used by ops.name_scope to ensure that all of the</span>
  <span class="c1"># input tensors for the scope belong to the same graph.  Defining this means</span>
  <span class="c1"># that you may include `RaggedTensor` objects in the name_scope `values`</span>
  <span class="c1"># list.</span>
  <span class="k">def</span> <span class="nf">_as_graph_element</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Convert `self` to a graph element.&quot;&quot;&quot;</span>
    <span class="n">values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">values</span>
    <span class="k">while</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
      <span class="n">values</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">values</span>
    <span class="k">return</span> <span class="n">values</span>

  <span class="c1">#=============================================================================</span>
  <span class="c1"># Composite Tensor</span>
  <span class="c1">#=============================================================================</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_type_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">RaggedTensorSpec</span><span class="p">(</span>
        <span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">ragged_rank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ragged_rank</span><span class="p">,</span>
        <span class="n">row_splits_dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_row_splits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_shape_invariant_to_type_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">RaggedTensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ragged_rank</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">row_splits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

<div class="viewcode-block" id="RaggedTensor.consumers"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensor.consumers">[docs]</a>  <span class="k">def</span> <span class="nf">consumers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_consumers</span><span class="p">()</span></div></div>


<span class="k">def</span> <span class="nf">is_ragged</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns true if `value` is a ragged tensor or ragged tensor value.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span>
                    <span class="p">(</span><span class="n">RaggedTensor</span><span class="p">,</span> <span class="n">ragged_tensor_value</span><span class="o">.</span><span class="n">RaggedTensorValue</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">match_row_splits_dtypes</span><span class="p">(</span><span class="o">*</span><span class="n">tensors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Return a copy of `tensors` with row_splits all having the same dtype.</span>

<span class="sd">  Args:</span>
<span class="sd">    *tensors: A list of Tensors or RaggedTensors.</span>
<span class="sd">    **kwargs: If &#39;return_dtype=True&#39;, then return a tuple (dtype, tensors),</span>
<span class="sd">      where `dtype` is the data type used by row-splits, and `tensors` is the</span>
<span class="sd">      converted list of `Tensors` and `RaggedTensors`.</span>
<span class="sd">  Returns:</span>
<span class="sd">    The converted list of `Tensors` and `RaggedTensors`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">return_dtype</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;return_dtype&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unexpected keyword args </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">kwargs</span><span class="p">)</span>

  <span class="n">has_int32</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">has_int64</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensors</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">row_splits</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">:</span>
        <span class="n">has_int32</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">has_int64</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="k">if</span> <span class="n">has_int32</span> <span class="ow">and</span> <span class="n">has_int64</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">ragged_config</span><span class="o">.</span><span class="n">auto_cast_partition_dtype</span><span class="p">():</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Input RaggedTensors have mismatched row_splits dtypes; &quot;</span>
                       <span class="s2">&quot;use RaggedTensor.with_row_splits_dtype() to convert &quot;</span>
                       <span class="s2">&quot;them to compatible dtypes.&quot;</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span>
    <span class="n">tensors</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">with_row_splits_dtype</span><span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">)</span> <span class="k">else</span> <span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tensors</span><span class="p">)</span>

  <span class="k">elif</span> <span class="n">has_int32</span><span class="p">:</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span>

  <span class="k">if</span> <span class="n">return_dtype</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">tensors</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tensors</span>


<span class="c1">#===============================================================================</span>
<span class="c1"># RaggedTensorSpec</span>
<span class="c1">#===============================================================================</span>
<div class="viewcode-block" id="RaggedTensorSpec"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensorSpec">[docs]</a><span class="nd">@tf_export</span><span class="p">(</span><span class="s2">&quot;RaggedTensorSpec&quot;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">RaggedTensorSpec</span><span class="p">(</span><span class="n">type_spec</span><span class="o">.</span><span class="n">BatchableTypeSpec</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Type specification for a `tf.RaggedTensor`.&quot;&quot;&quot;</span>

  <span class="vm">__slots__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;_shape&quot;</span><span class="p">,</span> <span class="s2">&quot;_dtype&quot;</span><span class="p">,</span> <span class="s2">&quot;_ragged_rank&quot;</span><span class="p">,</span> <span class="s2">&quot;_row_splits_dtype&quot;</span><span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">value_type</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">RaggedTensor</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">ragged_rank</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">row_splits_dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a type specification for a `tf.RaggedTensor`.</span>

<span class="sd">    Args:</span>
<span class="sd">      shape: The shape of the RaggedTensor, or `None` to allow any shape.  If</span>
<span class="sd">        a shape is specified, then all ragged dimensions must have size `None`.</span>
<span class="sd">      dtype: `tf.DType` of values in the RaggedTensor.</span>
<span class="sd">      ragged_rank: Python integer, the ragged rank of the RaggedTensor</span>
<span class="sd">        to be described.  Defaults to `shape.ndims - 1`.</span>
<span class="sd">      row_splits_dtype: `dtype` for the RaggedTensor&#39;s `row_splits` tensor.</span>
<span class="sd">        One of `tf.int32` or `tf.int64`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">as_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits_dtype</span> <span class="o">=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">row_splits_dtype</span><span class="p">)</span>

    <span class="n">rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="o">.</span><span class="n">ndims</span>
    <span class="k">if</span> <span class="n">ragged_rank</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must specify ragged_rank or &quot;</span>
                         <span class="s2">&quot;a shape with a known rank.&quot;</span><span class="p">)</span>
      <span class="n">ragged_rank</span> <span class="o">=</span> <span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span> <span class="o">=</span> <span class="n">ragged_rank</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;ragged_rank must be an int&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">ragged_rank</span> <span class="o">&gt;=</span> <span class="n">rank</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;ragged_rank must be less than rank.&quot;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_serialize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits_dtype</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_component_specs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span> <span class="p">[</span><span class="n">tensor_spec</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)]</span>

    <span class="n">flat_values_shape</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">])</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:])</span>
    <span class="n">outer_dim</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_at_index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">outer_splits_shape</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">if</span> <span class="n">outer_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">outer_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">inner_splits_spec</span> <span class="o">=</span> <span class="n">tensor_spec</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">([</span><span class="kc">None</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits_dtype</span><span class="p">)</span>

    <span class="n">specs</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">[</span><span class="n">tensor_spec</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">flat_values_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">),</span>
         <span class="n">tensor_spec</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">outer_splits_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits_dtype</span><span class="p">)]</span> <span class="o">+</span>
        <span class="p">[</span><span class="n">inner_splits_spec</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)])</span>
    <span class="k">return</span> <span class="n">specs</span>

  <span class="k">def</span> <span class="nf">_to_components</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">is_ragged</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
      <span class="k">return</span> <span class="p">[</span><span class="n">value</span><span class="o">.</span><span class="n">flat_values</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">nested_row_splits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="p">[</span><span class="n">value</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">_from_components</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor_list</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tensor_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tensor_list</span><span class="p">)</span> <span class="ow">and</span>
        <span class="ow">not</span> <span class="n">tf2</span><span class="o">.</span><span class="n">enabled</span><span class="p">()):</span>
      <span class="k">for</span> <span class="n">row_splits</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">ragged_tensor_value</span><span class="o">.</span><span class="n">RaggedTensorValue</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">row_splits</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">tensor_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tensor_list</span><span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">tensor_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="k">for</span> <span class="n">row_splits</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">RaggedTensor</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">row_splits</span><span class="p">,</span> <span class="n">internal</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>

  <span class="c1"># The RaggedTensorSpec tensor_list encoding uses to/from_variant ops</span>
  <span class="c1"># to (un)box the component tensors in a way that allows for batching &amp;</span>
  <span class="c1"># unbatching.</span>
  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_flat_tensor_specs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># NOTE(mishragaurav): The default flat shape of a boxed `RaggedTensor` is</span>
    <span class="c1"># `[]` (scalar), but a `RaggedTensorSpec` can also represent a batch of</span>
    <span class="c1"># boxed `RaggedTensor` objects with shape `(...)` (and batches of batches,</span>
    <span class="c1"># etc.), so the flat shape must be unknown.</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">tensor_spec</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">variant</span><span class="p">)]</span>

  <span class="k">def</span> <span class="nf">_to_tensor_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="n">ragged_rank</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">ragged_rank</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">ragged_rank</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Ragged rank of value (</span><span class="si">%d</span><span class="s2">) does not match ragged &quot;</span>
                       <span class="s2">&quot;rank of type (</span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">ragged_rank</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">ragged_rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span> <span class="p">[</span>
          <span class="n">gen_ragged_conversion_ops</span><span class="o">.</span><span class="n">ragged_tensor_to_variant</span><span class="p">(</span>
              <span class="p">(),</span> <span class="n">value</span><span class="p">,</span> <span class="n">batched_input</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="p">]</span>
    <span class="c1"># pylint: disable=protected-access</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">value</span><span class="o">.</span><span class="n">_to_variant</span><span class="p">(</span><span class="n">batched_input</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span>

  <span class="k">def</span> <span class="nf">_to_batched_tensor_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="n">ragged_rank</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">ragged_rank</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">ragged_rank</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Ragged rank of value (</span><span class="si">%d</span><span class="s2">) does not match ragged &quot;</span>
                       <span class="s2">&quot;rank of type (</span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">ragged_rank</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">ragged_rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="c1"># TODO(b/141789000) Update this to handle ragged_rank=0.</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s2">&quot;_to_batched_tensor_list doesn&#39;t support ragged_rank=0 yet&quot;</span><span class="p">)</span>
    <span class="c1"># pylint: disable=protected-access</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">value</span><span class="o">.</span><span class="n">_to_variant</span><span class="p">(</span><span class="n">batched_input</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

  <span class="k">def</span> <span class="nf">_from_compatible_tensor_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor_list</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s2">&quot;ragged_rank must be non-negative; got </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">RaggedTensor</span><span class="o">.</span><span class="n">_from_variant</span><span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>
        <span class="n">tensor_list</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span>
        <span class="n">row_splits_dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_row_splits_dtype</span><span class="p">,</span>
        <span class="n">output_ragged_rank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="o">.</span><span class="n">ndims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
        <span class="n">outer_dim</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">dimension_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">outer_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">result</span><span class="o">.</span><span class="n">row_splits</span><span class="o">.</span><span class="n">set_shape</span><span class="p">([</span><span class="n">outer_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">result</span><span class="o">.</span><span class="n">flat_values</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span>
            <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">])</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span><span class="p">:]))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">result</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>

  <span class="k">def</span> <span class="nf">_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">RaggedTensorSpec</span><span class="p">(</span>
        <span class="n">tensor_shape</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="n">batch_size</span><span class="p">])</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">),</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits_dtype</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_unbatch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Note: Negative ragged_rank is allowed here because the dataset could be</span>
    <span class="c1"># subsequently batched again. If ragged_rank &gt; 1, assume row_splits_dtype is</span>
    <span class="c1"># consistent. Errors are handled in</span>
    <span class="c1"># RaggedTensorSpec._from_compatible_tensor_list()</span>
    <span class="k">return</span> <span class="n">RaggedTensorSpec</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits_dtype</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_to_legacy_output_types</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span>

  <span class="k">def</span> <span class="nf">_to_legacy_output_shapes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span>

  <span class="k">def</span> <span class="nf">_to_legacy_output_classes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span>

<div class="viewcode-block" id="RaggedTensorSpec.from_value"><a class="viewcode-back" href="../../../../../index.html#tensorflow.RaggedTensorSpec.from_value">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">from_value</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
               <span class="n">dtype</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
               <span class="n">ragged_rank</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">ragged_rank</span><span class="p">,</span>
               <span class="n">row_splits_dtype</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">row_splits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span></div></div>


<span class="n">type_spec</span><span class="o">.</span><span class="n">register_type_spec_from_value_converter</span><span class="p">(</span>
    <span class="n">ragged_tensor_value</span><span class="o">.</span><span class="n">RaggedTensorValue</span><span class="p">,</span> <span class="n">RaggedTensorSpec</span><span class="o">.</span><span class="n">from_value</span><span class="p">)</span>


<span class="c1">#===============================================================================</span>
<span class="c1"># Convert value -&gt; tensor</span>
<span class="c1">#===============================================================================</span>
<span class="k">def</span> <span class="nf">convert_to_tensor_or_ragged_tensor</span><span class="p">(</span><span class="n">value</span><span class="p">,</span>
                                       <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                       <span class="n">preferred_dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                       <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Converts value to a `RaggedTensor` or `Tensor`.</span>

<span class="sd">  * If `value` is a `RaggedTensor`, then return it as-is.</span>
<span class="sd">  * If `value` is a `RaggedTensorValue`, return a corresponding constant</span>
<span class="sd">    `RaggedTensor`.</span>
<span class="sd">  * Otherwise, use `convert_to_tensor` to convert `value` to a `Tensor`.</span>

<span class="sd">  Args:</span>
<span class="sd">    value: A `RaggedTensor`, a `RaggedTensorValue`, or an object whose type has</span>
<span class="sd">      a registered `Tensor` conversion function.</span>
<span class="sd">    dtype: Optional element type for the returned tensor.  If missing the type</span>
<span class="sd">      is inferred from the type of `value`.</span>
<span class="sd">    preferred_dtype: Optional element type for the returned tensor, used when</span>
<span class="sd">      dtype is None.  This argument has no effect if `value` is already a</span>
<span class="sd">      tensor, or when conversion is not possible.</span>
<span class="sd">    name: Optional name to use if a new `Tensor` is created.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` or `RaggedTensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">dtype</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Tensor conversion requested dtype </span><span class="si">%s</span><span class="s2"> for &quot;</span>
                       <span class="s2">&quot;RaggedTensor with dtype </span><span class="si">%s</span><span class="s2">: </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span>
                       <span class="p">(</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">value</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">ragged_tensor_value</span><span class="o">.</span><span class="n">RaggedTensorValue</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">ops</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s2">&quot;ConvertToTensorOrRaggedTensor&quot;</span><span class="p">,</span> <span class="p">[]):</span>
      <span class="n">flat_values</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
          <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">flat_values</span><span class="p">,</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">preferred_dtype</span><span class="o">=</span><span class="n">preferred_dtype</span><span class="p">,</span>
          <span class="n">name</span><span class="o">=</span><span class="s2">&quot;flat_values&quot;</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_nested_row_splits</span><span class="p">(</span>
          <span class="n">flat_values</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">nested_row_splits</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
        <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">preferred_dtype</span><span class="o">=</span><span class="n">preferred_dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>


<span class="c1">#===============================================================================</span>
<span class="c1"># Register RaggedTensor for use with session.run.</span>
<span class="c1">#===============================================================================</span>
<span class="k">def</span> <span class="nf">_ragged_tensor_value_from_components</span><span class="p">(</span><span class="n">components</span><span class="p">):</span>
  <span class="n">components</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">components</span><span class="p">)</span>
  <span class="n">value</span> <span class="o">=</span> <span class="n">components</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
  <span class="k">while</span> <span class="n">components</span><span class="p">:</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">ragged_tensor_value</span><span class="o">.</span><span class="n">RaggedTensorValue</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">components</span><span class="o">.</span><span class="n">pop</span><span class="p">())</span>
  <span class="k">return</span> <span class="n">value</span>


<span class="k">def</span> <span class="nf">_ragged_tensor_session_fetch</span><span class="p">(</span><span class="n">rt</span><span class="p">):</span>
  <span class="n">components</span> <span class="o">=</span> <span class="n">rt</span><span class="o">.</span><span class="n">nested_row_splits</span> <span class="o">+</span> <span class="p">(</span><span class="n">rt</span><span class="o">.</span><span class="n">flat_values</span><span class="p">,)</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">components</span><span class="p">,</span> <span class="n">_ragged_tensor_value_from_components</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_ragged_tensor_session_feed</span><span class="p">(</span><span class="n">feed_key</span><span class="p">,</span> <span class="n">feed_val</span><span class="p">):</span>
  <span class="n">key_components</span> <span class="o">=</span> <span class="n">feed_key</span><span class="o">.</span><span class="n">nested_row_splits</span> <span class="o">+</span> <span class="p">(</span><span class="n">feed_key</span><span class="o">.</span><span class="n">flat_values</span><span class="p">,)</span>
  <span class="n">val_components</span> <span class="o">=</span> <span class="n">feed_val</span><span class="o">.</span><span class="n">nested_row_splits</span> <span class="o">+</span> <span class="p">(</span><span class="n">feed_val</span><span class="o">.</span><span class="n">flat_values</span><span class="p">,)</span>
  <span class="k">return</span> <span class="nb">zip</span><span class="p">(</span><span class="n">key_components</span><span class="p">,</span> <span class="n">val_components</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_ragged_tensor_session_feed_for_partial_run</span><span class="p">(</span><span class="n">feed_key</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">feed_key</span><span class="o">.</span><span class="n">nested_row_splits</span> <span class="o">+</span> <span class="p">(</span><span class="n">feed_key</span><span class="o">.</span><span class="n">flat_values</span><span class="p">,)</span>


<span class="n">session</span><span class="o">.</span><span class="n">register_session_run_conversion_functions</span><span class="p">(</span>
    <span class="n">RaggedTensor</span><span class="p">,</span> <span class="n">_ragged_tensor_session_fetch</span><span class="p">,</span> <span class="n">_ragged_tensor_session_feed</span><span class="p">,</span>
    <span class="n">_ragged_tensor_session_feed_for_partial_run</span><span class="p">)</span>


<span class="c1">#===============================================================================</span>
<span class="c1"># RaggedTensorType</span>
<span class="c1">#===============================================================================</span>
<span class="k">class</span> <span class="nc">RaggedTensorType</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Encoding of a static type for a `RaggedTensor`.</span>

<span class="sd">  Use this type to express/declare that an output must have the type of</span>
<span class="sd">  `RaggedTensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">ragged_rank</span><span class="p">,</span> <span class="n">row_splits_dtype</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes a RaggedTensorType object.</span>

<span class="sd">    Args:</span>
<span class="sd">      dtype: data type of the `RaggedTensor`&#39;s inner values.</span>
<span class="sd">      ragged_rank: ragged_rank of the declared `RaggedTensor`.</span>
<span class="sd">      row_splits_dtype: data type for the `RaggedTensor`&#39;s row splits.</span>
<span class="sd">        One of: `tf.int32` or `tf.int64`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">row_splits_dtype</span> <span class="o">=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">row_splits_dtype</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span> <span class="o">=</span> <span class="n">ragged_rank</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits_dtype</span> <span class="o">=</span> <span class="n">row_splits_dtype</span>

  <span class="n">dtype</span> <span class="o">=</span> <span class="nb">property</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
  <span class="n">ragged_rank</span> <span class="o">=</span> <span class="nb">property</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ragged_rank</span><span class="p">)</span>
  <span class="n">row_splits_dtype</span> <span class="o">=</span> <span class="nb">property</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_row_splits_dtype</span><span class="p">)</span>


<span class="c1">#===============================================================================</span>
<span class="c1"># Helper Functions</span>
<span class="c1">#===============================================================================</span>
<span class="k">def</span> <span class="nf">_assert_sparse_indices_are_ragged_right</span><span class="p">(</span><span class="n">indices</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Checks that the given SparseTensor.indices tensor is ragged-right.</span>

<span class="sd">  Example: `indices = [[0, 0], [0, 1], [2, 0], [3, 1]]` is not ragged right</span>
<span class="sd">  because the entry `[3, 1]` skips a cell.</span>

<span class="sd">  Args:</span>
<span class="sd">    indices: The SparseTensor indices to check.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A list of control dependency op tensors.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">index_prefix</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">index_suffix</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

  <span class="c1"># Check whether each index is starting a new row in the innermost dimension</span>
  <span class="c1"># (prefix[i] != prefix[i-1]) or continuing a row (prefix[i] == prefix[i-1]).</span>
  <span class="c1"># (Note: this skips the first index; we will check that separately below.)</span>
  <span class="n">index_prefix_changed</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_any</span><span class="p">(</span>
      <span class="n">math_ops</span><span class="o">.</span><span class="n">not_equal</span><span class="p">(</span><span class="n">index_prefix</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">index_prefix</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

  <span class="c1"># Check two cases:</span>
  <span class="c1">#   * For indices that start a new row: index_suffix[i] must be zero.</span>
  <span class="c1">#   * For indices that continue a row: index_suffix[i] must be equal to</span>
  <span class="c1">#     index_suffix[i-1]+1.</span>
  <span class="n">index_ok</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
      <span class="n">index_prefix_changed</span><span class="p">,</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">index_suffix</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="mi">0</span><span class="p">),</span>
      <span class="n">math_ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">index_suffix</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">index_suffix</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

  <span class="c1"># Also check that the very first index didn&#39;t skip any cells.  The first</span>
  <span class="c1"># index starts a new row (by definition), so its suffix should be zero.</span>
  <span class="n">sparse_indices_are_ragged_right</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span>
      <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">index_suffix</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">)),</span>
      <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">index_ok</span><span class="p">))</span>

  <span class="n">message</span> <span class="o">=</span> <span class="p">[</span>
      <span class="s2">&quot;SparseTensor is not right-ragged&quot;</span><span class="p">,</span> <span class="s2">&quot;SparseTensor.indices =&quot;</span><span class="p">,</span> <span class="n">indices</span>
  <span class="p">]</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">control_flow_ops</span><span class="o">.</span><span class="n">Assert</span><span class="p">(</span><span class="n">sparse_indices_are_ragged_right</span><span class="p">,</span> <span class="n">message</span><span class="p">)]</span>


<span class="nd">@ops</span><span class="o">.</span><span class="n">RegisterGradient</span><span class="p">(</span><span class="s2">&quot;RaggedTensorToSparse&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_ragged_tensor_to_sparse_gradient</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">unused_sparse_indices_grad</span><span class="p">,</span>
                                      <span class="n">sparse_values_grad</span><span class="p">,</span>
                                      <span class="n">unused_sparse_shape_grad</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Gradient for RaggedTensorToSparse.&quot;&quot;&quot;</span>
  <span class="n">op_inputs_nested_row_splits</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">op_inputs_flat_values</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

  <span class="c1"># No gradient for the RaggedTensor&#39;s nested_row_splits.</span>
  <span class="n">nested_row_splits_gradient</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">op_inputs_nested_row_splits</span><span class="p">)</span>

  <span class="c1"># Gradient for the RaggedTensor&#39;s flat_values is formed by reshaping</span>
  <span class="c1"># the gradient for the SparseTensor&#39;s values.</span>
  <span class="n">flat_values_shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">op_inputs_flat_values</span><span class="p">)</span>
  <span class="n">flat_values_gradient</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">sparse_values_grad</span><span class="p">,</span>
                                           <span class="n">flat_values_shape</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">nested_row_splits_gradient</span> <span class="o">+</span> <span class="p">[</span><span class="n">flat_values_gradient</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">_assert_monotonic_increasing</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_non_negative</span><span class="p">(</span>
      <span class="n">tensor</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">tensor</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">message</span><span class="o">=</span><span class="n">message</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_assert_zero</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">check_ops</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span>
      <span class="n">tensor</span><span class="p">,</span> <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">message</span><span class="o">=</span><span class="n">message</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_nrows</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">nrows</span><span class="p">(</span><span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">_merge_dims</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">outer_axis</span><span class="p">,</span> <span class="n">inner_axis</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Merges value[outer_axis...inner_axis] into a single dimension.</span>

<span class="sd">  See `RaggedTensor.merge_dims()` for more details.  This helper differs from</span>
<span class="sd">  `RaggedTensor.merge_dims()` in that `value` may be a dense or ragged tensor.</span>

<span class="sd">  Args:</span>
<span class="sd">    value: A `RaggedTensor` or `Tensor`</span>
<span class="sd">    outer_axis: `int`</span>
<span class="sd">    inner_axis: `int`</span>

<span class="sd">  Returns:</span>
<span class="sd">    A flattened `RaggedTensor` or `Tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">outer_axis</span> <span class="o">==</span> <span class="n">inner_axis</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">value</span>

  <span class="c1"># Flatten outer dimensions of a RaggedTensor by just taking its values.</span>
  <span class="k">while</span> <span class="n">outer_axis</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">values</span>
    <span class="n">inner_axis</span> <span class="o">-=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">inner_axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">value</span>

  <span class="c1"># Flatten non-Ragged tensors using tf.reshape().</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">is_fully_defined</span><span class="p">():</span>
      <span class="n">old_shape</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
      <span class="n">new_shape</span> <span class="o">=</span> <span class="n">old_shape</span><span class="p">[:</span><span class="n">outer_axis</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">old_shape</span><span class="p">[</span><span class="n">inner_axis</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">old_shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
      <span class="n">new_shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
          <span class="p">[</span><span class="n">old_shape</span><span class="p">[:</span><span class="n">outer_axis</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">old_shape</span><span class="p">[</span><span class="n">inner_axis</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span>

  <span class="c1"># Handle outer_axis&gt;1 via recursion.</span>
  <span class="k">if</span> <span class="n">outer_axis</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">value</span><span class="o">.</span><span class="n">with_values</span><span class="p">(</span>
        <span class="n">_merge_dims</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">outer_axis</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inner_axis</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

  <span class="c1"># At this point, we know outer_axis == 1, and value is a RaggedTensor.</span>
  <span class="c1"># So we need to flatten the values and build a corresponding splits tensor.</span>
  <span class="n">new_values</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">values</span>
  <span class="n">new_splits</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">row_splits</span>
  <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">outer_axis</span><span class="p">,</span> <span class="n">inner_axis</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">new_values</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
      <span class="c1"># Flatten a single ragged dimension.</span>
      <span class="n">new_splits</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">new_values</span><span class="o">.</span><span class="n">row_splits</span><span class="p">,</span> <span class="n">new_splits</span><span class="p">)</span>
      <span class="n">new_values</span> <span class="o">=</span> <span class="n">new_values</span><span class="o">.</span><span class="n">values</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># Flatten all remaining dense dimensions.</span>
      <span class="n">shape_split</span> <span class="o">=</span> <span class="n">inner_axis</span> <span class="o">-</span> <span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span>
      <span class="k">if</span> <span class="n">new_values</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">is_fully_defined</span><span class="p">():</span>
        <span class="n">old_shape</span> <span class="o">=</span> <span class="n">new_values</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">old_shape</span><span class="p">[</span><span class="n">shape_split</span><span class="p">:]</span>
        <span class="n">flat_size</span> <span class="o">=</span> <span class="n">_prod</span><span class="p">(</span><span class="n">old_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">shape_split</span><span class="p">])</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">old_shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">new_values</span><span class="p">)</span>
        <span class="n">new_shape</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">concat</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">old_shape</span><span class="p">[</span><span class="n">shape_split</span><span class="p">:]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">flat_size</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
            <span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_prod</span><span class="p">(</span><span class="n">old_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">shape_split</span><span class="p">]),</span> <span class="n">new_splits</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">new_values</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_values</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">)</span>
      <span class="n">new_splits</span> <span class="o">=</span> <span class="n">new_splits</span> <span class="o">*</span> <span class="n">flat_size</span>
      <span class="k">break</span>
  <span class="k">return</span> <span class="n">RaggedTensor</span><span class="o">.</span><span class="n">from_row_splits</span><span class="p">(</span><span class="n">new_values</span><span class="p">,</span> <span class="n">new_splits</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_prod</span><span class="p">(</span><span class="n">lst</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns the product of the numbers in a list.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">operator</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="n">lst</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_row_partition_type_tensor_pairs_tail</span><span class="p">(</span><span class="n">rt_value</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Gets a list of the row partitions for rt_value.</span>

<span class="sd">  If parent_indices are defined, then they are used. Otherwise, row_splits</span>
<span class="sd">  are used.</span>

<span class="sd">  This assumes that rt_input is nested inside another RaggedTensor. If it is</span>
<span class="sd">  a tensor, then return an empty list.</span>

<span class="sd">  Args:</span>
<span class="sd">    rt_value: a ragged tensor value. May be a tensor.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A list of (row_partition_type, row_partition_tensor) pairs.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rt_value</span><span class="p">,</span> <span class="n">RaggedTensor</span><span class="p">):</span>
    <span class="n">tail</span> <span class="o">=</span> <span class="n">_get_row_partition_type_tensor_pairs_tail</span><span class="p">(</span><span class="n">rt_value</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">rt_value</span><span class="o">.</span><span class="n">_cached_value_rowids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># pylint: disable=protected-access</span>
      <span class="k">return</span> <span class="p">[(</span><span class="s2">&quot;VALUE_ROWIDS&quot;</span><span class="p">,</span> <span class="n">rt_value</span><span class="o">.</span><span class="n">value_rowids</span><span class="p">())]</span> <span class="o">+</span> <span class="n">tail</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="p">[(</span><span class="s2">&quot;ROW_SPLITS&quot;</span><span class="p">,</span> <span class="n">rt_value</span><span class="o">.</span><span class="n">row_splits</span><span class="p">)]</span> <span class="o">+</span> <span class="n">tail</span>
  <span class="k">return</span> <span class="p">[]</span>


<span class="k">def</span> <span class="nf">_get_row_partition_type_tensor_pairs</span><span class="p">(</span><span class="n">rt_input</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Gets a list of the row partitions for rt_input.</span>

<span class="sd">  If value_rowids are defined, then they are used. Otherwise, row_splits</span>
<span class="sd">  are used. If the outermost level has value_rowids defind, then nrows is</span>
<span class="sd">  also added.</span>

<span class="sd">  Args:</span>
<span class="sd">    rt_input: a ragged tensor.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A list of (row_partition_type, row_partition_tensor) pairs.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">tail</span> <span class="o">=</span> <span class="n">_get_row_partition_type_tensor_pairs_tail</span><span class="p">(</span><span class="n">rt_input</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">rt_input</span><span class="o">.</span><span class="n">_cached_value_rowids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># pylint: disable=protected-access</span>
    <span class="k">return</span> <span class="p">[(</span><span class="s2">&quot;FIRST_DIM_SIZE&quot;</span><span class="p">,</span> <span class="n">rt_input</span><span class="o">.</span><span class="n">nrows</span><span class="p">()),</span>
            <span class="p">(</span><span class="s2">&quot;VALUE_ROWIDS&quot;</span><span class="p">,</span> <span class="n">rt_input</span><span class="o">.</span><span class="n">value_rowids</span><span class="p">())]</span> <span class="o">+</span> <span class="n">tail</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">[(</span><span class="s2">&quot;ROW_SPLITS&quot;</span><span class="p">,</span> <span class="n">rt_input</span><span class="o">.</span><span class="n">row_splits</span><span class="p">)]</span> <span class="o">+</span> <span class="n">tail</span>


<span class="k">def</span> <span class="nf">_shape_as_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Takes shape and coerces it to a shape as a tensor.</span>

<span class="sd">  If the object is already a tensor, simply passes it on (result is guaranteed</span>
<span class="sd">  to be int64 or int32, but not necessarily dtype).</span>
<span class="sd">  If not, creates a tensor of type dtype.</span>

<span class="sd">  Result is either a scalar equal to -1 if the shape is unknown_rank.</span>
<span class="sd">  Otherwise, it is a vector, where unknown dimensions are represented with a</span>
<span class="sd">  value of -1.</span>

<span class="sd">  In C++, see TensorShapeFromTensor for parsing shapes in kernels, and</span>
<span class="sd">  InferenceContext::MakeShapeFromShapeTensorTreatScalarAsUnknownShape, for</span>
<span class="sd">  use in the shape inference function.</span>

<span class="sd">  Args:</span>
<span class="sd">    shape: input to coerce from TensorShape, Tensor, None, List[Optional[Int]],</span>
<span class="sd">      Tuple[Optional[Int]].</span>
<span class="sd">    dtype: tf.int64 or tf.int32</span>

<span class="sd">  Returns:</span>
<span class="sd">    a scalar or vector tensor of dtype tf.int32 or tf.int64.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">dtype</span> <span class="o">!=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span> <span class="ow">and</span> <span class="n">dtype</span> <span class="o">!=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Expected int64 or int32 for dtype: got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dtype</span><span class="p">))</span>

  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">shape</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int64</span> <span class="ow">and</span> <span class="n">shape</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">shape</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="o">.</span><span class="n">as_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">shape</span><span class="p">:</span>
    <span class="c1"># Imply rank is unknown using a -1 scalar.</span>
    <span class="k">return</span> <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="p">[(</span><span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">()]</span>
  <span class="c1"># At this point, shape is List[Int].</span>
  <span class="k">return</span> <span class="n">constant_op</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>


<span class="n">ops</span><span class="o">.</span><span class="n">no_gradient</span><span class="p">(</span><span class="s2">&quot;RaggedTensorToVariant&quot;</span><span class="p">)</span>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright - Wei MEI (Nick Cafferry).

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>
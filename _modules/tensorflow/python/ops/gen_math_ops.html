

<!DOCTYPE html>
<html class="writer-html5" lang="Chinese" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tensorflow.python.ops.gen_math_ops &mdash; tensorflow 0.1.3 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../../../_static/GCC.png"/>
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/language_data.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #343131" >
          

          
            <a href="../../../../index.html" class="icon icon-home" alt="Documentation Home"> tensorflow
          

          
            
            <img src="../../../../_static/GCC.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.1.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">从TensorFlow开始 (Getting Started)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html">TensorFlow如何工作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id1">变量和张量的声明</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id2">使用占位符和变量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id3">矩阵</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id4">操作符的声明</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id5">载入激活函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id6">数据资源</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id7">资源库</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id8">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">TensorFlow方式 (TensorFlow Way)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html">计算图</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id2">分层嵌套操作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id3">多层操作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id4">载入损失函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id5">载入反向传播</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id6">随机和批量训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id7">结合训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id8">模型评估</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id9">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">线性回归 (Linear Regression)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html">矩阵转置</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#id2">矩阵分解法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#tensorflow">TensorFLow的线性回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#id3">线性回归的损失函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#deming">Deming回归(全回归)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#lasso-ridge">套索(Lasso)回归和岭(Ridge)回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#elastic-net">弹性网(Elastic Net)回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#logistic">逻辑(Logistic)回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#id4">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">支持向量机(Support Vector Machines)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_Support_Vector_Machines/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_Support_Vector_Machines/index.html#id2">线性支持向量机</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_Support_Vector_Machines/index.html#id3">回归线性回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_Support_Vector_Machines/index.html#tensorflow">TensorFlow中的核</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_Support_Vector_Machines/index.html#id4">非线性支持向量机</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_Support_Vector_Machines/index.html#id5">多类支持向量机</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_Support_Vector_Machines/index.html#id6">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">最近邻法 (Nearest Neighbor Methods)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_Nearest_Neighbor_Methods/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_Nearest_Neighbor_Methods/index.html#id2">最近邻法的使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_Nearest_Neighbor_Methods/index.html#id3">文本距离函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_Nearest_Neighbor_Methods/index.html#id4">计算混合距离函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_Nearest_Neighbor_Methods/index.html#id5">地址匹配</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_Nearest_Neighbor_Methods/index.html#id6">图像处理的近邻法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_Nearest_Neighbor_Methods/index.html#id7">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">神经元网络 (Neural Networks)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id2">载入操作门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id3">门运算和激活函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id4">载入一层神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id5">载入多层神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id6">使用多层神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id7">线性模型预测改善</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id8">神经网络学习井字棋</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id9">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">自然语言处理(NLP)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#bag-of-words">词袋 (Bag of Words)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#tf-idf">词频-逆文本频率 (TF-IDF)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#skip-gram">运用Skip-Gram</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#cbow-continuous-bag-fo-words">CBOW (Continuous Bag fo Words)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#word2vec">Word2Vec应用实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#doc2vec-sentiment-analysis">Doc2Vec情感分析 (Sentiment Analysis)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#id2">神经网络学习井字棋</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#id3">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">卷积神经网络(CNN)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../08_Convolutional_Neural_Networks/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../08_Convolutional_Neural_Networks/index.html#simple-cnns">简单卷积神经网络 (Simple CNNs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../08_Convolutional_Neural_Networks/index.html#advanced-cnns">高级卷积神经网络 (Advanced CNNs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../08_Convolutional_Neural_Networks/index.html#id2">重新训练一个存在架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../08_Convolutional_Neural_Networks/index.html#stylenet-neural-style">使用Stylenet/Neural-Style</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../08_Convolutional_Neural_Networks/index.html#deep-dream">运用Deep Dream</a></li>
</ul>
<p class="caption"><span class="caption-text">递归神经网络(RNN)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../09_Recurrent_Neural_Networks/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../09_Recurrent_Neural_Networks/index.html#id2">卷积神经网络模型用于垃圾信息检测</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../09_Recurrent_Neural_Networks/index.html#lstm">LSTM模型用于文本生成</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../09_Recurrent_Neural_Networks/index.html#id3">堆叠多层LSTM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../09_Recurrent_Neural_Networks/index.html#seq2seq">创建段对段模型翻译 (Seq2Seq)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../09_Recurrent_Neural_Networks/index.html#siamese">训练Siamese相似度测量</a></li>
</ul>
<p class="caption"><span class="caption-text">TensorFlow的应用技巧</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../10_Taking_TensorFlow_to_Production/index.html">单元测试</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../10_Taking_TensorFlow_to_Production/index.html#id2">使用多个执行器 (设备)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../10_Taking_TensorFlow_to_Production/index.html#tensorflow">TensorFlow平行化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../10_Taking_TensorFlow_to_Production/index.html#id3">TensorFlow开发贴士</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../10_Taking_TensorFlow_to_Production/index.html#id4">TensorFlow开发实例</a></li>
</ul>
<p class="caption"><span class="caption-text">TensorFlow的更多功能</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../11_More_with_TensorFlow/index.html">计算图可视化(用Tensorboard)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../11_More_with_TensorFlow/index.html#id1">遗传算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../11_More_with_TensorFlow/index.html#k-means">K-means聚类分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../11_More_with_TensorFlow/index.html#id2">解决体系常微分方程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../11_More_with_TensorFlow/index.html#id3">随机森林</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../11_More_with_TensorFlow/index.html#tensorflowkeras">TensorFlow中的Keras</a></li>
</ul>
<p class="caption"><span class="caption-text">TF Cookbook</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html">书籍介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id2">第一章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id3">第二章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id4">第三章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id5">第四章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id6">第五章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id7">第六章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id8">第七章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id9">第八章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id10">第九章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id11">第十章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id12">第十一章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id13">索引</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">tensorflow</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>tensorflow.python.ops.gen_math_ops</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for tensorflow.python.ops.gen_math_ops</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Python wrappers around TensorFlow ops.</span>

<span class="sd">This file is MACHINE GENERATED! Do not edit.</span>
<span class="sd">Original C++ source file: math_ops.cc</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">collections</span>

<span class="kn">from</span> <span class="nn">tensorflow.python</span> <span class="k">import</span> <span class="n">pywrap_tfe</span> <span class="k">as</span> <span class="n">pywrap_tfe</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager</span> <span class="k">import</span> <span class="n">context</span> <span class="k">as</span> <span class="n">_context</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager</span> <span class="k">import</span> <span class="n">core</span> <span class="k">as</span> <span class="n">_core</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager</span> <span class="k">import</span> <span class="n">execute</span> <span class="k">as</span> <span class="n">_execute</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">dtypes</span> <span class="k">as</span> <span class="n">_dtypes</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">op_def_registry</span> <span class="k">as</span> <span class="n">_op_def_registry</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">ops</span> <span class="k">as</span> <span class="n">_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">op_def_library</span> <span class="k">as</span> <span class="n">_op_def_library</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util.deprecation</span> <span class="k">import</span> <span class="n">deprecated_endpoints</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util</span> <span class="k">import</span> <span class="n">dispatch</span> <span class="k">as</span> <span class="n">_dispatch</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util.tf_export</span> <span class="k">import</span> <span class="n">tf_export</span>


<span class="k">def</span> <span class="nf">_abs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the absolute value of a tensor.</span>

<span class="sd">  Given a tensor `x`, this operation returns a tensor containing the absolute</span>
<span class="sd">  value of each element in `x`. For example, if x is an input element and y is</span>
<span class="sd">  an output element, this operation computes \\(y = |x|\\).</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Abs&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_abs_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Abs&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Abs&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Abs</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Abs&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">_abs</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_abs_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Abs&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Abs&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">accumulate_nv2</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the element-wise sum of a list of tensors.</span>

<span class="sd">  `tf.accumulate_n_v2` performs the same operation as `tf.add_n`, but does not</span>
<span class="sd">  wait for all of its inputs to be ready before beginning to sum. This can</span>
<span class="sd">  save memory if inputs are ready at different times, since minimum temporary</span>
<span class="sd">  storage is proportional to the output size rather than the inputs size.</span>

<span class="sd">  Unlike the original `accumulate_n`, `accumulate_n_v2` is differentiable.</span>

<span class="sd">  Returns a `Tensor` of same shape and type as the elements of `inputs`.</span>

<span class="sd">  Args:</span>
<span class="sd">    inputs: A list of at least 1 `Tensor` objects with the same type in: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">      A list of `Tensor` objects, each with same shape and type.</span>
<span class="sd">    shape: A `tf.TensorShape` or list of `ints`.</span>
<span class="sd">      Shape of elements of `inputs`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `inputs`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;AccumulateNV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">accumulate_nv2_eager_fallback</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;inputs&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;accumulate_nv2&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">inputs</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;AccumulateNV2&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
              <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;AccumulateNV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">AccumulateNV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.AccumulateNV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">accumulate_nv2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">accumulate_nv2_eager_fallback</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;inputs&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;accumulate_nv2&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">inputs</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_attr_N</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;AccumulateNV2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;AccumulateNV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="acos"><a class="viewcode-back" href="../../../../index.html#tensorflow.acos">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.acos&#39;</span><span class="p">,</span> <span class="s1">&#39;acos&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">acos</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes acos of x element-wise.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Acos&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">acos_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">acos</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Acos&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">acos</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Acos&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Acos</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Acos&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">acos</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">acos_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Acos&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Acos&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="acosh"><a class="viewcode-back" href="../../../../index.html#tensorflow.acosh">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.acosh&#39;</span><span class="p">,</span> <span class="s1">&#39;acosh&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">acosh</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes inverse hyperbolic cosine of x element-wise.</span>

<span class="sd">  Given an input tensor, the function computes inverse hyperbolic cosine of every element.</span>
<span class="sd">  Input range is `[1, inf]`. It returns `nan` if the input lies outside the range.</span>

<span class="sd">  ```python</span>
<span class="sd">  x = tf.constant([-2, -0.5, 1, 1.2, 200, 10000, float(&quot;inf&quot;)])</span>
<span class="sd">  tf.math.acosh(x) ==&gt; [nan nan 0. 0.62236255 5.9914584 9.903487 inf]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Acosh&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">acosh_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">acosh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Acosh&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">acosh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Acosh&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Acosh</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Acosh&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">acosh</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">acosh_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Acosh&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Acosh&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="add"><a class="viewcode-back" href="../../../../index.html#tensorflow.add">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.add&#39;</span><span class="p">,</span> <span class="s1">&#39;add&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns x + y element-wise.</span>

<span class="sd">  *NOTE*: `math.add` supports broadcasting. `AddN` does not. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `string`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Add&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">add_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">add</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Add&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">add</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Add&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Add</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Add&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">add</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">add_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Add&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Add&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">add_n</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Add all input tensors element wise.</span>

<span class="sd">    Inputs must be of same size and shape.</span>

<span class="sd">    ```python</span>
<span class="sd">    x = [9, 7, 10]</span>
<span class="sd">    tf.math.add_n(x) ==&gt; 26</span>
<span class="sd">    ```</span>

<span class="sd">  Args:</span>
<span class="sd">    inputs: A list of at least 1 `Tensor` objects with the same type in: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`, `variant`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `inputs`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;AddN&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">add_n_eager_fallback</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;inputs&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;add_n&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">inputs</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;AddN&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;AddN&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">AddN</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.AddN&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">add_n</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">add_n_eager_fallback</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;inputs&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;add_n&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">inputs</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_attr_N</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;AddN&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;AddN&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">add_v2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns x + y element-wise.</span>

<span class="sd">  *NOTE*: `Add` supports broadcasting. `AddN` does not. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;AddV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">add_v2_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;AddV2&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;AddV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">AddV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.AddV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">add_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">add_v2_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;AddV2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;AddV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">_all</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the &quot;logical and&quot; of elements across dimensions of a tensor.</span>

<span class="sd">  Reduces `input` along the dimensions given in `axis`. Unless</span>
<span class="sd">  `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in</span>
<span class="sd">  `axis`. If `keep_dims` is true, the reduced dimensions are</span>
<span class="sd">  retained with length 1.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor` of type `bool`. The tensor to reduce.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      The dimensions to reduce. Must be in the range</span>
<span class="sd">      `[-rank(input), rank(input))`.</span>
<span class="sd">    keep_dims: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If true, retain reduced dimensions with length 1.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;All&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_all_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;All&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;All&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">All</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.All&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">_all</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_all_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="nb">input</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;All&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;All&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">angle</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the argument of a complex number.</span>

<span class="sd">  Given a tensor `input` of complex numbers, this operation returns a tensor of</span>
<span class="sd">  type `float` that is the argument of each element in `input`. All elements in</span>
<span class="sd">  `input` must be complex numbers of the form \\(a + bj\\), where *a*</span>
<span class="sd">  is the real part and *b* is the imaginary part.</span>

<span class="sd">  The argument returned by this operation is of the form \\(atan2(b, a)\\).</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;input&#39; is [-2.25 + 4.75j, 3.25 + 5.75j]</span>
<span class="sd">  tf.angle(input) ==&gt; [2.0132, 1.056]</span>
<span class="sd">  ```</span>

<span class="sd">  @compatibility(numpy)</span>
<span class="sd">  Equivalent to np.angle.</span>
<span class="sd">  @end_compatibility</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.</span>
<span class="sd">    Tout: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `Tout`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Angle&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span> <span class="n">Tout</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">angle_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">Tout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Tout</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span>
  <span class="n">Tout</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Tout</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Angle&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tout&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Angle&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Angle</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Angle&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">angle</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">angle_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">Tout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Tout</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span>
  <span class="n">Tout</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Tout</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">complex64</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span> <span class="n">Tout</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Angle&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Angle&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">_any</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the &quot;logical or&quot; of elements across dimensions of a tensor.</span>

<span class="sd">  Reduces `input` along the dimensions given in `axis`. Unless</span>
<span class="sd">  `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in</span>
<span class="sd">  `axis`. If `keep_dims` is true, the reduced dimensions are</span>
<span class="sd">  retained with length 1.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor` of type `bool`. The tensor to reduce.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      The dimensions to reduce. Must be in the range</span>
<span class="sd">      `[-rank(input), rank(input))`.</span>
<span class="sd">    keep_dims: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If true, retain reduced dimensions with length 1.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Any&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_any_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Any&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Any&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Any</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Any&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">_any</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_any_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="nb">input</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Any&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Any&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">approximate_equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the truth value of abs(x-y) &lt; tolerance element-wise.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    tolerance: An optional `float`. Defaults to `1e-05`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ApproximateEqual&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;tolerance&quot;</span><span class="p">,</span> <span class="n">tolerance</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">approximate_equal_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="n">tolerance</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">tolerance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">tolerance</span> <span class="o">=</span> <span class="mf">1e-05</span>
  <span class="n">tolerance</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">tolerance</span><span class="p">,</span> <span class="s2">&quot;tolerance&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ApproximateEqual&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="n">tolerance</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;tolerance&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;tolerance&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ApproximateEqual&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ApproximateEqual</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ApproximateEqual&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">approximate_equal</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">approximate_equal_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">tolerance</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">tolerance</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">tolerance</span> <span class="o">=</span> <span class="mf">1e-05</span>
  <span class="n">tolerance</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">tolerance</span><span class="p">,</span> <span class="s2">&quot;tolerance&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;tolerance&quot;</span><span class="p">,</span> <span class="n">tolerance</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ApproximateEqual&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ApproximateEqual&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">arg_max</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the index with the largest value across dimensions of a tensor.</span>

<span class="sd">  Note that in case of ties the identity of the return value is not guaranteed.</span>

<span class="sd">  Usage:</span>
<span class="sd">    ```python</span>
<span class="sd">    import tensorflow as tf</span>
<span class="sd">    a = [1, 10, 26.9, 2.8, 166.32, 62.3]</span>
<span class="sd">    b = tf.math.argmax(input = a)</span>
<span class="sd">    c = tf.keras.backend.eval(b)</span>
<span class="sd">    # c = 4</span>
<span class="sd">    # here a[4] = 166.32 which is the largest element of a across axis 0</span>
<span class="sd">    ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    dimension: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      int32 or int64, must be in the range `[-rank(input), rank(input))`.</span>
<span class="sd">      Describes which dimension of the input Tensor to reduce across. For vectors,</span>
<span class="sd">      use dimension = 0.</span>
<span class="sd">    output_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `output_type`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ArgMax&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="s2">&quot;output_type&quot;</span><span class="p">,</span> <span class="n">output_type</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">arg_max_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">output_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">output_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">output_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span>
  <span class="n">output_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">output_type</span><span class="p">,</span> <span class="s2">&quot;output_type&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ArgMax&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="n">dimension</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">output_type</span><span class="p">,</span>
                  <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">),</span> <span class="s2">&quot;output_type&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;output_type&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ArgMax&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ArgMax</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ArgMax&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">arg_max</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">arg_max_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">output_type</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">output_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">output_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span>
  <span class="n">output_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">output_type</span><span class="p">,</span> <span class="s2">&quot;output_type&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">dimension</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">dimension</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">dimension</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="s2">&quot;output_type&quot;</span><span class="p">,</span> <span class="n">output_type</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ArgMax&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ArgMax&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">arg_min</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the index with the smallest value across dimensions of a tensor.</span>

<span class="sd">  Note that in case of ties the identity of the return value is not guaranteed.</span>

<span class="sd">  Usage:</span>
<span class="sd">    ```python</span>
<span class="sd">    import tensorflow as tf</span>
<span class="sd">    a = [1, 10, 26.9, 2.8, 166.32, 62.3]</span>
<span class="sd">    b = tf.math.argmin(input = a)</span>
<span class="sd">    c = tf.keras.backend.eval(b)</span>
<span class="sd">    # c = 0</span>
<span class="sd">    # here a[0] = 1 which is the smallest element of a across axis 0</span>
<span class="sd">    ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    dimension: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      int32 or int64, must be in the range `[-rank(input), rank(input))`.</span>
<span class="sd">      Describes which dimension of the input Tensor to reduce across. For vectors,</span>
<span class="sd">      use dimension = 0.</span>
<span class="sd">    output_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `output_type`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ArgMin&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="s2">&quot;output_type&quot;</span><span class="p">,</span> <span class="n">output_type</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">arg_min_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">output_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">output_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">output_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span>
  <span class="n">output_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">output_type</span><span class="p">,</span> <span class="s2">&quot;output_type&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ArgMin&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="n">dimension</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">output_type</span><span class="p">,</span>
                  <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">),</span> <span class="s2">&quot;output_type&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;output_type&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ArgMin&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ArgMin</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ArgMin&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">arg_min</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">arg_min_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">output_type</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">output_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">output_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span>
  <span class="n">output_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">output_type</span><span class="p">,</span> <span class="s2">&quot;output_type&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">dimension</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">dimension</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">dimension</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="s2">&quot;output_type&quot;</span><span class="p">,</span> <span class="n">output_type</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ArgMin&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ArgMin&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="asin"><a class="viewcode-back" href="../../../../index.html#tensorflow.asin">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.asin&#39;</span><span class="p">,</span> <span class="s1">&#39;asin&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">asin</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the trignometric inverse sine of x element-wise.</span>

<span class="sd">  The `tf.math.asin` operation returns the inverse of `tf.math.sin`, such that</span>
<span class="sd">  if `y = tf.math.sin(x)` then, `x = tf.math.asin(y)`.</span>

<span class="sd">  **Note**: The output of `tf.math.asin` will lie within the invertible range</span>
<span class="sd">  of sine, i.e [-pi/2, pi/2].</span>

<span class="sd">  For example:</span>

<span class="sd">  ```python</span>
<span class="sd">  # Note: [1.047, 0.785] ~= [(pi/3), (pi/4)]</span>
<span class="sd">  x = tf.constant([1.047, 0.785])</span>
<span class="sd">  y = tf.math.sin(x) # [0.8659266, 0.7068252]</span>

<span class="sd">  tf.math.asin(y) # [1.047, 0.785] = x</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Asin&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">asin_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">asin</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Asin&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">asin</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Asin&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Asin</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Asin&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">asin</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">asin_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Asin&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Asin&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="asinh"><a class="viewcode-back" href="../../../../index.html#tensorflow.asinh">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.asinh&#39;</span><span class="p">,</span> <span class="s1">&#39;asinh&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">asinh</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes inverse hyperbolic sine of x element-wise.</span>

<span class="sd">    Given an input tensor, this function computes inverse hyperbolic sine</span>
<span class="sd">    for every element in the tensor. Both input and output has a range of</span>
<span class="sd">    `[-inf, inf]`.</span>

<span class="sd">    ```python</span>
<span class="sd">    x = tf.constant([-float(&quot;inf&quot;), -2, -0.5, 1, 1.2, 200, 10000, float(&quot;inf&quot;)])</span>
<span class="sd">    tf.math.asinh(x) ==&gt; [-inf -1.4436355 -0.4812118 0.8813736 1.0159732 5.991471 9.903487 inf]</span>
<span class="sd">    ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Asinh&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">asinh_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">asinh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Asinh&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">asinh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Asinh&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Asinh</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Asinh&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">asinh</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">asinh_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Asinh&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Asinh&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="atan"><a class="viewcode-back" href="../../../../index.html#tensorflow.atan">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.atan&#39;</span><span class="p">,</span> <span class="s1">&#39;atan&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">atan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the trignometric inverse tangent of x element-wise.</span>

<span class="sd">  The `tf.math.atan` operation returns the inverse of `tf.math.tan`, such that</span>
<span class="sd">  if `y = tf.math.tan(x)` then, `x = tf.math.atan(y)`.</span>

<span class="sd">  **Note**: The output of `tf.math.atan` will lie within the invertible range</span>
<span class="sd">  of tan, i.e (-pi/2, pi/2).</span>

<span class="sd">  For example:</span>

<span class="sd">  ```python</span>
<span class="sd">  # Note: [1.047, 0.785] ~= [(pi/3), (pi/4)]</span>
<span class="sd">  x = tf.constant([1.047, 0.785])</span>
<span class="sd">  y = tf.math.tan(x) # [1.731261, 0.99920404]</span>

<span class="sd">  tf.math.atan(y) # [1.047, 0.785] = x</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Atan&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">atan_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">atan</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Atan&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">atan</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Atan&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Atan</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Atan&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">atan</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">atan_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Atan&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Atan&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="atan2"><a class="viewcode-back" href="../../../../index.html#tensorflow.atan2">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.atan2&#39;</span><span class="p">,</span> <span class="s1">&#39;atan2&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">atan2</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes arctangent of `y/x` element-wise, respecting signs of the arguments.</span>

<span class="sd">  This is the angle \( \theta \in [-\pi, \pi] \) such that</span>
<span class="sd">  \[ x = r \cos(\theta) \]</span>
<span class="sd">  and</span>
<span class="sd">  \[ y = r \sin(\theta) \]</span>
<span class="sd">  where \(r = \sqrt(x^2 + y^2) \).</span>

<span class="sd">  Args:</span>
<span class="sd">    y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    x: A `Tensor`. Must have the same type as `y`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `y`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Atan2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">atan2_eager_fallback</span><span class="p">(</span>
            <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">atan2</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Atan2&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">atan2</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Atan2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Atan2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Atan2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">atan2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">atan2_eager_fallback</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Atan2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Atan2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="atanh"><a class="viewcode-back" href="../../../../index.html#tensorflow.atanh">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.atanh&#39;</span><span class="p">,</span> <span class="s1">&#39;atanh&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">atanh</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes inverse hyperbolic tangent of x element-wise.</span>

<span class="sd">    Given an input tensor, this function computes inverse hyperbolic tangent</span>
<span class="sd">    for every element in the tensor. Input range is `[-1,1]` and output range is</span>
<span class="sd">    `[-inf, inf]`. If input is `-1`, output will be `-inf` and if the</span>
<span class="sd">    input is `1`, output will be `inf`. Values outside the range will have</span>
<span class="sd">    `nan` as output.</span>

<span class="sd">    ```python</span>
<span class="sd">    x = tf.constant([-float(&quot;inf&quot;), -1, -0.5, 1, 0, 0.5, 10, float(&quot;inf&quot;)])</span>
<span class="sd">    tf.math.atanh(x) ==&gt; [nan -inf -0.54930615 inf  0. 0.54930615 nan nan]</span>
<span class="sd">    ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Atanh&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">atanh_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">atanh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Atanh&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">atanh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Atanh&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Atanh</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Atanh&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">atanh</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">atanh_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Atanh&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Atanh&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">batch_mat_mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">adj_x</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">adj_y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Multiplies slices of two tensors in batches.</span>

<span class="sd">  Multiplies all slices of `Tensor` `x` and `y` (each slice can be</span>
<span class="sd">  viewed as an element of a batch), and arranges the individual results</span>
<span class="sd">  in a single output tensor of the same batch size. Each of the</span>
<span class="sd">  individual slices can optionally be adjointed (to adjoint a matrix</span>
<span class="sd">  means to transpose and conjugate it) before multiplication by setting</span>
<span class="sd">  the `adj_x` or `adj_y` flag to `True`, which are by default `False`.</span>

<span class="sd">  The input tensors `x` and `y` are 2-D or higher with shape `[..., r_x, c_x]`</span>
<span class="sd">  and `[..., r_y, c_y]`.</span>

<span class="sd">  The output tensor is 2-D or higher with shape `[..., r_o, c_o]`, where:</span>

<span class="sd">      r_o = c_x if adj_x else r_x</span>
<span class="sd">      c_o = r_y if adj_y else c_y</span>

<span class="sd">  It is computed as:</span>

<span class="sd">      output[..., :, :] = matrix(x[..., :, :]) * matrix(y[..., :, :])</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">      2-D or higher with shape `[..., r_x, c_x]`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">      2-D or higher with shape `[..., r_y, c_y]`.</span>
<span class="sd">    adj_x: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If `True`, adjoint the slices of `x`. Defaults to `False`.</span>
<span class="sd">    adj_y: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If `True`, adjoint the slices of `y`. Defaults to `False`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;BatchMatMul&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;adj_x&quot;</span><span class="p">,</span> <span class="n">adj_x</span><span class="p">,</span> <span class="s2">&quot;adj_y&quot;</span><span class="p">,</span> <span class="n">adj_y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">batch_mat_mul_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">adj_x</span><span class="o">=</span><span class="n">adj_x</span><span class="p">,</span> <span class="n">adj_y</span><span class="o">=</span><span class="n">adj_y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">adj_x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">adj_x</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">adj_x</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">adj_x</span><span class="p">,</span> <span class="s2">&quot;adj_x&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">adj_y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">adj_y</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">adj_y</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">adj_y</span><span class="p">,</span> <span class="s2">&quot;adj_y&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatMul&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">adj_x</span><span class="o">=</span><span class="n">adj_x</span><span class="p">,</span> <span class="n">adj_y</span><span class="o">=</span><span class="n">adj_y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;adj_x&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;adj_x&quot;</span><span class="p">),</span> <span class="s2">&quot;adj_y&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;adj_y&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatMul&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">BatchMatMul</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.BatchMatMul&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">batch_mat_mul</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">batch_mat_mul_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">adj_x</span><span class="p">,</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">adj_x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">adj_x</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">adj_x</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">adj_x</span><span class="p">,</span> <span class="s2">&quot;adj_x&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">adj_y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">adj_y</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">adj_y</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">adj_y</span><span class="p">,</span> <span class="s2">&quot;adj_y&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;adj_x&quot;</span><span class="p">,</span> <span class="n">adj_x</span><span class="p">,</span> <span class="s2">&quot;adj_y&quot;</span><span class="p">,</span> <span class="n">adj_y</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;BatchMatMul&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatMul&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">batch_mat_mul_v2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">adj_x</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">adj_y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Multiplies slices of two tensors in batches.</span>

<span class="sd">  Multiplies all slices of `Tensor` `x` and `y` (each slice can be</span>
<span class="sd">  viewed as an element of a batch), and arranges the individual results</span>
<span class="sd">  in a single output tensor of the same batch size. Each of the</span>
<span class="sd">  individual slices can optionally be adjointed (to adjoint a matrix</span>
<span class="sd">  means to transpose and conjugate it) before multiplication by setting</span>
<span class="sd">  the `adj_x` or `adj_y` flag to `True`, which are by default `False`.</span>

<span class="sd">  The input tensors `x` and `y` are 2-D or higher with shape `[..., r_x, c_x]`</span>
<span class="sd">  and `[..., r_y, c_y]`.</span>

<span class="sd">  The output tensor is 2-D or higher with shape `[..., r_o, c_o]`, where:</span>

<span class="sd">      r_o = c_x if adj_x else r_x</span>
<span class="sd">      c_o = r_y if adj_y else c_y</span>

<span class="sd">  It is computed as:</span>

<span class="sd">      output[..., :, :] = matrix(x[..., :, :]) * matrix(y[..., :, :])</span>

<span class="sd">  *NOTE*: `BatchMatMulV2` supports broadcasting in the batch dimensions. More</span>
<span class="sd">  about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">      2-D or higher with shape `[..., r_x, c_x]`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">      2-D or higher with shape `[..., r_y, c_y]`.</span>
<span class="sd">    adj_x: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If `True`, adjoint the slices of `x`. Defaults to `False`.</span>
<span class="sd">    adj_y: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If `True`, adjoint the slices of `y`. Defaults to `False`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;BatchMatMulV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;adj_x&quot;</span><span class="p">,</span> <span class="n">adj_x</span><span class="p">,</span> <span class="s2">&quot;adj_y&quot;</span><span class="p">,</span> <span class="n">adj_y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">batch_mat_mul_v2_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">adj_x</span><span class="o">=</span><span class="n">adj_x</span><span class="p">,</span> <span class="n">adj_y</span><span class="o">=</span><span class="n">adj_y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">adj_x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">adj_x</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">adj_x</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">adj_x</span><span class="p">,</span> <span class="s2">&quot;adj_x&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">adj_y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">adj_y</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">adj_y</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">adj_y</span><span class="p">,</span> <span class="s2">&quot;adj_y&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatMulV2&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">adj_x</span><span class="o">=</span><span class="n">adj_x</span><span class="p">,</span> <span class="n">adj_y</span><span class="o">=</span><span class="n">adj_y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;adj_x&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;adj_x&quot;</span><span class="p">),</span> <span class="s2">&quot;adj_y&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;adj_y&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatMulV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">BatchMatMulV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.BatchMatMulV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">batch_mat_mul_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">batch_mat_mul_v2_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">adj_x</span><span class="p">,</span> <span class="n">adj_y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">adj_x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">adj_x</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">adj_x</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">adj_x</span><span class="p">,</span> <span class="s2">&quot;adj_x&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">adj_y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">adj_y</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">adj_y</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">adj_y</span><span class="p">,</span> <span class="s2">&quot;adj_y&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;adj_x&quot;</span><span class="p">,</span> <span class="n">adj_x</span><span class="p">,</span> <span class="s2">&quot;adj_y&quot;</span><span class="p">,</span> <span class="n">adj_y</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;BatchMatMulV2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatMulV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.bessel_i0e&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">bessel_i0e</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the Bessel i0e function of `x` element-wise.</span>

<span class="sd">  Exponentially scaled modified Bessel function of order 0 defined as</span>
<span class="sd">  `bessel_i0e(x) = exp(-abs(x)) bessel_i0(x)`.</span>

<span class="sd">  This function is faster and numerically stabler than `bessel_i0(x)`.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;BesselI0e&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">bessel_i0e_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">bessel_i0e</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;BesselI0e&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">bessel_i0e</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BesselI0e&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">BesselI0e</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.BesselI0e&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">bessel_i0e</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">bessel_i0e_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;BesselI0e&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BesselI0e&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.bessel_i1e&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">bessel_i1e</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the Bessel i1e function of `x` element-wise.</span>

<span class="sd">  Exponentially scaled modified Bessel function of order 0 defined as</span>
<span class="sd">  `bessel_i1e(x) = exp(-abs(x)) bessel_i1(x)`.</span>

<span class="sd">  This function is faster and numerically stabler than `bessel_i1(x)`.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;BesselI1e&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">bessel_i1e_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">bessel_i1e</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;BesselI1e&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">bessel_i1e</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BesselI1e&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">BesselI1e</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.BesselI1e&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">bessel_i1e</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">bessel_i1e_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;BesselI1e&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BesselI1e&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.betainc&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.betainc&#39;</span><span class="p">,</span> <span class="s1">&#39;betainc&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;betainc&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">betainc</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the regularized incomplete beta integral \\(I_x(a, b)\\).</span>

<span class="sd">  The regularized incomplete beta integral is defined as:</span>


<span class="sd">  \\(I_x(a, b) = \frac{B(x; a, b)}{B(a, b)}\\)</span>

<span class="sd">  where</span>


<span class="sd">  \\(B(x; a, b) = \int_0^x t^{a-1} (1 - t)^{b-1} dt\\)</span>


<span class="sd">  is the incomplete beta function and \\(B(a, b)\\) is the *complete*</span>
<span class="sd">  beta function.</span>

<span class="sd">  Args:</span>
<span class="sd">    a: A `Tensor`. Must be one of the following types: `float32`, `float64`.</span>
<span class="sd">    b: A `Tensor`. Must have the same type as `a`.</span>
<span class="sd">    x: A `Tensor`. Must have the same type as `a`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `a`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Betainc&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">betainc_eager_fallback</span><span class="p">(</span>
            <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">betainc</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Betainc&quot;</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">betainc</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Betainc&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Betainc</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Betainc&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">betainc</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">betainc_eager_fallback</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Betainc&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Betainc&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">bincount</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Counts the number of occurrences of each value in an integer array.</span>

<span class="sd">  Outputs a vector with length `size` and the same dtype as `weights`. If</span>
<span class="sd">  `weights` are empty, then index `i` stores the number of times the value `i` is</span>
<span class="sd">  counted in `arr`. If `weights` are non-empty, then index `i` stores the sum of</span>
<span class="sd">  the value in `weights` at each index where the corresponding value in `arr` is</span>
<span class="sd">  `i`.</span>

<span class="sd">  Values in `arr` outside of the range [0, size) are ignored.</span>

<span class="sd">  Args:</span>
<span class="sd">    arr: A `Tensor` of type `int32`. int32 `Tensor`.</span>
<span class="sd">    size: A `Tensor` of type `int32`. non-negative int32 scalar `Tensor`.</span>
<span class="sd">    weights: A `Tensor`. Must be one of the following types: `int32`, `int64`, `float32`, `float64`.</span>
<span class="sd">      is an int32, int64, float32, or float64 `Tensor` with the same</span>
<span class="sd">      shape as `arr`, or a length-0 `Tensor`, in which case it acts as all weights</span>
<span class="sd">      equal to 1.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `weights`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Bincount&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">arr</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">bincount_eager_fallback</span><span class="p">(</span>
            <span class="n">arr</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Bincount&quot;</span><span class="p">,</span> <span class="n">arr</span><span class="o">=</span><span class="n">arr</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Bincount&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Bincount</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Bincount&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">bincount</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">bincount_eager_fallback</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">weights</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">weights</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">arr</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">size</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">arr</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">weights</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Bincount&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Bincount&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">bucketize</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Bucketizes &#39;input&#39; based on &#39;boundaries&#39;.</span>

<span class="sd">  For example, if the inputs are</span>
<span class="sd">      boundaries = [0, 10, 100]</span>
<span class="sd">      input = [[-5, 10000]</span>
<span class="sd">               [150,   10]</span>
<span class="sd">               [5,    100]]</span>

<span class="sd">  then the output will be</span>
<span class="sd">      output = [[0, 3]</span>
<span class="sd">                [3, 2]</span>
<span class="sd">                [1, 3]]</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `int32`, `int64`, `float32`, `float64`.</span>
<span class="sd">      Any shape of Tensor contains with int or float type.</span>
<span class="sd">    boundaries: A list of `floats`.</span>
<span class="sd">      A sorted list of floats gives the boundary of the buckets.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `int32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Bucketize&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;boundaries&quot;</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">bucketize_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">boundaries</span><span class="o">=</span><span class="n">boundaries</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">boundaries</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;boundaries&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;bucketize&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">boundaries</span><span class="p">)</span>
  <span class="n">boundaries</span> <span class="o">=</span> <span class="p">[</span><span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">_f</span><span class="p">,</span> <span class="s2">&quot;boundaries&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_f</span> <span class="ow">in</span> <span class="n">boundaries</span><span class="p">]</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Bucketize&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">boundaries</span><span class="o">=</span><span class="n">boundaries</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;boundaries&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;boundaries&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Bucketize&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Bucketize</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Bucketize&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">bucketize</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">bucketize_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">boundaries</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;boundaries&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;bucketize&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">boundaries</span><span class="p">)</span>
  <span class="n">boundaries</span> <span class="o">=</span> <span class="p">[</span><span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">_f</span><span class="p">,</span> <span class="s2">&quot;boundaries&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_f</span> <span class="ow">in</span> <span class="n">boundaries</span><span class="p">]</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;boundaries&quot;</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Bucketize&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Bucketize&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">DstT</span><span class="p">,</span> <span class="n">Truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Cast x of type SrcT to y of DstT.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`.</span>
<span class="sd">    DstT: A `tf.DType`.</span>
<span class="sd">    Truncate: An optional `bool`. Defaults to `False`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `DstT`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Cast&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;DstT&quot;</span><span class="p">,</span> <span class="n">DstT</span><span class="p">,</span> <span class="s2">&quot;Truncate&quot;</span><span class="p">,</span> <span class="n">Truncate</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cast_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">DstT</span><span class="o">=</span><span class="n">DstT</span><span class="p">,</span> <span class="n">Truncate</span><span class="o">=</span><span class="n">Truncate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">DstT</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">DstT</span><span class="p">,</span> <span class="s2">&quot;DstT&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">Truncate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Truncate</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">Truncate</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">Truncate</span><span class="p">,</span> <span class="s2">&quot;Truncate&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Cast&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">DstT</span><span class="o">=</span><span class="n">DstT</span><span class="p">,</span> <span class="n">Truncate</span><span class="o">=</span><span class="n">Truncate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;SrcT&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;SrcT&quot;</span><span class="p">),</span> <span class="s2">&quot;DstT&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;DstT&quot;</span><span class="p">),</span> <span class="s2">&quot;Truncate&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;Truncate&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Cast&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Cast</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Cast&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">cast</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">cast_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">DstT</span><span class="p">,</span> <span class="n">Truncate</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">DstT</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">DstT</span><span class="p">,</span> <span class="s2">&quot;DstT&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">Truncate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Truncate</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">Truncate</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">Truncate</span><span class="p">,</span> <span class="s2">&quot;Truncate&quot;</span><span class="p">)</span>
  <span class="n">_attr_SrcT</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;SrcT&quot;</span><span class="p">,</span> <span class="n">_attr_SrcT</span><span class="p">,</span> <span class="s2">&quot;DstT&quot;</span><span class="p">,</span> <span class="n">DstT</span><span class="p">,</span> <span class="s2">&quot;Truncate&quot;</span><span class="p">,</span> <span class="n">Truncate</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Cast&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Cast&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">ceil</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns element-wise smallest integer not less than x.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Ceil&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ceil_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Ceil&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Ceil&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Ceil</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Ceil&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">ceil</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">ceil_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Ceil&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Ceil&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">_clip_by_value</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">clip_value_min</span><span class="p">,</span> <span class="n">clip_value_max</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Clips tensor values to a specified min and max.</span>

<span class="sd">  Given a tensor `t`, this operation returns a tensor of the same type and</span>
<span class="sd">  shape as `t` with its values clipped to `clip_value_min` and `clip_value_max`.</span>
<span class="sd">  Any values less than `clip_value_min` are set to `clip_value_min`. Any values</span>
<span class="sd">  greater than `clip_value_max` are set to `clip_value_max`.</span>

<span class="sd">  Args:</span>
<span class="sd">    t: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">      A `Tensor`.</span>
<span class="sd">    clip_value_min: A `Tensor`. Must have the same type as `t`.</span>
<span class="sd">      A 0-D (scalar) `Tensor`, or a `Tensor` with the same shape</span>
<span class="sd">      as `t`. The minimum value to clip by.</span>
<span class="sd">    clip_value_max: A `Tensor`. Must have the same type as `t`.</span>
<span class="sd">      A 0-D (scalar) `Tensor`, or a `Tensor` with the same shape</span>
<span class="sd">      as `t`. The maximum value to clip by.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `t`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ClipByValue&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">clip_value_min</span><span class="p">,</span> <span class="n">clip_value_max</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_clip_by_value_eager_fallback</span><span class="p">(</span>
            <span class="n">t</span><span class="p">,</span> <span class="n">clip_value_min</span><span class="p">,</span> <span class="n">clip_value_max</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ClipByValue&quot;</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">clip_value_min</span><span class="o">=</span><span class="n">clip_value_min</span><span class="p">,</span>
                       <span class="n">clip_value_max</span><span class="o">=</span><span class="n">clip_value_max</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ClipByValue&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ClipByValue</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ClipByValue&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">_clip_by_value</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_clip_by_value_eager_fallback</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">clip_value_min</span><span class="p">,</span> <span class="n">clip_value_max</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">t</span><span class="p">,</span> <span class="n">clip_value_min</span><span class="p">,</span> <span class="n">clip_value_max</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">clip_value_min</span><span class="p">,</span> <span class="n">clip_value_max</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">clip_value_min</span><span class="p">,</span> <span class="n">clip_value_max</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ClipByValue&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ClipByValue&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">compare_and_bitpack</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compare values of `input` to `threshold` and pack resulting bits into a `uint8`.</span>

<span class="sd">  Each comparison returns a boolean `true` (if `input_value &gt; threshold`)</span>
<span class="sd">  or and `false` otherwise.</span>

<span class="sd">  This operation is useful for Locality-Sensitive-Hashing (LSH) and other</span>
<span class="sd">  algorithms that use hashing approximations of cosine and `L2` distances;</span>
<span class="sd">  codes can be generated from an input via:</span>

<span class="sd">  ```python</span>
<span class="sd">  codebook_size = 50</span>
<span class="sd">  codebook_bits = codebook_size * 32</span>
<span class="sd">  codebook = tf.get_variable(&#39;codebook&#39;, [x.shape[-1].value, codebook_bits],</span>
<span class="sd">                             dtype=x.dtype,</span>
<span class="sd">                             initializer=tf.orthogonal_initializer())</span>
<span class="sd">  codes = compare_and_threshold(tf.matmul(x, codebook), threshold=0.)</span>
<span class="sd">  codes = tf.bitcast(codes, tf.int32)  # go from uint8 to int32</span>
<span class="sd">  # now codes has shape x.shape[:-1] + [codebook_size]</span>
<span class="sd">  ```</span>

<span class="sd">  **NOTE**: Currently, the innermost dimension of the tensor must be divisible</span>
<span class="sd">  by 8.</span>

<span class="sd">  Given an `input` shaped `[s0, s1, ..., s_n]`, the output is</span>
<span class="sd">  a `uint8` tensor shaped `[s0, s1, ..., s_n / 8]`.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `bool`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`.</span>
<span class="sd">      Values to compare against `threshold` and bitpack.</span>
<span class="sd">    threshold: A `Tensor`. Must have the same type as `input`.</span>
<span class="sd">      Threshold to compare against.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `uint8`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;CompareAndBitpack&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">compare_and_bitpack_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;CompareAndBitpack&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;CompareAndBitpack&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">CompareAndBitpack</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.CompareAndBitpack&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">compare_and_bitpack</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">compare_and_bitpack_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">threshold</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">threshold</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;CompareAndBitpack&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;CompareAndBitpack&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">_complex</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">complex64</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Converts two real numbers to a complex number.</span>

<span class="sd">  Given a tensor `real` representing the real part of a complex number, and a</span>
<span class="sd">  tensor `imag` representing the imaginary part of a complex number, this</span>
<span class="sd">  operation returns complex numbers elementwise of the form \\(a + bj\\), where</span>
<span class="sd">  *a* represents the `real` part and *b* represents the `imag` part.</span>

<span class="sd">  The input tensors `real` and `imag` must have the same shape.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;real&#39; is [2.25, 3.25]</span>
<span class="sd">  # tensor `imag` is [4.75, 5.75]</span>
<span class="sd">  tf.complex(real, imag) ==&gt; [[2.25 + 4.75j], [3.25 + 5.75j]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    real: A `Tensor`. Must be one of the following types: `float32`, `float64`.</span>
<span class="sd">    imag: A `Tensor`. Must have the same type as `real`.</span>
<span class="sd">    Tout: An optional `tf.DType` from: `tf.complex64, tf.complex128`. Defaults to `tf.complex64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `Tout`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Complex&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span> <span class="n">Tout</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_complex_eager_fallback</span><span class="p">(</span>
            <span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">Tout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Tout</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">complex64</span>
  <span class="n">Tout</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Tout</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Complex&quot;</span><span class="p">,</span> <span class="n">real</span><span class="o">=</span><span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="o">=</span><span class="n">imag</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tout&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Complex&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Complex</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Complex&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">_complex</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_complex_eager_fallback</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="p">,</span> <span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">Tout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Tout</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">complex64</span>
  <span class="n">Tout</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Tout</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span> <span class="n">Tout</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Complex&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Complex&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">complex_abs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the complex absolute value of a tensor.</span>

<span class="sd">  Given a tensor `x` of complex numbers, this operation returns a tensor of type</span>
<span class="sd">  `float` or `double` that is the absolute value of each element in `x`. All</span>
<span class="sd">  elements in `x` must be complex numbers of the form \\(a + bj\\). The absolute</span>
<span class="sd">  value is computed as \\( \sqrt{a^2 + b^2}\\).</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.</span>
<span class="sd">    Tout: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `Tout`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ComplexAbs&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span> <span class="n">Tout</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">complex_abs_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">Tout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Tout</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span>
  <span class="n">Tout</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Tout</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ComplexAbs&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tout&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ComplexAbs&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ComplexAbs</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ComplexAbs&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">complex_abs</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">complex_abs_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">Tout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Tout</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span>
  <span class="n">Tout</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Tout</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">complex64</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span> <span class="n">Tout</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ComplexAbs&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ComplexAbs&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">conj</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the complex conjugate of a complex number.</span>

<span class="sd">  Given a tensor `input` of complex numbers, this operation returns a tensor of</span>
<span class="sd">  complex numbers that are the complex conjugate of each element in `input`. The</span>
<span class="sd">  complex numbers in `input` must be of the form \\(a + bj\\), where *a* is the</span>
<span class="sd">  real part and *b* is the imaginary part.</span>

<span class="sd">  The complex conjugate returned by this operation is of the form \\(a - bj\\).</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;input&#39; is [-2.25 + 4.75j, 3.25 + 5.75j]</span>
<span class="sd">  tf.conj(input) ==&gt; [-2.25 - 4.75j, 3.25 - 5.75j]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`, `variant`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Conj&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">conj_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Conj&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Conj&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Conj</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Conj&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">conj</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">conj_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">complex64</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Conj&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Conj&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="cos"><a class="viewcode-back" href="../../../../index.html#tensorflow.cos">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.cos&#39;</span><span class="p">,</span> <span class="s1">&#39;cos&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">cos</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes cos of x element-wise.</span>

<span class="sd">    Given an input tensor, this function computes cosine of every</span>
<span class="sd">    element in the tensor. Input range is `(-inf, inf)` and</span>
<span class="sd">    output range is `[-1,1]`. If input lies outside the boundary, `nan`</span>
<span class="sd">    is returned.</span>

<span class="sd">    ```python</span>
<span class="sd">    x = tf.constant([-float(&quot;inf&quot;), -9, -0.5, 1, 1.2, 200, 10000, float(&quot;inf&quot;)])</span>
<span class="sd">    tf.math.cos(x) ==&gt; [nan -0.91113025 0.87758255 0.5403023 0.36235774 0.48718765 -0.95215535 nan]</span>
<span class="sd">    ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Cos&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cos_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">cos</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Cos&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">cos</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Cos&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Cos</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Cos&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">cos</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">cos_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Cos&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Cos&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="cosh"><a class="viewcode-back" href="../../../../index.html#tensorflow.cosh">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.cosh&#39;</span><span class="p">,</span> <span class="s1">&#39;cosh&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">cosh</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes hyperbolic cosine of x element-wise.</span>

<span class="sd">    Given an input tensor, this function computes hyperbolic cosine of every</span>
<span class="sd">    element in the tensor. Input range is `[-inf, inf]` and output range</span>
<span class="sd">    is `[1, inf]`.</span>

<span class="sd">    ```python</span>
<span class="sd">    x = tf.constant([-float(&quot;inf&quot;), -9, -0.5, 1, 1.2, 2, 10, float(&quot;inf&quot;)])</span>
<span class="sd">    tf.math.cosh(x) ==&gt; [inf 4.0515420e+03 1.1276259e+00 1.5430807e+00 1.8106556e+00 3.7621956e+00 1.1013233e+04 inf]</span>
<span class="sd">    ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Cosh&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cosh_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">cosh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Cosh&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">cosh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Cosh&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Cosh</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Cosh&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">cosh</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">cosh_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Cosh&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Cosh&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;linalg.cross&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;linalg.cross&#39;</span><span class="p">,</span> <span class="s1">&#39;cross&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;cross&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">cross</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the pairwise cross product.</span>

<span class="sd">  `a` and `b` must be the same shape; they can either be simple 3-element vectors,</span>
<span class="sd">  or any shape where the innermost dimension is 3. In the latter case, each pair</span>
<span class="sd">  of corresponding 3-element vectors is cross-multiplied independently.</span>

<span class="sd">  Args:</span>
<span class="sd">    a: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.</span>
<span class="sd">      A tensor containing 3-element vectors.</span>
<span class="sd">    b: A `Tensor`. Must have the same type as `a`.</span>
<span class="sd">      Another tensor, of same type and shape as `a`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `a`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Cross&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cross_eager_fallback</span><span class="p">(</span>
            <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">cross</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Cross&quot;</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">cross</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Cross&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Cross</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Cross&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">cross</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">cross_eager_fallback</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Cross&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Cross&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">cumprod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">exclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the cumulative product of the tensor `x` along `axis`.</span>

<span class="sd">  By default, this op performs an inclusive cumprod, which means that the first</span>
<span class="sd">  element of the input is identical to the first element of the output:</span>

<span class="sd">  ```python</span>
<span class="sd">  tf.cumprod([a, b, c])  # =&gt; [a, a * b, a * b * c]</span>
<span class="sd">  ```</span>

<span class="sd">  By setting the `exclusive` kwarg to `True`, an exclusive cumprod is</span>
<span class="sd">  performed instead:</span>

<span class="sd">  ```python</span>
<span class="sd">  tf.cumprod([a, b, c], exclusive=True)  # =&gt; [1, a, a * b]</span>
<span class="sd">  ```</span>

<span class="sd">  By setting the `reverse` kwarg to `True`, the cumprod is performed in the</span>
<span class="sd">  opposite direction:</span>

<span class="sd">  ```python</span>
<span class="sd">  tf.cumprod([a, b, c], reverse=True)  # =&gt; [a * b * c, b * c, c]</span>
<span class="sd">  ```</span>

<span class="sd">  This is more efficient than using separate `tf.reverse` ops.</span>

<span class="sd">  The `reverse` and `exclusive` kwargs can also be combined:</span>

<span class="sd">  ```python</span>
<span class="sd">  tf.cumprod([a, b, c], exclusive=True, reverse=True)  # =&gt; [b * c, c, 1]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">      A `Tensor`. Must be one of the following types: `float32`, `float64`,</span>
<span class="sd">      `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,</span>
<span class="sd">      `complex128`, `qint8`, `quint8`, `qint32`, `half`.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A `Tensor` of type `int32` (default: 0). Must be in the range</span>
<span class="sd">      `[-rank(x), rank(x))`.</span>
<span class="sd">    exclusive: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If `True`, perform exclusive cumprod.</span>
<span class="sd">    reverse: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      A `bool` (default: False).</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Cumprod&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;exclusive&quot;</span><span class="p">,</span> <span class="n">exclusive</span><span class="p">,</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span> <span class="n">reverse</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cumprod_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">exclusive</span><span class="o">=</span><span class="n">exclusive</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="n">reverse</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">exclusive</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">exclusive</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">exclusive</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">exclusive</span><span class="p">,</span> <span class="s2">&quot;exclusive&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">reverse</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">reverse</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">reverse</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">reverse</span><span class="p">,</span> <span class="s2">&quot;reverse&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Cumprod&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">exclusive</span><span class="o">=</span><span class="n">exclusive</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="n">reverse</span><span class="p">,</span>
                   <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;exclusive&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;exclusive&quot;</span><span class="p">),</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;reverse&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
              <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Cumprod&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Cumprod</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Cumprod&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">cumprod</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">cumprod_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">exclusive</span><span class="p">,</span> <span class="n">reverse</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">exclusive</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">exclusive</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">exclusive</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">exclusive</span><span class="p">,</span> <span class="s2">&quot;exclusive&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">reverse</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">reverse</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">reverse</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">reverse</span><span class="p">,</span> <span class="s2">&quot;reverse&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;exclusive&quot;</span><span class="p">,</span> <span class="n">exclusive</span><span class="p">,</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span> <span class="n">reverse</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
  <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Cumprod&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Cumprod&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">cumsum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">exclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the cumulative sum of the tensor `x` along `axis`.</span>

<span class="sd">  By default, this op performs an inclusive cumsum, which means that the first</span>
<span class="sd">  element of the input is identical to the first element of the output:</span>

<span class="sd">  ```python</span>
<span class="sd">  tf.cumsum([a, b, c])  # =&gt; [a, a + b, a + b + c]</span>
<span class="sd">  ```</span>

<span class="sd">  By setting the `exclusive` kwarg to `True`, an exclusive cumsum is</span>
<span class="sd">  performed instead:</span>

<span class="sd">  ```python</span>
<span class="sd">  tf.cumsum([a, b, c], exclusive=True)  # =&gt; [0, a, a + b]</span>
<span class="sd">  ```</span>

<span class="sd">  By setting the `reverse` kwarg to `True`, the cumsum is performed in the</span>
<span class="sd">  opposite direction:</span>

<span class="sd">  ```python</span>
<span class="sd">  tf.cumsum([a, b, c], reverse=True)  # =&gt; [a + b + c, b + c, c]</span>
<span class="sd">  ```</span>

<span class="sd">  This is more efficient than using separate `tf.reverse` ops.</span>

<span class="sd">  The `reverse` and `exclusive` kwargs can also be combined:</span>

<span class="sd">  ```python</span>
<span class="sd">  tf.cumsum([a, b, c], exclusive=True, reverse=True)  # =&gt; [b + c, c, 0]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">      A `Tensor`. Must be one of the following types: `float32`, `float64`,</span>
<span class="sd">      `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,</span>
<span class="sd">      `complex128`, `qint8`, `quint8`, `qint32`, `half`.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A `Tensor` of type `int32` (default: 0). Must be in the range</span>
<span class="sd">      `[-rank(x), rank(x))`.</span>
<span class="sd">    exclusive: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If `True`, perform exclusive cumsum.</span>
<span class="sd">    reverse: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      A `bool` (default: False).</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Cumsum&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;exclusive&quot;</span><span class="p">,</span> <span class="n">exclusive</span><span class="p">,</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span> <span class="n">reverse</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cumsum_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">exclusive</span><span class="o">=</span><span class="n">exclusive</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="n">reverse</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">exclusive</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">exclusive</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">exclusive</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">exclusive</span><span class="p">,</span> <span class="s2">&quot;exclusive&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">reverse</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">reverse</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">reverse</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">reverse</span><span class="p">,</span> <span class="s2">&quot;reverse&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Cumsum&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">exclusive</span><span class="o">=</span><span class="n">exclusive</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="n">reverse</span><span class="p">,</span>
                  <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;exclusive&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;exclusive&quot;</span><span class="p">),</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;reverse&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
              <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Cumsum&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Cumsum</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Cumsum&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">cumsum</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">cumsum_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">exclusive</span><span class="p">,</span> <span class="n">reverse</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">exclusive</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">exclusive</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">exclusive</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">exclusive</span><span class="p">,</span> <span class="s2">&quot;exclusive&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">reverse</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">reverse</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">reverse</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">reverse</span><span class="p">,</span> <span class="s2">&quot;reverse&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;exclusive&quot;</span><span class="p">,</span> <span class="n">exclusive</span><span class="p">,</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span> <span class="n">reverse</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
  <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Cumsum&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Cumsum&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">cumulative_logsumexp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">exclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the cumulative product of the tensor `x` along `axis`.</span>

<span class="sd">  By default, this op performs an inclusive cumulative log-sum-exp,</span>
<span class="sd">  which means that the first</span>
<span class="sd">  element of the input is identical to the first element of the output:</span>
<span class="sd">  ```python</span>
<span class="sd">  tf.math.cumulative_logsumexp([a, b, c])  # =&gt; [a, log(exp(a) + exp(b)), log(exp(a) + exp(b) + exp(c))]</span>
<span class="sd">  ```</span>

<span class="sd">  By setting the `exclusive` kwarg to `True`, an exclusive cumulative log-sum-exp is</span>
<span class="sd">  performed instead:</span>
<span class="sd">  ```python</span>
<span class="sd">  tf.cumulative_logsumexp([a, b, c], exclusive=True)  # =&gt; [-inf, a, log(exp(a) * exp(b))]</span>
<span class="sd">  ```</span>
<span class="sd">  Note that the neutral element of the log-sum-exp operation is `-inf`,</span>
<span class="sd">  however, for performance reasons, the minimal value representable by the</span>
<span class="sd">  floating point type is used instead.</span>

<span class="sd">  By setting the `reverse` kwarg to `True`, the cumulative log-sum-exp is performed in the</span>
<span class="sd">  opposite direction.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.</span>
<span class="sd">      A `Tensor`. Must be one of the following types: `float16`, `float32`, `float64`.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A `Tensor` of type `int32` (default: 0). Must be in the range</span>
<span class="sd">      `[-rank(x), rank(x))`.</span>
<span class="sd">    exclusive: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If `True`, perform exclusive cumulative log-sum-exp.</span>
<span class="sd">    reverse: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      A `bool` (default: False).</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;CumulativeLogsumexp&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;exclusive&quot;</span><span class="p">,</span> <span class="n">exclusive</span><span class="p">,</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span> <span class="n">reverse</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cumulative_logsumexp_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">exclusive</span><span class="o">=</span><span class="n">exclusive</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="n">reverse</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">exclusive</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">exclusive</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">exclusive</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">exclusive</span><span class="p">,</span> <span class="s2">&quot;exclusive&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">reverse</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">reverse</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">reverse</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">reverse</span><span class="p">,</span> <span class="s2">&quot;reverse&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;CumulativeLogsumexp&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">exclusive</span><span class="o">=</span><span class="n">exclusive</span><span class="p">,</span>
                               <span class="n">reverse</span><span class="o">=</span><span class="n">reverse</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;exclusive&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;exclusive&quot;</span><span class="p">),</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;reverse&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
              <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;CumulativeLogsumexp&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">CumulativeLogsumexp</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.CumulativeLogsumexp&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">cumulative_logsumexp</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">cumulative_logsumexp_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">exclusive</span><span class="p">,</span> <span class="n">reverse</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">exclusive</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">exclusive</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">exclusive</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">exclusive</span><span class="p">,</span> <span class="s2">&quot;exclusive&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">reverse</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">reverse</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">reverse</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">reverse</span><span class="p">,</span> <span class="s2">&quot;reverse&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;exclusive&quot;</span><span class="p">,</span> <span class="n">exclusive</span><span class="p">,</span> <span class="s2">&quot;reverse&quot;</span><span class="p">,</span> <span class="n">reverse</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
  <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;CumulativeLogsumexp&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;CumulativeLogsumexp&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.digamma&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.digamma&#39;</span><span class="p">,</span> <span class="s1">&#39;digamma&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;digamma&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">digamma</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes Psi, the derivative of Lgamma (the log of the absolute value of</span>

<span class="sd">  `Gamma(x)`), element-wise.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Digamma&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">digamma_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">digamma</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Digamma&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">digamma</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Digamma&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Digamma</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Digamma&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">digamma</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">digamma_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Digamma&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Digamma&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns x / y element-wise.</span>

<span class="sd">  *NOTE*: `Div` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Div&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">div_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Div&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Div&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Div</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Div&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">div</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">div_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Div&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Div&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">div_no_nan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns 0 if the denominator is zero.</span>

<span class="sd">  </span>
<span class="sd">  *NOTE*: `DivNoNan` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;DivNoNan&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">div_no_nan_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;DivNoNan&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;DivNoNan&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">DivNoNan</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.DivNoNan&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">div_no_nan</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">div_no_nan_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;DivNoNan&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;DivNoNan&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">incompatible_shape_error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the truth value of (x == y) element-wise.</span>

<span class="sd">  *NOTE*: `Equal` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  ```python</span>
<span class="sd">  x = tf.constant([2, 4])</span>
<span class="sd">  y = tf.constant(2)</span>
<span class="sd">  tf.math.equal(x, y) ==&gt; array([True, False])</span>

<span class="sd">  x = tf.constant([2, 4])</span>
<span class="sd">  y = tf.constant([2, 4])</span>
<span class="sd">  tf.math.equal(x, y) ==&gt; array([True,  True])</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `int16`, `int32`, `int64`, `complex64`, `quint8`, `qint8`, `qint32`, `string`, `bool`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    incompatible_shape_error: An optional `bool`. Defaults to `True`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Equal&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;incompatible_shape_error&quot;</span><span class="p">,</span>
        <span class="n">incompatible_shape_error</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">equal_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">incompatible_shape_error</span><span class="o">=</span><span class="n">incompatible_shape_error</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">incompatible_shape_error</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">incompatible_shape_error</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">incompatible_shape_error</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">incompatible_shape_error</span><span class="p">,</span> <span class="s2">&quot;incompatible_shape_error&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Equal&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">incompatible_shape_error</span><span class="o">=</span><span class="n">incompatible_shape_error</span><span class="p">,</span>
                 <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;incompatible_shape_error&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;incompatible_shape_error&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Equal&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Equal</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Equal&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">equal</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">equal_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">incompatible_shape_error</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">incompatible_shape_error</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">incompatible_shape_error</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">incompatible_shape_error</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">incompatible_shape_error</span><span class="p">,</span> <span class="s2">&quot;incompatible_shape_error&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;incompatible_shape_error&quot;</span><span class="p">,</span>
  <span class="n">incompatible_shape_error</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Equal&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Equal&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.erf&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.erf&#39;</span><span class="p">,</span> <span class="s1">&#39;erf&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;erf&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">erf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the Gauss error function of `x` element-wise.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Erf&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">erf_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">erf</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Erf&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">erf</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Erf&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Erf</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Erf&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">erf</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">erf_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Erf&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Erf&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.erfc&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.erfc&#39;</span><span class="p">,</span> <span class="s1">&#39;erfc&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;erfc&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">erfc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the complementary error function of `x` element-wise.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Erfc&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">erfc_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">erfc</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Erfc&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">erfc</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Erfc&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Erfc</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Erfc&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">erfc</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">erfc_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Erfc&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Erfc&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">erfinv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;TODO: add doc.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Erfinv&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">erfinv_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Erfinv&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Erfinv&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Erfinv</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Erfinv&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">erfinv</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">erfinv_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Erfinv&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Erfinv&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">euclidean_norm</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the euclidean norm of elements across dimensions of a tensor.</span>

<span class="sd">  Reduces `input` along the dimensions given in `axis`. Unless</span>
<span class="sd">  `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in</span>
<span class="sd">  `axis`. If `keep_dims` is true, the reduced dimensions are</span>
<span class="sd">  retained with length 1.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">      The tensor to reduce.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      The dimensions to reduce. Must be in the range</span>
<span class="sd">      `[-rank(input), rank(input))`.</span>
<span class="sd">    keep_dims: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If true, retain reduced dimensions with length 1.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;EuclideanNorm&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">euclidean_norm_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;EuclideanNorm&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
                         <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;EuclideanNorm&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">EuclideanNorm</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.EuclideanNorm&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">euclidean_norm</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">euclidean_norm_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;EuclideanNorm&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;EuclideanNorm&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">exp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes exponential of x element-wise.  \\(y = e^x\\).</span>

<span class="sd">    This function computes the exponential of every element in the input tensor.</span>
<span class="sd">    i.e. `exp(x)` or `e^(x)`, where `x` is the input tensor.</span>
<span class="sd">    `e` denotes Euler&#39;s number and is approximately equal to 2.718281.</span>
<span class="sd">    Output is positive for any real input.</span>

<span class="sd">    ```python</span>
<span class="sd">    x = tf.constant(2.0)</span>
<span class="sd">    tf.math.exp(x) ==&gt; 7.389056</span>

<span class="sd">    x = tf.constant([2.0, 8.0])</span>
<span class="sd">    tf.math.exp(x) ==&gt; array([7.389056, 2980.958], dtype=float32)</span>
<span class="sd">    ```</span>

<span class="sd">    For complex numbers, the exponential value is calculated as follows:</span>

<span class="sd">    ```</span>
<span class="sd">    e^(x+iy) = e^x * e^iy = e^x * (cos y + i sin y)</span>
<span class="sd">    ```</span>

<span class="sd">    Let&#39;s consider complex number 1+1j as an example.</span>
<span class="sd">    e^1 * (cos 1 + i sin 1) = 2.7182818284590 * (0.54030230586+0.8414709848j)</span>

<span class="sd">    ```python</span>
<span class="sd">    x = tf.constant(1 + 1j)</span>
<span class="sd">    tf.math.exp(x) ==&gt; 1.4686939399158851+2.2873552871788423j</span>
<span class="sd">    ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Exp&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">exp_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Exp&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Exp&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Exp</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Exp&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">exp</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">exp_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Exp&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Exp&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.expm1&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.expm1&#39;</span><span class="p">,</span> <span class="s1">&#39;expm1&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;expm1&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">expm1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes `exp(x) - 1` element-wise.</span>

<span class="sd">    i.e. `exp(x) - 1` or `e^(x) - 1`, where `x` is the input tensor.</span>
<span class="sd">    `e` denotes Euler&#39;s number and is approximately equal to 2.718281.</span>

<span class="sd">    ```python</span>
<span class="sd">    x = tf.constant(2.0)</span>
<span class="sd">    tf.math.expm1(x) ==&gt; 6.389056</span>

<span class="sd">    x = tf.constant([2.0, 8.0])</span>
<span class="sd">    tf.math.expm1(x) ==&gt; array([6.389056, 2979.958], dtype=float32)</span>

<span class="sd">    x = tf.constant(1 + 1j)</span>
<span class="sd">    tf.math.expm1(x) ==&gt; (0.46869393991588515+2.2873552871788423j)</span>
<span class="sd">    ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Expm1&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">expm1_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">expm1</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Expm1&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">expm1</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Expm1&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Expm1</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Expm1&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">expm1</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">expm1_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Expm1&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Expm1&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="floor"><a class="viewcode-back" href="../../../../index.html#tensorflow.floor">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.floor&#39;</span><span class="p">,</span> <span class="s1">&#39;floor&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">floor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns element-wise largest integer not greater than x.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Floor&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">floor_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">floor</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Floor&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">floor</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Floor&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Floor</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Floor&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">floor</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">floor_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Floor&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Floor&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;floor_div&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;floor_div&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">floor_div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns x // y element-wise.</span>

<span class="sd">  *NOTE*: `floor_div` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;FloorDiv&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">floor_div_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">floor_div</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;FloorDiv&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">floor_div</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FloorDiv&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">FloorDiv</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.FloorDiv&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">floor_div</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">floor_div_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;FloorDiv&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FloorDiv&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.floormod&#39;</span><span class="p">,</span> <span class="s1">&#39;math.mod&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.floormod&#39;</span><span class="p">,</span> <span class="s1">&#39;floormod&#39;</span><span class="p">,</span> <span class="s1">&#39;math.mod&#39;</span><span class="p">,</span> <span class="s1">&#39;mod&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;floormod&#39;</span><span class="p">,</span> <span class="s1">&#39;mod&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">floor_mod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns element-wise remainder of division. When `x &lt; 0` xor `y &lt; 0` is</span>

<span class="sd">  true, this follows Python semantics in that the result here is consistent</span>
<span class="sd">  with a flooring divide. E.g. `floor(x / y) * y + mod(x, y) = x`.</span>

<span class="sd">  *NOTE*: `math.floormod` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;FloorMod&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">floor_mod_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">floor_mod</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;FloorMod&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">floor_mod</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FloorMod&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">FloorMod</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.FloorMod&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">floor_mod</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">floor_mod_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;FloorMod&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FloorMod&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="greater"><a class="viewcode-back" href="../../../../index.html#tensorflow.greater">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.greater&#39;</span><span class="p">,</span> <span class="s1">&#39;greater&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">greater</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the truth value of (x &gt; y) element-wise.</span>

<span class="sd">  *NOTE*: `math.greater` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  x = tf.constant([5, 4, 6])</span>
<span class="sd">  y = tf.constant([5, 2, 5])</span>
<span class="sd">  tf.math.greater(x, y) ==&gt; [False, True, True]</span>

<span class="sd">  x = tf.constant([5, 4, 6])</span>
<span class="sd">  y = tf.constant([5])</span>
<span class="sd">  tf.math.greater(x, y) ==&gt; [False, False, True]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Greater&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">greater_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">greater</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Greater&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">greater</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Greater&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Greater</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Greater&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">greater</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">greater_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Greater&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Greater&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="greater_equal"><a class="viewcode-back" href="../../../../index.html#tensorflow.greater_equal">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.greater_equal&#39;</span><span class="p">,</span> <span class="s1">&#39;greater_equal&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">greater_equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the truth value of (x &gt;= y) element-wise.</span>

<span class="sd">  *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  x = tf.constant([5, 4, 6, 7])</span>
<span class="sd">  y = tf.constant([5, 2, 5, 10])</span>
<span class="sd">  tf.math.greater_equal(x, y) ==&gt; [True, True, True, False]</span>

<span class="sd">  x = tf.constant([5, 4, 6, 7])</span>
<span class="sd">  y = tf.constant([5])</span>
<span class="sd">  tf.math.greater_equal(x, y) ==&gt; [True, False, True, True]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;GreaterEqual&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">greater_equal_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">greater_equal</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;GreaterEqual&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">greater_equal</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;GreaterEqual&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">GreaterEqual</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.GreaterEqual&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">greater_equal</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">greater_equal_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;GreaterEqual&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;GreaterEqual&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">_histogram_fixed_width</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">value_range</span><span class="p">,</span> <span class="n">nbins</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return histogram of values.</span>

<span class="sd">  Given the tensor `values`, this operation returns a rank 1 histogram counting</span>
<span class="sd">  the number of entries in `values` that fall into every bin.  The bins are</span>
<span class="sd">  equal width and determined by the arguments `value_range` and `nbins`.</span>

<span class="sd">  ```python</span>
<span class="sd">  # Bins will be:  (-inf, 1), [1, 2), [2, 3), [3, 4), [4, inf)</span>
<span class="sd">  nbins = 5</span>
<span class="sd">  value_range = [0.0, 5.0]</span>
<span class="sd">  new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]</span>

<span class="sd">  with tf.get_default_session() as sess:</span>
<span class="sd">    hist = tf.histogram_fixed_width(new_values, value_range, nbins=5)</span>
<span class="sd">    variables.global_variables_initializer().run()</span>
<span class="sd">    sess.run(hist) =&gt; [2, 1, 1, 0, 2]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    values: A `Tensor`. Must be one of the following types: `int32`, `int64`, `float32`, `float64`.</span>
<span class="sd">      Numeric `Tensor`.</span>
<span class="sd">    value_range: A `Tensor`. Must have the same type as `values`.</span>
<span class="sd">      Shape [2] `Tensor` of same `dtype` as `values`.</span>
<span class="sd">      values &lt;= value_range[0] will be mapped to hist[0],</span>
<span class="sd">      values &gt;= value_range[1] will be mapped to hist[-1].</span>
<span class="sd">    nbins: A `Tensor` of type `int32`.</span>
<span class="sd">      Scalar `int32 Tensor`.  Number of histogram bins.</span>
<span class="sd">    dtype: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `dtype`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;HistogramFixedWidth&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">value_range</span><span class="p">,</span> <span class="n">nbins</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_histogram_fixed_width_eager_fallback</span><span class="p">(</span>
            <span class="n">values</span><span class="p">,</span> <span class="n">value_range</span><span class="p">,</span> <span class="n">nbins</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;HistogramFixedWidth&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">value_range</span><span class="o">=</span><span class="n">value_range</span><span class="p">,</span>
                               <span class="n">nbins</span><span class="o">=</span><span class="n">nbins</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;HistogramFixedWidth&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">HistogramFixedWidth</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.HistogramFixedWidth&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">_histogram_fixed_width</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_histogram_fixed_width_eager_fallback</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">value_range</span><span class="p">,</span> <span class="n">nbins</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">values</span><span class="p">,</span> <span class="n">value_range</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">value_range</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">nbins</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">nbins</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">values</span><span class="p">,</span> <span class="n">value_range</span><span class="p">,</span> <span class="n">nbins</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;HistogramFixedWidth&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;HistogramFixedWidth&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.igamma&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.igamma&#39;</span><span class="p">,</span> <span class="s1">&#39;igamma&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;igamma&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">igamma</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the lower regularized incomplete Gamma function `P(a, x)`.</span>

<span class="sd">  The lower regularized incomplete Gamma function is defined as:</span>


<span class="sd">  \\(P(a, x) = gamma(a, x) / Gamma(a) = 1 - Q(a, x)\\)</span>

<span class="sd">  where</span>

<span class="sd">  \\(gamma(a, x) = \\int_{0}^{x} t^{a-1} exp(-t) dt\\)</span>

<span class="sd">  is the lower incomplete Gamma function.</span>

<span class="sd">  Note, above `Q(a, x)` (`Igammac`) is the upper regularized complete</span>
<span class="sd">  Gamma function.</span>

<span class="sd">  Args:</span>
<span class="sd">    a: A `Tensor`. Must be one of the following types: `float32`, `float64`.</span>
<span class="sd">    x: A `Tensor`. Must have the same type as `a`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `a`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Igamma&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">igamma_eager_fallback</span><span class="p">(</span>
            <span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">igamma</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Igamma&quot;</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">igamma</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Igamma&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Igamma</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Igamma&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">igamma</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">igamma_eager_fallback</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Igamma&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Igamma&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">igamma_grad_a</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the gradient of `igamma(a, x)` wrt `a`.</span>

<span class="sd">  Args:</span>
<span class="sd">    a: A `Tensor`. Must be one of the following types: `float32`, `float64`.</span>
<span class="sd">    x: A `Tensor`. Must have the same type as `a`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `a`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;IgammaGradA&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">igamma_grad_a_eager_fallback</span><span class="p">(</span>
            <span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;IgammaGradA&quot;</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;IgammaGradA&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">IgammaGradA</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.IgammaGradA&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">igamma_grad_a</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">igamma_grad_a_eager_fallback</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;IgammaGradA&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;IgammaGradA&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.igammac&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.igammac&#39;</span><span class="p">,</span> <span class="s1">&#39;igammac&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;igammac&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">igammac</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the upper regularized incomplete Gamma function `Q(a, x)`.</span>

<span class="sd">  The upper regularized incomplete Gamma function is defined as:</span>

<span class="sd">  \\(Q(a, x) = Gamma(a, x) / Gamma(a) = 1 - P(a, x)\\)</span>

<span class="sd">  where</span>

<span class="sd">  \\(Gamma(a, x) = int_{x}^{\infty} t^{a-1} exp(-t) dt\\)</span>

<span class="sd">  is the upper incomplete Gama function.</span>

<span class="sd">  Note, above `P(a, x)` (`Igamma`) is the lower regularized complete</span>
<span class="sd">  Gamma function.</span>

<span class="sd">  Args:</span>
<span class="sd">    a: A `Tensor`. Must be one of the following types: `float32`, `float64`.</span>
<span class="sd">    x: A `Tensor`. Must have the same type as `a`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `a`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Igammac&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">igammac_eager_fallback</span><span class="p">(</span>
            <span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">igammac</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Igammac&quot;</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">igammac</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Igammac&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Igammac</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Igammac&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">igammac</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">igammac_eager_fallback</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Igammac&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Igammac&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">imag</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the imaginary part of a complex number.</span>

<span class="sd">  Given a tensor `input` of complex numbers, this operation returns a tensor of</span>
<span class="sd">  type `float` that is the imaginary part of each element in `input`. All</span>
<span class="sd">  elements in `input` must be complex numbers of the form \\(a + bj\\), where *a*</span>
<span class="sd">  is the real part and *b* is the imaginary part returned by this operation.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;input&#39; is [-2.25 + 4.75j, 3.25 + 5.75j]</span>
<span class="sd">  tf.imag(input) ==&gt; [4.75, 5.75]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.</span>
<span class="sd">    Tout: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `Tout`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Imag&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span> <span class="n">Tout</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">imag_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">Tout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Tout</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span>
  <span class="n">Tout</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Tout</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Imag&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tout&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Imag&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Imag</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Imag&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">imag</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">imag_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">Tout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Tout</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span>
  <span class="n">Tout</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Tout</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">complex64</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span> <span class="n">Tout</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Imag&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Imag&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">inv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the reciprocal of x element-wise.</span>

<span class="sd">  I.e., \\(y = 1 / x\\).</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Inv&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">inv_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Inv&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Inv&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Inv</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Inv&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">inv</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">inv_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Inv&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Inv&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">inv_grad</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the gradient for the inverse of `x` wrt its input.</span>

<span class="sd">  Specifically, `grad = -dy * y*y`, where `y = 1/x`, and `dy`</span>
<span class="sd">  is the corresponding input gradient.</span>

<span class="sd">  Args:</span>
<span class="sd">    y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    dy: A `Tensor`. Must have the same type as `y`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `y`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;InvGrad&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">inv_grad_eager_fallback</span><span class="p">(</span>
            <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;InvGrad&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;InvGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">InvGrad</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.InvGrad&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">inv_grad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">inv_grad_eager_fallback</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;InvGrad&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;InvGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.is_finite&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.is_finite&#39;</span><span class="p">,</span> <span class="s1">&#39;debugging.is_finite&#39;</span><span class="p">,</span> <span class="s1">&#39;is_finite&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;debugging.is_finite&#39;</span><span class="p">,</span> <span class="s1">&#39;is_finite&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">is_finite</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns which elements of x are finite.</span>

<span class="sd">  @compatibility(numpy)</span>
<span class="sd">  Equivalent to np.isfinite</span>
<span class="sd">  @end_compatibility</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  x = tf.constant([5.0, 4.8, 6.8, np.inf, np.nan])</span>
<span class="sd">  tf.math.is_finite(x) ==&gt; [True, True, True, False, False]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;IsFinite&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">is_finite_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">is_finite</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;IsFinite&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">is_finite</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;IsFinite&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">IsFinite</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.IsFinite&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">is_finite</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">is_finite_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;IsFinite&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;IsFinite&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.is_inf&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.is_inf&#39;</span><span class="p">,</span> <span class="s1">&#39;debugging.is_inf&#39;</span><span class="p">,</span> <span class="s1">&#39;is_inf&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;debugging.is_inf&#39;</span><span class="p">,</span> <span class="s1">&#39;is_inf&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">is_inf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns which elements of x are Inf.</span>

<span class="sd">  @compatibility(numpy)</span>
<span class="sd">  Equivalent to np.isinf</span>
<span class="sd">  @end_compatibility</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  x = tf.constant([5.0, np.inf, 6.8, np.inf])</span>
<span class="sd">  tf.math.is_inf(x) ==&gt; [False, True, False, True]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;IsInf&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">is_inf_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">is_inf</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;IsInf&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">is_inf</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;IsInf&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">IsInf</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.IsInf&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">is_inf</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">is_inf_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;IsInf&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;IsInf&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.is_nan&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.is_nan&#39;</span><span class="p">,</span> <span class="s1">&#39;debugging.is_nan&#39;</span><span class="p">,</span> <span class="s1">&#39;is_nan&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;debugging.is_nan&#39;</span><span class="p">,</span> <span class="s1">&#39;is_nan&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">is_nan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns which elements of x are NaN.</span>

<span class="sd">  @compatibility(numpy)</span>
<span class="sd">  Equivalent to np.isnan</span>
<span class="sd">  @end_compatibility</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  x = tf.constant([5.0, np.nan, 6.8, np.nan, np.inf])</span>
<span class="sd">  tf.math.is_nan(x) ==&gt; [False, True, False, True, False]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;IsNan&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">is_nan_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">is_nan</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;IsNan&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">is_nan</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;IsNan&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">IsNan</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.IsNan&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">is_nan</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">is_nan_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;IsNan&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;IsNan&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="less"><a class="viewcode-back" href="../../../../index.html#tensorflow.less">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.less&#39;</span><span class="p">,</span> <span class="s1">&#39;less&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">less</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the truth value of (x &lt; y) element-wise.</span>

<span class="sd">  *NOTE*: `math.less` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  x = tf.constant([5, 4, 6])</span>
<span class="sd">  y = tf.constant([5])</span>
<span class="sd">  tf.math.less(x, y) ==&gt; [False, True, False]</span>

<span class="sd">  x = tf.constant([5, 4, 6])</span>
<span class="sd">  y = tf.constant([5, 6, 7])</span>
<span class="sd">  tf.math.less(x, y) ==&gt; [False, True, True]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Less&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">less_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">less</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Less&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">less</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Less&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Less</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Less&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">less</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">less_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Less&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Less&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="less_equal"><a class="viewcode-back" href="../../../../index.html#tensorflow.less_equal">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.less_equal&#39;</span><span class="p">,</span> <span class="s1">&#39;less_equal&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">less_equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the truth value of (x &lt;= y) element-wise.</span>

<span class="sd">  *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  x = tf.constant([5, 4, 6])</span>
<span class="sd">  y = tf.constant([5])</span>
<span class="sd">  tf.math.less_equal(x, y) ==&gt; [True, True, False]</span>

<span class="sd">  x = tf.constant([5, 4, 6])</span>
<span class="sd">  y = tf.constant([5, 6, 6])</span>
<span class="sd">  tf.math.less_equal(x, y) ==&gt; [True, True, True]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;LessEqual&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">less_equal_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">less_equal</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;LessEqual&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">less_equal</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;LessEqual&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">LessEqual</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.LessEqual&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">less_equal</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">less_equal_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;LessEqual&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;LessEqual&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.lgamma&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.lgamma&#39;</span><span class="p">,</span> <span class="s1">&#39;lgamma&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;lgamma&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">lgamma</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the log of the absolute value of `Gamma(x)` element-wise.</span>

<span class="sd">    For positive numbers, this function computes log((input - 1)!) for every element in the tensor.</span>
<span class="sd">    `lgamma(5) = log((5-1)!) = log(4!) = log(24) = 3.1780539`</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  x = tf.constant([0, 0.5, 1, 4.5, -4, -5.6])</span>
<span class="sd">  tf.math.lgamma(x) ==&gt; [inf, 0.5723649, 0., 2.4537368, inf, -4.6477685]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Lgamma&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">lgamma_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">lgamma</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Lgamma&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">lgamma</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Lgamma&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Lgamma</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Lgamma&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">lgamma</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">lgamma_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Lgamma&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Lgamma&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;linspace&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;lin_space&#39;</span><span class="p">,</span> <span class="s1">&#39;linspace&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;lin_space&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">lin_space</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Generates values in an interval.</span>

<span class="sd">  A sequence of `num` evenly-spaced values are generated beginning at `start`.</span>
<span class="sd">  If `num &gt; 1`, the values in the sequence increase by `stop - start / num - 1`,</span>
<span class="sd">  so that the last one is exactly `stop`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  tf.linspace(10.0, 12.0, 3, name=&quot;linspace&quot;) =&gt; [ 10.0  11.0  12.0]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    start: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">      0-D tensor. First entry in the range.</span>
<span class="sd">    stop: A `Tensor`. Must have the same type as `start`.</span>
<span class="sd">      0-D tensor. Last entry in the range.</span>
<span class="sd">    num: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      0-D tensor. Number of values to generate.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `start`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;LinSpace&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">lin_space_eager_fallback</span><span class="p">(</span>
            <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">lin_space</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">num</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;LinSpace&quot;</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">num</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">lin_space</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">num</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;LinSpace&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">LinSpace</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.LinSpace&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">lin_space</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">lin_space_eager_fallback</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">num</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">num</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">num</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;LinSpace&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;LinSpace&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.log&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.log&#39;</span><span class="p">,</span> <span class="s1">&#39;log&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">log</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes natural logarithm of x element-wise.</span>

<span class="sd">  I.e., \\(y = \log_e x\\).</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  &gt;&gt;&gt; x = tf.constant([0, 0.5, 1, 5])</span>
<span class="sd">  &gt;&gt;&gt; tf.math.log(x)</span>
<span class="sd">  &lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([      -inf, -0.6931472,  0.       ,  1.609438 ], dtype=float32)&gt;</span>

<span class="sd">  ```</span>

<span class="sd">  See: https://en.wikipedia.org/wiki/Logarithm</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Log&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">log_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">log</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Log&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">log</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Log&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Log</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Log&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">log</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">log_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Log&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Log&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.log1p&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.log1p&#39;</span><span class="p">,</span> <span class="s1">&#39;log1p&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;log1p&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">log1p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes natural logarithm of (1 + x) element-wise.</span>

<span class="sd">  I.e., \\(y = \log_e (1 + x)\\).</span>

<span class="sd">  Example:</span>
<span class="sd">  &gt;&gt;&gt; x = tf.constant([0, 0.5, 1, 5])</span>
<span class="sd">  &gt;&gt;&gt; tf.math.log1p(x)</span>
<span class="sd">  &lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.       , 0.4054651, 0.6931472, 1.7917595], dtype=float32)&gt;</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Log1p&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">log1p_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">log1p</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Log1p&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">log1p</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Log1p&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Log1p</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Log1p&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">log1p</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">log1p_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Log1p&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Log1p&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">logical_and</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the truth value of x AND y element-wise.</span>

<span class="sd">  *NOTE*: `LogicalAnd` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor` of type `bool`.</span>
<span class="sd">    y: A `Tensor` of type `bool`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;LogicalAnd&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">logical_and_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;LogicalAnd&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">()</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;LogicalAnd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">LogicalAnd</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.LogicalAnd&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">logical_and</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">logical_and_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;LogicalAnd&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;LogicalAnd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="logical_not"><a class="viewcode-back" href="../../../../index.html#tensorflow.logical_not">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.logical_not&#39;</span><span class="p">,</span> <span class="s1">&#39;logical_not&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">logical_not</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the truth value of `NOT x` element-wise.</span>

<span class="sd">  Example:</span>

<span class="sd">  &gt;&gt;&gt; tf.math.logical_not(tf.constant([True, False]))</span>
<span class="sd">  &lt;tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])&gt;</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor` of type `bool`. A `Tensor` of type `bool`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;LogicalNot&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">logical_not_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">logical_not</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;LogicalNot&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">logical_not</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">()</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;LogicalNot&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">LogicalNot</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.LogicalNot&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">logical_not</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">logical_not_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;LogicalNot&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;LogicalNot&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="logical_or"><a class="viewcode-back" href="../../../../index.html#tensorflow.logical_or">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.logical_or&#39;</span><span class="p">,</span> <span class="s1">&#39;logical_or&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">logical_or</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the truth value of x OR y element-wise.</span>

<span class="sd">  *NOTE*: `math.logical_or` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor` of type `bool`.</span>
<span class="sd">    y: A `Tensor` of type `bool`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;LogicalOr&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">logical_or_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">logical_or</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;LogicalOr&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">logical_or</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">()</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;LogicalOr&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">LogicalOr</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.LogicalOr&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">logical_or</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">logical_or_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;LogicalOr&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;LogicalOr&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">mat_mul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Multiply the matrix &quot;a&quot; by the matrix &quot;b&quot;.</span>

<span class="sd">  The inputs must be two-dimensional matrices and the inner dimension of</span>
<span class="sd">  &quot;a&quot; (after being transposed if transpose_a is true) must match the</span>
<span class="sd">  outer dimension of &quot;b&quot; (after being transposed if transposed_b is</span>
<span class="sd">  true).</span>

<span class="sd">  *Note*: The default kernel implementation for MatMul on GPUs uses</span>
<span class="sd">  cublas.</span>

<span class="sd">  Args:</span>
<span class="sd">    a: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    b: A `Tensor`. Must have the same type as `a`.</span>
<span class="sd">    transpose_a: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If true, &quot;a&quot; is transposed before multiplication.</span>
<span class="sd">    transpose_b: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If true, &quot;b&quot; is transposed before multiplication.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `a`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;MatMul&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="s2">&quot;transpose_a&quot;</span><span class="p">,</span> <span class="n">transpose_a</span><span class="p">,</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">,</span>
        <span class="n">transpose_b</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">mat_mul_eager_fallback</span><span class="p">(</span>
            <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="n">transpose_a</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="n">transpose_b</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">transpose_a</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">transpose_a</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">transpose_a</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">transpose_a</span><span class="p">,</span> <span class="s2">&quot;transpose_a&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">transpose_b</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">transpose_b</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">transpose_b</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">transpose_b</span><span class="p">,</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;MatMul&quot;</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="n">transpose_a</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="n">transpose_b</span><span class="p">,</span>
                  <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;transpose_a&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;transpose_a&quot;</span><span class="p">),</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;transpose_b&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatMul&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">MatMul</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.MatMul&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">mat_mul</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">mat_mul_eager_fallback</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">transpose_a</span><span class="p">,</span> <span class="n">transpose_b</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">transpose_a</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">transpose_a</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">transpose_a</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">transpose_a</span><span class="p">,</span> <span class="s2">&quot;transpose_a&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">transpose_b</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">transpose_b</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">transpose_b</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">transpose_b</span><span class="p">,</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;transpose_a&quot;</span><span class="p">,</span> <span class="n">transpose_a</span><span class="p">,</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">,</span> <span class="n">transpose_b</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
  <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;MatMul&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatMul&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">_max</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the maximum of elements across dimensions of a tensor.</span>

<span class="sd">  Reduces `input` along the dimensions given in `axis`. Unless</span>
<span class="sd">  `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in</span>
<span class="sd">  `axis`. If `keep_dims` is true, the reduced dimensions are</span>
<span class="sd">  retained with length 1.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">      The tensor to reduce.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      The dimensions to reduce. Must be in the range</span>
<span class="sd">      `[-rank(input), rank(input))`.</span>
<span class="sd">    keep_dims: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If true, retain reduced dimensions with length 1.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Max&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_max_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Max&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Max&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Max</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Max&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">_max</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_max_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Max&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Max&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="maximum"><a class="viewcode-back" href="../../../../index.html#tensorflow.maximum">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.maximum&#39;</span><span class="p">,</span> <span class="s1">&#39;maximum&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">maximum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the max of x and y (i.e. x &gt; y ? x : y) element-wise.</span>

<span class="sd">  Example:</span>
<span class="sd">  &gt;&gt;&gt; x = tf.constant([0., 0., 0., 0.])</span>
<span class="sd">  &gt;&gt;&gt; y = tf.constant([-2., 0., 2., 5.])</span>
<span class="sd">  &gt;&gt;&gt; tf.math.maximum(x, y)</span>
<span class="sd">  &lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 2., 5.], dtype=float32)&gt;</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Maximum&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">maximum_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">maximum</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Maximum&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">maximum</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Maximum&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Maximum</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Maximum&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">maximum</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">maximum_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Maximum&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Maximum&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the mean of elements across dimensions of a tensor.</span>

<span class="sd">  Reduces `input` along the dimensions given in `axis`. Unless</span>
<span class="sd">  `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in</span>
<span class="sd">  `axis`. If `keep_dims` is true, the reduced dimensions are</span>
<span class="sd">  retained with length 1.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">      The tensor to reduce.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      The dimensions to reduce. Must be in the range</span>
<span class="sd">      `[-rank(input), rank(input))`.</span>
<span class="sd">    keep_dims: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If true, retain reduced dimensions with length 1.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Mean&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">mean_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Mean&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Mean&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Mean</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Mean&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">mean</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">mean_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Mean&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Mean&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">_min</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the minimum of elements across dimensions of a tensor.</span>

<span class="sd">  Reduces `input` along the dimensions given in `axis`. Unless</span>
<span class="sd">  `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in</span>
<span class="sd">  `axis`. If `keep_dims` is true, the reduced dimensions are</span>
<span class="sd">  retained with length 1.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">      The tensor to reduce.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      The dimensions to reduce. Must be in the range</span>
<span class="sd">      `[-rank(input), rank(input))`.</span>
<span class="sd">    keep_dims: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If true, retain reduced dimensions with length 1.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Min&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_min_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Min&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Min&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Min</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Min&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">_min</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_min_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Min&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Min&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="minimum"><a class="viewcode-back" href="../../../../index.html#tensorflow.minimum">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.minimum&#39;</span><span class="p">,</span> <span class="s1">&#39;minimum&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">minimum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the min of x and y (i.e. x &lt; y ? x : y) element-wise.</span>

<span class="sd">  Example:</span>
<span class="sd">  &gt;&gt;&gt; x = tf.constant([0., 0., 0., 0.])</span>
<span class="sd">  &gt;&gt;&gt; y = tf.constant([-5., -2., 0., 3.])</span>
<span class="sd">  &gt;&gt;&gt; tf.math.minimum(x, y)</span>
<span class="sd">  &lt;tf.Tensor: shape=(4,), dtype=float32, numpy=array([-5., -2., 0., 0.], dtype=float32)&gt;</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Minimum&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">minimum_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">minimum</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Minimum&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">minimum</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Minimum&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Minimum</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Minimum&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">minimum</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">minimum_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Minimum&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Minimum&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">mod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns element-wise remainder of division. This emulates C semantics in that</span>

<span class="sd">  the result here is consistent with a truncating divide. E.g.</span>
<span class="sd">  `tf.truncatediv(x, y) * y + truncate_mod(x, y) = x`.</span>

<span class="sd">  *NOTE*: `Mod` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `half`, `half`, `bfloat16`, `float32`, `float64`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Mod&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">mod_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Mod&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Mod&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Mod</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Mod&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">mod</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">mod_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Mod&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Mod&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns x * y element-wise.</span>

<span class="sd">  *NOTE*: `Multiply` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Mul&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">mul_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Mul&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Mul&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Mul</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Mul&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">mul</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">mul_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Mul&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Mul&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">mul_no_nan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns x * y element-wise. Returns zero if y is zero, even if x if infinite or NaN.</span>

<span class="sd">  *NOTE*: `MulNoNan` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;MulNoNan&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">mul_no_nan_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;MulNoNan&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MulNoNan&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">MulNoNan</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.MulNoNan&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">mul_no_nan</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">mul_no_nan_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;MulNoNan&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MulNoNan&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">ndtri</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;TODO: add doc.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Ndtri&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ndtri_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Ndtri&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Ndtri&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Ndtri</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Ndtri&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">ndtri</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">ndtri_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Ndtri&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Ndtri&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.negative&#39;</span><span class="p">,</span> <span class="s1">&#39;negative&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">neg</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes numerical negative value element-wise.</span>

<span class="sd">  I.e., \\(y = -x\\).</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Neg&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">neg_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">neg</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Neg&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">neg</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Neg&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Neg</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Neg&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">neg</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">neg_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Neg&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Neg&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.nextafter&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">next_after</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the next representable value of `x1` in the direction of `x2`, element-wise.</span>

<span class="sd">  This operation returns the same result as the C++ std::nextafter function.</span>

<span class="sd">  It can also return a subnormal number.</span>

<span class="sd">  @compatibility(cpp)</span>
<span class="sd">  Equivalent to C++ std::nextafter function.</span>
<span class="sd">  @end_compatibility</span>

<span class="sd">  Args:</span>
<span class="sd">    x1: A `Tensor`. Must be one of the following types: `float64`, `float32`.</span>
<span class="sd">    x2: A `Tensor`. Must have the same type as `x1`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x1`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;NextAfter&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">next_after_eager_fallback</span><span class="p">(</span>
            <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">next_after</span><span class="p">,</span> <span class="n">x1</span><span class="o">=</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="o">=</span><span class="n">x2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;NextAfter&quot;</span><span class="p">,</span> <span class="n">x1</span><span class="o">=</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="o">=</span><span class="n">x2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">next_after</span><span class="p">,</span> <span class="n">x1</span><span class="o">=</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="o">=</span><span class="n">x2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;NextAfter&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">NextAfter</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.NextAfter&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">next_after</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">next_after_eager_fallback</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;NextAfter&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;NextAfter&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">not_equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">incompatible_shape_error</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the truth value of (x != y) element-wise.</span>

<span class="sd">  *NOTE*: `NotEqual` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `int16`, `int32`, `int64`, `complex64`, `quint8`, `qint8`, `qint32`, `string`, `bool`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    incompatible_shape_error: An optional `bool`. Defaults to `True`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `bool`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;NotEqual&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;incompatible_shape_error&quot;</span><span class="p">,</span>
        <span class="n">incompatible_shape_error</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">not_equal_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">incompatible_shape_error</span><span class="o">=</span><span class="n">incompatible_shape_error</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">incompatible_shape_error</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">incompatible_shape_error</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">incompatible_shape_error</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">incompatible_shape_error</span><span class="p">,</span> <span class="s2">&quot;incompatible_shape_error&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;NotEqual&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                    <span class="n">incompatible_shape_error</span><span class="o">=</span><span class="n">incompatible_shape_error</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;incompatible_shape_error&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;incompatible_shape_error&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;NotEqual&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">NotEqual</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.NotEqual&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">not_equal</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">not_equal_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">incompatible_shape_error</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">incompatible_shape_error</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">incompatible_shape_error</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">incompatible_shape_error</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">incompatible_shape_error</span><span class="p">,</span> <span class="s2">&quot;incompatible_shape_error&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;incompatible_shape_error&quot;</span><span class="p">,</span>
  <span class="n">incompatible_shape_error</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;NotEqual&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;NotEqual&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.polygamma&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.polygamma&#39;</span><span class="p">,</span> <span class="s1">&#39;polygamma&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;polygamma&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">polygamma</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the polygamma function \\(\psi^{(n)}(x)\\).</span>

<span class="sd">  The polygamma function is defined as:</span>


<span class="sd">  \\(\psi^{(a)}(x) = \frac{d^a}{dx^a} \psi(x)\\)</span>

<span class="sd">  where \\(\psi(x)\\) is the digamma function.</span>
<span class="sd">  The polygamma function is defined only for non-negative integer orders \\a\\.</span>

<span class="sd">  Args:</span>
<span class="sd">    a: A `Tensor`. Must be one of the following types: `float32`, `float64`.</span>
<span class="sd">    x: A `Tensor`. Must have the same type as `a`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `a`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Polygamma&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">polygamma_eager_fallback</span><span class="p">(</span>
            <span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">polygamma</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Polygamma&quot;</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">polygamma</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Polygamma&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Polygamma</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Polygamma&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">polygamma</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">polygamma_eager_fallback</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Polygamma&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Polygamma&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">_pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the power of one value to another.</span>

<span class="sd">  Given a tensor `x` and a tensor `y`, this operation computes \\(x^y\\) for</span>
<span class="sd">  corresponding elements in `x` and `y`. For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;x&#39; is [[2, 2]], [3, 3]]</span>
<span class="sd">  # tensor &#39;y&#39; is [[8, 16], [2, 3]]</span>
<span class="sd">  tf.pow(x, y) ==&gt; [[256, 65536], [9, 27]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `float32`, `half`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Pow&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_pow_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Pow&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Pow&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Pow</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Pow&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">_pow</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_pow_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Pow&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Pow&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">prod</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the product of elements across dimensions of a tensor.</span>

<span class="sd">  Reduces `input` along the dimensions given in `axis`. Unless</span>
<span class="sd">  `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in</span>
<span class="sd">  `axis`. If `keep_dims` is true, the reduced dimensions are</span>
<span class="sd">  retained with length 1.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">      The tensor to reduce.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      The dimensions to reduce. Must be in the range</span>
<span class="sd">      `[-rank(input), rank(input))`.</span>
<span class="sd">    keep_dims: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If true, retain reduced dimensions with length 1.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Prod&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">prod_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Prod&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Prod&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Prod</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Prod&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">prod</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">prod_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Prod&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Prod&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_QuantizeDownAndShrinkRangeOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;QuantizeDownAndShrinkRange&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">,</span> <span class="s2">&quot;output_min&quot;</span><span class="p">,</span> <span class="s2">&quot;output_max&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">quantize_down_and_shrink_range</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Convert the quantized &#39;input&#39; tensor into a lower-precision &#39;output&#39;, using the</span>

<span class="sd">  actual distribution of the values to maximize the usage of the lower bit depth</span>
<span class="sd">  and adjusting the output min and max ranges accordingly.</span>

<span class="sd">  [input_min, input_max] are scalar floats that specify the range for the float</span>
<span class="sd">  interpretation of the &#39;input&#39; data. For example, if input_min is -1.0f and</span>
<span class="sd">  input_max is 1.0f, and we are dealing with quint16 quantized data, then a 0</span>
<span class="sd">  value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.</span>

<span class="sd">  This operator tries to squeeze as much precision as possible into an output with</span>
<span class="sd">  a lower bit depth by calculating the actual min and max values found in the</span>
<span class="sd">  data. For example, maybe that quint16 input has no values lower than 16,384 and</span>
<span class="sd">  none higher than 49,152. That means only half the range is actually needed, all</span>
<span class="sd">  the float interpretations are between -0.5f and 0.5f, so if we want to compress</span>
<span class="sd">  the data into a quint8 output, we can use that range rather than the theoretical</span>
<span class="sd">  -1.0f to 1.0f that is suggested by the input min and max.</span>

<span class="sd">  In practice, this is most useful for taking output from operations like</span>
<span class="sd">  QuantizedMatMul that can produce higher bit-depth outputs than their inputs and</span>
<span class="sd">  may have large potential output ranges, but in practice have a distribution of</span>
<span class="sd">  input values that only uses a small fraction of the possible range. By feeding</span>
<span class="sd">  that output into this operator, we can reduce it from 32 bits down to 8 with</span>
<span class="sd">  minimal loss of accuracy.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.</span>
<span class="sd">    input_min: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the minimum quantized input value represents.</span>
<span class="sd">    input_max: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the maximum quantized input value represents.</span>
<span class="sd">    out_type: A `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`.</span>
<span class="sd">      The type of the output. Should be a lower bit depth than Tinput.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (output, output_min, output_max).</span>

<span class="sd">    output: A `Tensor` of type `out_type`.</span>
<span class="sd">    output_min: A `Tensor` of type `float32`.</span>
<span class="sd">    output_max: A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;QuantizeDownAndShrinkRange&quot;</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span>
        <span class="n">out_type</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizeDownAndShrinkRangeOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">quantize_down_and_shrink_range_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeDownAndShrinkRange&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="o">=</span><span class="n">input_min</span><span class="p">,</span>
                                      <span class="n">input_max</span><span class="o">=</span><span class="n">input_max</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span>
                                      <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Tinput&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tinput&quot;</span><span class="p">),</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;out_type&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeDownAndShrinkRange&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizeDownAndShrinkRangeOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">QuantizeDownAndShrinkRange</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.QuantizeDownAndShrinkRange&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">quantize_down_and_shrink_range</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">quantize_down_and_shrink_range_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_attr_Tinput</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">input_min</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">input_min</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">input_max</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">input_max</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Tinput&quot;</span><span class="p">,</span> <span class="n">_attr_Tinput</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;QuantizeDownAndShrinkRange&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeDownAndShrinkRange&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizeDownAndShrinkRangeOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_QuantizedAddOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;QuantizedAdd&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="s2">&quot;min_z&quot;</span><span class="p">,</span> <span class="s2">&quot;max_z&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">quantized_add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_y</span><span class="p">,</span> <span class="n">Toutput</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">qint32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns x + y element-wise, working on quantized buffers.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.</span>
<span class="sd">    y: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.</span>
<span class="sd">    min_x: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the lowest quantized `x` value represents.</span>
<span class="sd">    max_x: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the highest quantized `x` value represents.</span>
<span class="sd">    min_y: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the lowest quantized `y` value represents.</span>
<span class="sd">    max_y: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the highest quantized `y` value represents.</span>
<span class="sd">    Toutput: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (z, min_z, max_z).</span>

<span class="sd">    z: A `Tensor` of type `Toutput`.</span>
<span class="sd">    min_z: A `Tensor` of type `float32`.</span>
<span class="sd">    max_z: A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;QuantizedAdd&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_y</span><span class="p">,</span> <span class="s2">&quot;Toutput&quot;</span><span class="p">,</span>
        <span class="n">Toutput</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedAddOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">quantized_add_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_y</span><span class="p">,</span> <span class="n">Toutput</span><span class="o">=</span><span class="n">Toutput</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">Toutput</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Toutput</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">qint32</span>
  <span class="n">Toutput</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Toutput</span><span class="p">,</span> <span class="s2">&quot;Toutput&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedAdd&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">min_x</span><span class="o">=</span><span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="o">=</span><span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="o">=</span><span class="n">min_y</span><span class="p">,</span>
                        <span class="n">max_y</span><span class="o">=</span><span class="n">max_y</span><span class="p">,</span> <span class="n">Toutput</span><span class="o">=</span><span class="n">Toutput</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T1&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T1&quot;</span><span class="p">),</span> <span class="s2">&quot;T2&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T2&quot;</span><span class="p">),</span>
              <span class="s2">&quot;Toutput&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Toutput&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedAdd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedAddOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">QuantizedAdd</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.QuantizedAdd&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">quantized_add</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">quantized_add_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_y</span><span class="p">,</span> <span class="n">Toutput</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">Toutput</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Toutput</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">qint32</span>
  <span class="n">Toutput</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Toutput</span><span class="p">,</span> <span class="s2">&quot;Toutput&quot;</span><span class="p">)</span>
  <span class="n">_attr_T1</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_T2</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">min_x</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">max_x</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">max_x</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">min_y</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">min_y</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">max_y</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">max_y</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T1&quot;</span><span class="p">,</span> <span class="n">_attr_T1</span><span class="p">,</span> <span class="s2">&quot;T2&quot;</span><span class="p">,</span> <span class="n">_attr_T2</span><span class="p">,</span> <span class="s2">&quot;Toutput&quot;</span><span class="p">,</span> <span class="n">Toutput</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;QuantizedAdd&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedAdd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedAddOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_QuantizedMatMulOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;QuantizedMatMul&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;out&quot;</span><span class="p">,</span> <span class="s2">&quot;min_out&quot;</span><span class="p">,</span> <span class="s2">&quot;max_out&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">quantized_mat_mul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">min_a</span><span class="p">,</span> <span class="n">max_a</span><span class="p">,</span> <span class="n">min_b</span><span class="p">,</span> <span class="n">max_b</span><span class="p">,</span> <span class="n">Toutput</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">qint32</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">Tactivation</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">quint8</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Perform a quantized matrix multiplication of  `a` by the matrix `b`.</span>

<span class="sd">  The inputs must be two-dimensional matrices and the inner dimension of</span>
<span class="sd">  `a` (after being transposed if `transpose_a` is non-zero) must match the</span>
<span class="sd">  outer dimension of `b` (after being transposed if `transposed_b` is</span>
<span class="sd">  non-zero).</span>

<span class="sd">  Args:</span>
<span class="sd">    a: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.</span>
<span class="sd">      Must be a two-dimensional tensor.</span>
<span class="sd">    b: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.</span>
<span class="sd">      Must be a two-dimensional tensor.</span>
<span class="sd">    min_a: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the lowest quantized `a` value represents.</span>
<span class="sd">    max_a: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the highest quantized `a` value represents.</span>
<span class="sd">    min_b: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the lowest quantized `b` value represents.</span>
<span class="sd">    max_b: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the highest quantized `b` value represents.</span>
<span class="sd">    Toutput: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.</span>
<span class="sd">    transpose_a: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If true, `a` is transposed before multiplication.</span>
<span class="sd">    transpose_b: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If true, `b` is transposed before multiplication.</span>
<span class="sd">    Tactivation: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.quint8`.</span>
<span class="sd">      The type of output produced by activation function</span>
<span class="sd">      following this operation.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (out, min_out, max_out).</span>

<span class="sd">    out: A `Tensor` of type `Toutput`.</span>
<span class="sd">    min_out: A `Tensor` of type `float32`.</span>
<span class="sd">    max_out: A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;QuantizedMatMul&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">min_a</span><span class="p">,</span> <span class="n">max_a</span><span class="p">,</span> <span class="n">min_b</span><span class="p">,</span> <span class="n">max_b</span><span class="p">,</span> <span class="s2">&quot;Toutput&quot;</span><span class="p">,</span>
        <span class="n">Toutput</span><span class="p">,</span> <span class="s2">&quot;transpose_a&quot;</span><span class="p">,</span> <span class="n">transpose_a</span><span class="p">,</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">,</span> <span class="n">transpose_b</span><span class="p">,</span>
        <span class="s2">&quot;Tactivation&quot;</span><span class="p">,</span> <span class="n">Tactivation</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedMatMulOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">quantized_mat_mul_eager_fallback</span><span class="p">(</span>
            <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">min_a</span><span class="p">,</span> <span class="n">max_a</span><span class="p">,</span> <span class="n">min_b</span><span class="p">,</span> <span class="n">max_b</span><span class="p">,</span> <span class="n">Toutput</span><span class="o">=</span><span class="n">Toutput</span><span class="p">,</span>
            <span class="n">transpose_a</span><span class="o">=</span><span class="n">transpose_a</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="n">transpose_b</span><span class="p">,</span>
            <span class="n">Tactivation</span><span class="o">=</span><span class="n">Tactivation</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">Toutput</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Toutput</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">qint32</span>
  <span class="n">Toutput</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Toutput</span><span class="p">,</span> <span class="s2">&quot;Toutput&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">transpose_a</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">transpose_a</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">transpose_a</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">transpose_a</span><span class="p">,</span> <span class="s2">&quot;transpose_a&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">transpose_b</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">transpose_b</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">transpose_b</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">transpose_b</span><span class="p">,</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">Tactivation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Tactivation</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">quint8</span>
  <span class="n">Tactivation</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Tactivation</span><span class="p">,</span> <span class="s2">&quot;Tactivation&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedMatMul&quot;</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">min_a</span><span class="o">=</span><span class="n">min_a</span><span class="p">,</span> <span class="n">max_a</span><span class="o">=</span><span class="n">max_a</span><span class="p">,</span> <span class="n">min_b</span><span class="o">=</span><span class="n">min_b</span><span class="p">,</span>
                           <span class="n">max_b</span><span class="o">=</span><span class="n">max_b</span><span class="p">,</span> <span class="n">Toutput</span><span class="o">=</span><span class="n">Toutput</span><span class="p">,</span>
                           <span class="n">transpose_a</span><span class="o">=</span><span class="n">transpose_a</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="n">transpose_b</span><span class="p">,</span>
                           <span class="n">Tactivation</span><span class="o">=</span><span class="n">Tactivation</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T1&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T1&quot;</span><span class="p">),</span> <span class="s2">&quot;T2&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T2&quot;</span><span class="p">),</span>
              <span class="s2">&quot;Toutput&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Toutput&quot;</span><span class="p">),</span> <span class="s2">&quot;transpose_a&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;transpose_a&quot;</span><span class="p">),</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;transpose_b&quot;</span><span class="p">),</span> <span class="s2">&quot;Tactivation&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tactivation&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedMatMul&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedMatMulOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">QuantizedMatMul</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.QuantizedMatMul&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">quantized_mat_mul</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">quantized_mat_mul_eager_fallback</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">min_a</span><span class="p">,</span> <span class="n">max_a</span><span class="p">,</span> <span class="n">min_b</span><span class="p">,</span> <span class="n">max_b</span><span class="p">,</span> <span class="n">Toutput</span><span class="p">,</span> <span class="n">transpose_a</span><span class="p">,</span> <span class="n">transpose_b</span><span class="p">,</span> <span class="n">Tactivation</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">Toutput</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Toutput</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">qint32</span>
  <span class="n">Toutput</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Toutput</span><span class="p">,</span> <span class="s2">&quot;Toutput&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">transpose_a</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">transpose_a</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">transpose_a</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">transpose_a</span><span class="p">,</span> <span class="s2">&quot;transpose_a&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">transpose_b</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">transpose_b</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">transpose_b</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">transpose_b</span><span class="p">,</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">Tactivation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Tactivation</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">quint8</span>
  <span class="n">Tactivation</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Tactivation</span><span class="p">,</span> <span class="s2">&quot;Tactivation&quot;</span><span class="p">)</span>
  <span class="n">_attr_T1</span><span class="p">,</span> <span class="p">(</span><span class="n">a</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">a</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_T2</span><span class="p">,</span> <span class="p">(</span><span class="n">b</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">b</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">min_a</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">min_a</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">max_a</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">max_a</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">min_b</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">min_b</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">max_b</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">max_b</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">min_a</span><span class="p">,</span> <span class="n">max_a</span><span class="p">,</span> <span class="n">min_b</span><span class="p">,</span> <span class="n">max_b</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T1&quot;</span><span class="p">,</span> <span class="n">_attr_T1</span><span class="p">,</span> <span class="s2">&quot;T2&quot;</span><span class="p">,</span> <span class="n">_attr_T2</span><span class="p">,</span> <span class="s2">&quot;Toutput&quot;</span><span class="p">,</span> <span class="n">Toutput</span><span class="p">,</span> <span class="s2">&quot;transpose_a&quot;</span><span class="p">,</span>
  <span class="n">transpose_a</span><span class="p">,</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">,</span> <span class="n">transpose_b</span><span class="p">,</span> <span class="s2">&quot;Tactivation&quot;</span><span class="p">,</span> <span class="n">Tactivation</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;QuantizedMatMul&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedMatMul&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedMatMulOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_QuantizedMulOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;QuantizedMul&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;z&quot;</span><span class="p">,</span> <span class="s2">&quot;min_z&quot;</span><span class="p">,</span> <span class="s2">&quot;max_z&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">quantized_mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_y</span><span class="p">,</span> <span class="n">Toutput</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">qint32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns x * y element-wise, working on quantized buffers.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.</span>
<span class="sd">    y: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.</span>
<span class="sd">    min_x: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the lowest quantized `x` value represents.</span>
<span class="sd">    max_x: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the highest quantized `x` value represents.</span>
<span class="sd">    min_y: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the lowest quantized `y` value represents.</span>
<span class="sd">    max_y: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the highest quantized `y` value represents.</span>
<span class="sd">    Toutput: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (z, min_z, max_z).</span>

<span class="sd">    z: A `Tensor` of type `Toutput`.</span>
<span class="sd">    min_z: A `Tensor` of type `float32`.</span>
<span class="sd">    max_z: A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;QuantizedMul&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_y</span><span class="p">,</span> <span class="s2">&quot;Toutput&quot;</span><span class="p">,</span>
        <span class="n">Toutput</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedMulOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">quantized_mul_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_y</span><span class="p">,</span> <span class="n">Toutput</span><span class="o">=</span><span class="n">Toutput</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">Toutput</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Toutput</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">qint32</span>
  <span class="n">Toutput</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Toutput</span><span class="p">,</span> <span class="s2">&quot;Toutput&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedMul&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">min_x</span><span class="o">=</span><span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="o">=</span><span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="o">=</span><span class="n">min_y</span><span class="p">,</span>
                        <span class="n">max_y</span><span class="o">=</span><span class="n">max_y</span><span class="p">,</span> <span class="n">Toutput</span><span class="o">=</span><span class="n">Toutput</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T1&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T1&quot;</span><span class="p">),</span> <span class="s2">&quot;T2&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T2&quot;</span><span class="p">),</span>
              <span class="s2">&quot;Toutput&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Toutput&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedMul&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedMulOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">QuantizedMul</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.QuantizedMul&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">quantized_mul</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">quantized_mul_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_y</span><span class="p">,</span> <span class="n">Toutput</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">Toutput</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Toutput</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">qint32</span>
  <span class="n">Toutput</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Toutput</span><span class="p">,</span> <span class="s2">&quot;Toutput&quot;</span><span class="p">)</span>
  <span class="n">_attr_T1</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_T2</span><span class="p">,</span> <span class="p">(</span><span class="n">y</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">min_x</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">max_x</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">max_x</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">min_y</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">min_y</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">max_y</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">max_y</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">min_x</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T1&quot;</span><span class="p">,</span> <span class="n">_attr_T1</span><span class="p">,</span> <span class="s2">&quot;T2&quot;</span><span class="p">,</span> <span class="n">_attr_T2</span><span class="p">,</span> <span class="s2">&quot;Toutput&quot;</span><span class="p">,</span> <span class="n">Toutput</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;QuantizedMul&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedMul&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedMulOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">_range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Creates a sequence of numbers.</span>

<span class="sd">  This operation creates a sequence of numbers that begins at `start` and</span>
<span class="sd">  extends by increments of `delta` up to but not including `limit`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;start&#39; is 3</span>
<span class="sd">  # &#39;limit&#39; is 18</span>
<span class="sd">  # &#39;delta&#39; is 3</span>
<span class="sd">  tf.range(start, limit, delta) ==&gt; [3, 6, 9, 12, 15]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    start: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`.</span>
<span class="sd">      0-D (scalar). First entry in the sequence.</span>
<span class="sd">    limit: A `Tensor`. Must have the same type as `start`.</span>
<span class="sd">      0-D (scalar). Upper limit of sequence, exclusive.</span>
<span class="sd">    delta: A `Tensor`. Must have the same type as `start`.</span>
<span class="sd">      0-D (scalar). Optional. Default is 1. Number that increments `start`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `start`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Range&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="n">delta</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_range_eager_fallback</span><span class="p">(</span>
            <span class="n">start</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Range&quot;</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">start</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="n">limit</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="n">delta</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Range&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Range</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Range&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">_range</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_range_eager_fallback</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="n">_inputs_Tidx</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">start</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="n">delta</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="n">delta</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_Tidx</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">start</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="n">delta</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Range&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Range&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">real</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the real part of a complex number.</span>

<span class="sd">  Given a tensor `input` of complex numbers, this operation returns a tensor of</span>
<span class="sd">  type `float` that is the real part of each element in `input`. All elements in</span>
<span class="sd">  `input` must be complex numbers of the form \\(a + bj\\), where *a* is the real</span>
<span class="sd">   part returned by this operation and *b* is the imaginary part.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;input&#39; is [-2.25 + 4.75j, 3.25 + 5.75j]</span>
<span class="sd">  tf.real(input) ==&gt; [-2.25, 3.25]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.</span>
<span class="sd">    Tout: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `Tout`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Real&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span> <span class="n">Tout</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">real_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">Tout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Tout</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span>
  <span class="n">Tout</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Tout</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Real&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">Tout</span><span class="o">=</span><span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tout&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Real&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Real</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Real&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">real</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">real_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">Tout</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">Tout</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">Tout</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span>
  <span class="n">Tout</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">Tout</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">complex64</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tout&quot;</span><span class="p">,</span> <span class="n">Tout</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Real&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Real&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;realdiv&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">real_div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns x / y element-wise for real types.</span>

<span class="sd">  If `x` and `y` are reals, this will return the floating-point division.</span>

<span class="sd">  *NOTE*: `Div` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;RealDiv&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">real_div_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">real_div</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;RealDiv&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">real_div</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;RealDiv&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">RealDiv</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.RealDiv&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">real_div</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">real_div_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;RealDiv&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;RealDiv&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.reciprocal&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.reciprocal&#39;</span><span class="p">,</span> <span class="s1">&#39;reciprocal&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;reciprocal&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">reciprocal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the reciprocal of x element-wise.</span>

<span class="sd">  I.e., \\(y = 1 / x\\).</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Reciprocal&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">reciprocal_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">reciprocal</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Reciprocal&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">reciprocal</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Reciprocal&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Reciprocal</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Reciprocal&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">reciprocal</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">reciprocal_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Reciprocal&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Reciprocal&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">reciprocal_grad</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the gradient for the inverse of `x` wrt its input.</span>

<span class="sd">  Specifically, `grad = -dy * y*y`, where `y = 1/x`, and `dy`</span>
<span class="sd">  is the corresponding input gradient.</span>

<span class="sd">  Args:</span>
<span class="sd">    y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    dy: A `Tensor`. Must have the same type as `y`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `y`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ReciprocalGrad&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">reciprocal_grad_eager_fallback</span><span class="p">(</span>
            <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ReciprocalGrad&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ReciprocalGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ReciprocalGrad</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ReciprocalGrad&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">reciprocal_grad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">reciprocal_grad_eager_fallback</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ReciprocalGrad&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ReciprocalGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_RequantizationRangeOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;RequantizationRange&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;output_min&quot;</span><span class="p">,</span> <span class="s2">&quot;output_max&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">requantization_range</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes a range that covers the actual values present in a quantized tensor.</span>

<span class="sd">  Given a quantized tensor described by `(input, input_min, input_max)`, outputs a</span>
<span class="sd">  range that covers the actual values present in that tensor. This op is typically</span>
<span class="sd">  used to produce the `requested_output_min` and `requested_output_max` for</span>
<span class="sd">  `Requantize`.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.</span>
<span class="sd">    input_min: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the minimum quantized input value represents.</span>
<span class="sd">    input_max: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the maximum quantized input value represents.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (output_min, output_max).</span>

<span class="sd">    output_min: A `Tensor` of type `float32`.</span>
<span class="sd">    output_max: A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;RequantizationRange&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_RequantizationRangeOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">requantization_range_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;RequantizationRange&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="o">=</span><span class="n">input_min</span><span class="p">,</span>
                               <span class="n">input_max</span><span class="o">=</span><span class="n">input_max</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Tinput&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tinput&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;RequantizationRange&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_RequantizationRangeOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">RequantizationRange</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.RequantizationRange&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">requantization_range</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">requantization_range_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_Tinput</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">input_min</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">input_min</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">input_max</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">input_max</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Tinput&quot;</span><span class="p">,</span> <span class="n">_attr_Tinput</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;RequantizationRange&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;RequantizationRange&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_RequantizationRangeOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_RequantizationRangePerChannelOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;RequantizationRangePerChannel&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;output_min&quot;</span><span class="p">,</span> <span class="s2">&quot;output_max&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">requantization_range_per_channel</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">clip_value_max</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes requantization range per channel.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.</span>
<span class="sd">      The original input tensor.</span>
<span class="sd">    input_min: A `Tensor` of type `float32`.</span>
<span class="sd">      The minimum value of the input tensor</span>
<span class="sd">    input_max: A `Tensor` of type `float32`.</span>
<span class="sd">      The maximum value of the input tensor.</span>
<span class="sd">    clip_value_max: A `float`.</span>
<span class="sd">      The maximum value of the output that needs to be clipped.</span>
<span class="sd">      Example: set this to 6 for Relu6.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (output_min, output_max).</span>

<span class="sd">    output_min: A `Tensor` of type `float32`.</span>
<span class="sd">    output_max: A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span>
        <span class="s2">&quot;RequantizationRangePerChannel&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span>
        <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="s2">&quot;clip_value_max&quot;</span><span class="p">,</span> <span class="n">clip_value_max</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_RequantizationRangePerChannelOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">requantization_range_per_channel_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">clip_value_max</span><span class="o">=</span><span class="n">clip_value_max</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">clip_value_max</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">clip_value_max</span><span class="p">,</span> <span class="s2">&quot;clip_value_max&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;RequantizationRangePerChannel&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="o">=</span><span class="n">input_min</span><span class="p">,</span>
                                         <span class="n">input_max</span><span class="o">=</span><span class="n">input_max</span><span class="p">,</span>
                                         <span class="n">clip_value_max</span><span class="o">=</span><span class="n">clip_value_max</span><span class="p">,</span>
                                         <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;clip_value_max&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;clip_value_max&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;RequantizationRangePerChannel&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_RequantizationRangePerChannelOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">RequantizationRangePerChannel</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.RequantizationRangePerChannel&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">requantization_range_per_channel</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">requantization_range_per_channel_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">clip_value_max</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">clip_value_max</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">clip_value_max</span><span class="p">,</span> <span class="s2">&quot;clip_value_max&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">qint32</span><span class="p">)</span>
  <span class="n">input_min</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">input_min</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">input_max</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">input_max</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;clip_value_max&quot;</span><span class="p">,</span> <span class="n">clip_value_max</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;RequantizationRangePerChannel&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;RequantizationRangePerChannel&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_RequantizationRangePerChannelOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_RequantizeOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;Requantize&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">,</span> <span class="s2">&quot;output_min&quot;</span><span class="p">,</span> <span class="s2">&quot;output_max&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">requantize</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">requested_output_min</span><span class="p">,</span> <span class="n">requested_output_max</span><span class="p">,</span> <span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Converts the quantized `input` tensor into a lower-precision `output`.</span>

<span class="sd">  Converts the quantized `input` tensor into a lower-precision `output`, using the</span>
<span class="sd">  output range specified with `requested_output_min` and `requested_output_max`.</span>

<span class="sd">  `[input_min, input_max]` are scalar floats that specify the range for the float</span>
<span class="sd">  interpretation of the `input` data. For example, if `input_min` is -1.0f and</span>
<span class="sd">  `input_max` is 1.0f, and we are dealing with `quint16` quantized data, then a 0</span>
<span class="sd">  value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.</span>
<span class="sd">    input_min: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the minimum quantized input value represents.</span>
<span class="sd">    input_max: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the maximum quantized input value represents.</span>
<span class="sd">    requested_output_min: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the minimum quantized output value represents.</span>
<span class="sd">    requested_output_max: A `Tensor` of type `float32`.</span>
<span class="sd">      The float value that the maximum quantized output value represents.</span>
<span class="sd">    out_type: A `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`.</span>
<span class="sd">      The type of the output. Should be a lower bit depth than Tinput.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (output, output_min, output_max).</span>

<span class="sd">    output: A `Tensor` of type `out_type`.</span>
<span class="sd">    output_min: A `Tensor` of type `float32`.</span>
<span class="sd">    output_max: A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Requantize&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">requested_output_min</span><span class="p">,</span>
        <span class="n">requested_output_max</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_RequantizeOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">requantize_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">requested_output_min</span><span class="p">,</span>
            <span class="n">requested_output_max</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Requantize&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="o">=</span><span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="o">=</span><span class="n">input_max</span><span class="p">,</span>
                      <span class="n">requested_output_min</span><span class="o">=</span><span class="n">requested_output_min</span><span class="p">,</span>
                      <span class="n">requested_output_max</span><span class="o">=</span><span class="n">requested_output_max</span><span class="p">,</span>
                      <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Tinput&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tinput&quot;</span><span class="p">),</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;out_type&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Requantize&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_RequantizeOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Requantize</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Requantize&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">requantize</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">requantize_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">requested_output_min</span><span class="p">,</span> <span class="n">requested_output_max</span><span class="p">,</span> <span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_attr_Tinput</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">input_min</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">input_min</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">input_max</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">input_max</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">requested_output_min</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">requested_output_min</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">requested_output_max</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">requested_output_max</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">requested_output_min</span><span class="p">,</span> <span class="n">requested_output_max</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Tinput&quot;</span><span class="p">,</span> <span class="n">_attr_Tinput</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Requantize&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Requantize&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_RequantizeOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_RequantizePerChannelOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;RequantizePerChannel&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">,</span> <span class="s2">&quot;output_min&quot;</span><span class="p">,</span> <span class="s2">&quot;output_max&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">requantize_per_channel</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">requested_output_min</span><span class="p">,</span> <span class="n">requested_output_max</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">quint8</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Requantizes input with min and max values known per channel.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.</span>
<span class="sd">      The original input tensor.</span>
<span class="sd">    input_min: A `Tensor` of type `float32`.</span>
<span class="sd">      The minimum value of the input tensor</span>
<span class="sd">    input_max: A `Tensor` of type `float32`.</span>
<span class="sd">      The maximum value of the input tensor.</span>
<span class="sd">    requested_output_min: A `Tensor` of type `float32`.</span>
<span class="sd">      The minimum value of the output tensor requested.</span>
<span class="sd">    requested_output_max: A `Tensor` of type `float32`.</span>
<span class="sd">      The maximum value of the output tensor requested.</span>
<span class="sd">    out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.quint8`.</span>
<span class="sd">      The quantized type of output tensor that needs to be converted.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (output, output_min, output_max).</span>

<span class="sd">    output: A `Tensor` of type `out_type`.</span>
<span class="sd">    output_min: A `Tensor` of type `float32`.</span>
<span class="sd">    output_max: A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;RequantizePerChannel&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">requested_output_min</span><span class="p">,</span>
        <span class="n">requested_output_max</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_RequantizePerChannelOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">requantize_per_channel_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">requested_output_min</span><span class="p">,</span>
            <span class="n">requested_output_max</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">out_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">quint8</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;RequantizePerChannel&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="o">=</span><span class="n">input_min</span><span class="p">,</span>
                                <span class="n">input_max</span><span class="o">=</span><span class="n">input_max</span><span class="p">,</span>
                                <span class="n">requested_output_min</span><span class="o">=</span><span class="n">requested_output_min</span><span class="p">,</span>
                                <span class="n">requested_output_max</span><span class="o">=</span><span class="n">requested_output_max</span><span class="p">,</span>
                                <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;out_type&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;RequantizePerChannel&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_RequantizePerChannelOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">RequantizePerChannel</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.RequantizePerChannel&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">requantize_per_channel</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">requantize_per_channel_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">requested_output_min</span><span class="p">,</span> <span class="n">requested_output_max</span><span class="p">,</span> <span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">out_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">quint8</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">qint32</span><span class="p">)</span>
  <span class="n">input_min</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">input_min</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">input_max</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">input_max</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">requested_output_min</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">requested_output_min</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">requested_output_max</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">requested_output_max</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">requested_output_min</span><span class="p">,</span> <span class="n">requested_output_max</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;RequantizePerChannel&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;RequantizePerChannel&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_RequantizePerChannelOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.rint&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.rint&#39;</span><span class="p">,</span> <span class="s1">&#39;rint&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;rint&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">rint</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns element-wise integer closest to x.</span>

<span class="sd">  If the result is midway between two representable values,</span>
<span class="sd">  the even representable is chosen.</span>
<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  rint(-1.5) ==&gt; -2.0</span>
<span class="sd">  rint(0.5000001) ==&gt; 1.0</span>
<span class="sd">  rint([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0]) ==&gt; [-2., -2., -0., 0., 2., 2., 2.]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Rint&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">rint_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">rint</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Rint&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">rint</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Rint&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Rint</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Rint&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">rint</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">rint_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Rint&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Rint&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">round</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Rounds the values of a tensor to the nearest integer, element-wise.</span>

<span class="sd">  Rounds half to even.  Also known as bankers rounding. If you want to round</span>
<span class="sd">  according to the current system rounding mode use std::cint.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Round&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">round_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Round&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Round&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Round</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Round&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="nb">round</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">round_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Round&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Round&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">rsqrt</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes reciprocal of square root of x element-wise.</span>

<span class="sd">  I.e., \\(y = 1 / \sqrt{x}\\).</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Rsqrt&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">rsqrt_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Rsqrt&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Rsqrt&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Rsqrt</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Rsqrt&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">rsqrt</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">rsqrt_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Rsqrt&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Rsqrt&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">rsqrt_grad</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the gradient for the rsqrt of `x` wrt its input.</span>

<span class="sd">  Specifically, `grad = dy * -0.5 * y^3`, where `y = rsqrt(x)`, and `dy`</span>
<span class="sd">  is the corresponding input gradient.</span>

<span class="sd">  Args:</span>
<span class="sd">    y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    dy: A `Tensor`. Must have the same type as `y`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `y`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;RsqrtGrad&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">rsqrt_grad_eager_fallback</span><span class="p">(</span>
            <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;RsqrtGrad&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;RsqrtGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">RsqrtGrad</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.RsqrtGrad&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">rsqrt_grad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">rsqrt_grad_eager_fallback</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;RsqrtGrad&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;RsqrtGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.segment_max&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.segment_max&#39;</span><span class="p">,</span> <span class="s1">&#39;segment_max&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;segment_max&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">segment_max</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the maximum along segments of a tensor.</span>

<span class="sd">  Read</span>
<span class="sd">  [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)</span>
<span class="sd">  for an explanation of segments.</span>

<span class="sd">  Computes a tensor such that</span>
<span class="sd">  \\(output_i = \max_j(data_j)\\) where `max` is over `j` such</span>
<span class="sd">  that `segment_ids[j] == i`.</span>

<span class="sd">  If the max is empty for a given segment ID `i`, `output[i] = 0`.</span>

<span class="sd">  &lt;div style=&quot;width:70%; margin:auto; margin-bottom:10px; margin-top:20px;&quot;&gt;</span>
<span class="sd">  &lt;img style=&quot;width:100%&quot; src=&quot;https://www.tensorflow.org/images/SegmentMax.png&quot; alt&gt;</span>
<span class="sd">  &lt;/div&gt;</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])</span>
<span class="sd">  tf.segment_max(c, tf.constant([0, 0, 1]))</span>
<span class="sd">  # ==&gt; [[4, 3, 3, 4],</span>
<span class="sd">  #      [5, 6, 7, 8]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A 1-D tensor whose size is equal to the size of `data`&#39;s</span>
<span class="sd">      first dimension.  Values should be sorted and can be repeated.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SegmentMax&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">segment_max_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">segment_max</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SegmentMax&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">segment_max</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SegmentMax&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SegmentMax</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SegmentMax&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">segment_max</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">segment_max_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">segment_ids</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">segment_ids</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SegmentMax&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SegmentMax&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.segment_mean&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.segment_mean&#39;</span><span class="p">,</span> <span class="s1">&#39;segment_mean&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;segment_mean&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">segment_mean</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the mean along segments of a tensor.</span>

<span class="sd">  Read</span>
<span class="sd">  [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)</span>
<span class="sd">  for an explanation of segments.</span>

<span class="sd">  Computes a tensor such that</span>
<span class="sd">  \\(output_i = \frac{\sum_j data_j}{N}\\) where `mean` is</span>
<span class="sd">  over `j` such that `segment_ids[j] == i` and `N` is the total number of</span>
<span class="sd">  values summed.</span>

<span class="sd">  If the mean is empty for a given segment ID `i`, `output[i] = 0`.</span>

<span class="sd">  &lt;div style=&quot;width:70%; margin:auto; margin-bottom:10px; margin-top:20px;&quot;&gt;</span>
<span class="sd">  &lt;img style=&quot;width:100%&quot; src=&quot;https://www.tensorflow.org/images/SegmentMean.png&quot; alt&gt;</span>
<span class="sd">  &lt;/div&gt;</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  c = tf.constant([[1.0,2,3,4], [4, 3, 2, 1], [5,6,7,8]])</span>
<span class="sd">  tf.segment_mean(c, tf.constant([0, 0, 1]))</span>
<span class="sd">  # ==&gt; [[2.5, 2.5, 2.5, 2.5],</span>
<span class="sd">  #      [5, 6, 7, 8]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A 1-D tensor whose size is equal to the size of `data`&#39;s</span>
<span class="sd">      first dimension.  Values should be sorted and can be repeated.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SegmentMean&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">segment_mean_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">segment_mean</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SegmentMean&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">segment_mean</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SegmentMean&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SegmentMean</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SegmentMean&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">segment_mean</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">segment_mean_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">segment_ids</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">segment_ids</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SegmentMean&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SegmentMean&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.segment_min&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.segment_min&#39;</span><span class="p">,</span> <span class="s1">&#39;segment_min&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;segment_min&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">segment_min</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the minimum along segments of a tensor.</span>

<span class="sd">  Read</span>
<span class="sd">  [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)</span>
<span class="sd">  for an explanation of segments.</span>

<span class="sd">  Computes a tensor such that</span>
<span class="sd">  \\(output_i = \min_j(data_j)\\) where `min` is over `j` such</span>
<span class="sd">  that `segment_ids[j] == i`.</span>

<span class="sd">  If the min is empty for a given segment ID `i`, `output[i] = 0`.</span>

<span class="sd">  &lt;div style=&quot;width:70%; margin:auto; margin-bottom:10px; margin-top:20px;&quot;&gt;</span>
<span class="sd">  &lt;img style=&quot;width:100%&quot; src=&quot;https://www.tensorflow.org/images/SegmentMin.png&quot; alt&gt;</span>
<span class="sd">  &lt;/div&gt;</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])</span>
<span class="sd">  tf.segment_min(c, tf.constant([0, 0, 1]))</span>
<span class="sd">  # ==&gt; [[1, 2, 2, 1],</span>
<span class="sd">  #      [5, 6, 7, 8]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A 1-D tensor whose size is equal to the size of `data`&#39;s</span>
<span class="sd">      first dimension.  Values should be sorted and can be repeated.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SegmentMin&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">segment_min_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">segment_min</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SegmentMin&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">segment_min</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SegmentMin&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SegmentMin</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SegmentMin&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">segment_min</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">segment_min_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">segment_ids</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">segment_ids</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SegmentMin&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SegmentMin&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.segment_prod&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.segment_prod&#39;</span><span class="p">,</span> <span class="s1">&#39;segment_prod&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;segment_prod&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">segment_prod</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the product along segments of a tensor.</span>

<span class="sd">  Read</span>
<span class="sd">  [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)</span>
<span class="sd">  for an explanation of segments.</span>

<span class="sd">  Computes a tensor such that</span>
<span class="sd">  \\(output_i = \prod_j data_j\\) where the product is over `j` such</span>
<span class="sd">  that `segment_ids[j] == i`.</span>

<span class="sd">  If the product is empty for a given segment ID `i`, `output[i] = 1`.</span>

<span class="sd">  &lt;div style=&quot;width:70%; margin:auto; margin-bottom:10px; margin-top:20px;&quot;&gt;</span>
<span class="sd">  &lt;img style=&quot;width:100%&quot; src=&quot;https://www.tensorflow.org/images/SegmentProd.png&quot; alt&gt;</span>
<span class="sd">  &lt;/div&gt;</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])</span>
<span class="sd">  tf.segment_prod(c, tf.constant([0, 0, 1]))</span>
<span class="sd">  # ==&gt; [[4, 6, 6, 4],</span>
<span class="sd">  #      [5, 6, 7, 8]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A 1-D tensor whose size is equal to the size of `data`&#39;s</span>
<span class="sd">      first dimension.  Values should be sorted and can be repeated.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SegmentProd&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">segment_prod_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">segment_prod</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SegmentProd&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">segment_prod</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SegmentProd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SegmentProd</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SegmentProd&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">segment_prod</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">segment_prod_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">segment_ids</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">segment_ids</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SegmentProd&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SegmentProd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.segment_sum&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.segment_sum&#39;</span><span class="p">,</span> <span class="s1">&#39;segment_sum&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;segment_sum&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">segment_sum</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the sum along segments of a tensor.</span>

<span class="sd">  Read</span>
<span class="sd">  [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)</span>
<span class="sd">  for an explanation of segments.</span>

<span class="sd">  Computes a tensor such that</span>
<span class="sd">  \\(output_i = \sum_j data_j\\) where sum is over `j` such</span>
<span class="sd">  that `segment_ids[j] == i`.</span>

<span class="sd">  If the sum is empty for a given segment ID `i`, `output[i] = 0`.</span>

<span class="sd">  &lt;div style=&quot;width:70%; margin:auto; margin-bottom:10px; margin-top:20px;&quot;&gt;</span>
<span class="sd">  &lt;img style=&quot;width:100%&quot; src=&quot;https://www.tensorflow.org/images/SegmentSum.png&quot; alt&gt;</span>
<span class="sd">  &lt;/div&gt;</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])</span>
<span class="sd">  tf.segment_sum(c, tf.constant([0, 0, 1]))</span>
<span class="sd">  # ==&gt; [[5, 5, 5, 5],</span>
<span class="sd">  #      [5, 6, 7, 8]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A 1-D tensor whose size is equal to the size of `data`&#39;s</span>
<span class="sd">      first dimension.  Values should be sorted and can be repeated.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SegmentSum&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">segment_sum_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">segment_sum</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SegmentSum&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">segment_sum</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SegmentSum&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SegmentSum</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SegmentSum&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">segment_sum</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">segment_sum_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">segment_ids</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">segment_ids</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SegmentSum&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SegmentSum&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">select</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Selects elements from `x` or `y`, depending on `condition`.</span>

<span class="sd">  The `x`, and `y` tensors must all have the same shape, and the</span>
<span class="sd">  output will also have that shape.</span>

<span class="sd">  The `condition` tensor must be a scalar if `x` and `y` are scalars.</span>
<span class="sd">  If `x` and `y` are vectors or higher rank, then `condition` must be either a</span>
<span class="sd">  scalar, a vector with size matching the first dimension of `x`, or must have</span>
<span class="sd">  the same shape as `x`.</span>

<span class="sd">  The `condition` tensor acts as a mask that chooses, based on the value at each</span>
<span class="sd">  element, whether the corresponding element / row in the output should be</span>
<span class="sd">  taken from `x` (if true) or `y` (if false).</span>

<span class="sd">  If `condition` is a vector and `x` and `y` are higher rank matrices, then</span>
<span class="sd">  it chooses which row (outer dimension) to copy from `x` and `y`.</span>
<span class="sd">  If `condition` has the same shape as `x` and `y`, then it chooses which</span>
<span class="sd">  element to copy from `x` and `y`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```python</span>
<span class="sd">  # &#39;condition&#39; tensor is [[True,  False]</span>
<span class="sd">  #                        [False, True]]</span>
<span class="sd">  # &#39;t&#39; is [[1, 2],</span>
<span class="sd">  #         [3, 4]]</span>
<span class="sd">  # &#39;e&#39; is [[5, 6],</span>
<span class="sd">  #         [7, 8]]</span>
<span class="sd">  select(condition, t, e)  # =&gt; [[1, 6], [7, 4]]</span>


<span class="sd">  # &#39;condition&#39; tensor is [True, False]</span>
<span class="sd">  # &#39;t&#39; is [[1, 2],</span>
<span class="sd">  #         [3, 4]]</span>
<span class="sd">  # &#39;e&#39; is [[5, 6],</span>
<span class="sd">  #         [7, 8]]</span>
<span class="sd">  select(condition, t, e) ==&gt; [[1, 2],</span>
<span class="sd">                               [7, 8]]</span>

<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    condition: A `Tensor` of type `bool`.</span>
<span class="sd">    x:  A `Tensor` which may have the same shape as `condition`.</span>
<span class="sd">      If `condition` is rank 1, `x` may have higher rank,</span>
<span class="sd">      but its first dimension must match the size of `condition`.</span>
<span class="sd">    y:  A `Tensor` with the same type and shape as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `t`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Select&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">condition</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">select_eager_fallback</span><span class="p">(</span>
            <span class="n">condition</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Select&quot;</span><span class="p">,</span> <span class="n">condition</span><span class="o">=</span><span class="n">condition</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">e</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Select&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Select</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Select&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">select</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">select_eager_fallback</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">condition</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">condition</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Select&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Select&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">select_v2</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;TODO: add doc.</span>

<span class="sd">  Args:</span>
<span class="sd">    condition: A `Tensor` of type `bool`.</span>
<span class="sd">    t: A `Tensor`.</span>
<span class="sd">    e: A `Tensor`. Must have the same type as `t`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `t`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SelectV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">condition</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">select_v2_eager_fallback</span><span class="p">(</span>
            <span class="n">condition</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SelectV2&quot;</span><span class="p">,</span> <span class="n">condition</span><span class="o">=</span><span class="n">condition</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">,</span> <span class="n">e</span><span class="o">=</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SelectV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SelectV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SelectV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">select_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">select_v2_eager_fallback</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">t</span><span class="p">,</span> <span class="n">e</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">condition</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">condition</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">e</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SelectV2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SelectV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes sigmoid of `x` element-wise.</span>

<span class="sd">  Specifically, `y = 1 / (1 + exp(-x))`.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Sigmoid&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sigmoid_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Sigmoid&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Sigmoid&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Sigmoid</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Sigmoid&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sigmoid_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Sigmoid&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Sigmoid&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sigmoid_grad</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the gradient of the sigmoid of `x` wrt its input.</span>

<span class="sd">  Specifically, `grad = dy * y * (1 - y)`, where `y = sigmoid(x)`, and</span>
<span class="sd">  `dy` is the corresponding input gradient.</span>

<span class="sd">  Args:</span>
<span class="sd">    y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    dy: A `Tensor`. Must have the same type as `y`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `y`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SigmoidGrad&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sigmoid_grad_eager_fallback</span><span class="p">(</span>
            <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SigmoidGrad&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SigmoidGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SigmoidGrad</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SigmoidGrad&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sigmoid_grad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sigmoid_grad_eager_fallback</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SigmoidGrad&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SigmoidGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sign</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns an element-wise indication of the sign of a number.</span>

<span class="sd">  `y = sign(x) = -1` if `x &lt; 0`; 0 if `x == 0`; 1 if `x &gt; 0`.</span>

<span class="sd">  For complex numbers, `y = sign(x) = x / |x|` if `x != 0`, otherwise `y = 0`.</span>

<span class="sd">  Example usage:</span>
<span class="sd">  &gt;&gt;&gt; tf.math.sign([0., 2., -3.])</span>
<span class="sd">  &lt;tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 0.,  1., -1.], dtype=float32)&gt;</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Sign&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sign_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Sign&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Sign&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Sign</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Sign&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sign</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sign_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Sign&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Sign&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="sin"><a class="viewcode-back" href="../../../../index.html#tensorflow.sin">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.sin&#39;</span><span class="p">,</span> <span class="s1">&#39;sin&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">sin</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes sine of x element-wise.</span>

<span class="sd">    Given an input tensor, this function computes sine of every</span>
<span class="sd">    element in the tensor. Input range is `(-inf, inf)` and</span>
<span class="sd">    output range is `[-1,1]`.</span>

<span class="sd">    ```python</span>
<span class="sd">    x = tf.constant([-float(&quot;inf&quot;), -9, -0.5, 1, 1.2, 200, 10, float(&quot;inf&quot;)])</span>
<span class="sd">    tf.math.sin(x) ==&gt; [nan -0.4121185 -0.47942555 0.84147096 0.9320391 -0.87329733 -0.54402107 nan]</span>
<span class="sd">    ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Sin&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sin_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">sin</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Sin&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">sin</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Sin&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Sin</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Sin&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sin</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sin_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Sin&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Sin&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="sinh"><a class="viewcode-back" href="../../../../index.html#tensorflow.sinh">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.sinh&#39;</span><span class="p">,</span> <span class="s1">&#39;sinh&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">sinh</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes hyperbolic sine of x element-wise.</span>

<span class="sd">    Given an input tensor, this function computes hyperbolic sine of every</span>
<span class="sd">    element in the tensor. Input range is `[-inf,inf]` and output range</span>
<span class="sd">    is `[-inf,inf]`.</span>

<span class="sd">    ```python</span>
<span class="sd">    x = tf.constant([-float(&quot;inf&quot;), -9, -0.5, 1, 1.2, 2, 10, float(&quot;inf&quot;)])</span>
<span class="sd">    tf.math.sinh(x) ==&gt; [-inf -4.0515420e+03 -5.2109528e-01 1.1752012e+00 1.5094614e+00 3.6268604e+00 1.1013232e+04 inf]</span>
<span class="sd">    ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Sinh&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sinh_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">sinh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Sinh&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">sinh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Sinh&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Sinh</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Sinh&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sinh</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sinh_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Sinh&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Sinh&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sobol_sample</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">num_results</span><span class="p">,</span> <span class="n">skip</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Generates points from the Sobol sequence.</span>

<span class="sd">  Creates a Sobol sequence with `num_results` samples. Each sample has dimension</span>
<span class="sd">  `dim`. Skips the first `skip` samples.</span>

<span class="sd">  Args:</span>
<span class="sd">    dim: A `Tensor` of type `int32`.</span>
<span class="sd">      Positive scalar `Tensor` representing each sample&#39;s dimension.</span>
<span class="sd">    num_results: A `Tensor` of type `int32`.</span>
<span class="sd">      Positive scalar `Tensor` of dtype int32. The number of Sobol points to return</span>
<span class="sd">      in the output.</span>
<span class="sd">    skip: A `Tensor` of type `int32`.</span>
<span class="sd">      Positive scalar `Tensor` of dtype int32. The number of initial points of the</span>
<span class="sd">      Sobol sequence to skip.</span>
<span class="sd">    dtype: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.</span>
<span class="sd">      The type of the sample. One of: `float32` or `float64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `dtype`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SobolSample&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">num_results</span><span class="p">,</span> <span class="n">skip</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sobol_sample_eager_fallback</span><span class="p">(</span>
            <span class="n">dim</span><span class="p">,</span> <span class="n">num_results</span><span class="p">,</span> <span class="n">skip</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SobolSample&quot;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">num_results</span><span class="o">=</span><span class="n">num_results</span><span class="p">,</span> <span class="n">skip</span><span class="o">=</span><span class="n">skip</span><span class="p">,</span>
                       <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SobolSample&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SobolSample</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SobolSample&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sobol_sample</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sobol_sample_eager_fallback</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">num_results</span><span class="p">,</span> <span class="n">skip</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="n">dim</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">num_results</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">num_results</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">skip</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">skip</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">dim</span><span class="p">,</span> <span class="n">num_results</span><span class="p">,</span> <span class="n">skip</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SobolSample&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SobolSample&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sparse_mat_mul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">a_is_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">b_is_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Multiply matrix &quot;a&quot; by matrix &quot;b&quot;.</span>

<span class="sd">  The inputs must be two-dimensional matrices and the inner dimension of &quot;a&quot; must</span>
<span class="sd">  match the outer dimension of &quot;b&quot;. Both &quot;a&quot; and &quot;b&quot; must be `Tensor`s not</span>
<span class="sd">  `SparseTensor`s.  This op is optimized for the case where at least one of &quot;a&quot; or</span>
<span class="sd">  &quot;b&quot; is sparse, in the sense that they have a large proportion of zero values.</span>
<span class="sd">  The breakeven for using this versus a dense matrix multiply on one platform was</span>
<span class="sd">  30% zero values in the sparse matrix.</span>

<span class="sd">  The gradient computation of this operation will only take advantage of sparsity</span>
<span class="sd">  in the input gradient when that gradient comes from a Relu.</span>

<span class="sd">  Args:</span>
<span class="sd">    a: A `Tensor`. Must be one of the following types: `float32`, `bfloat16`.</span>
<span class="sd">    b: A `Tensor`. Must be one of the following types: `float32`, `bfloat16`.</span>
<span class="sd">    transpose_a: An optional `bool`. Defaults to `False`.</span>
<span class="sd">    transpose_b: An optional `bool`. Defaults to `False`.</span>
<span class="sd">    a_is_sparse: An optional `bool`. Defaults to `False`.</span>
<span class="sd">    b_is_sparse: An optional `bool`. Defaults to `False`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SparseMatMul&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="s2">&quot;transpose_a&quot;</span><span class="p">,</span> <span class="n">transpose_a</span><span class="p">,</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">,</span>
        <span class="n">transpose_b</span><span class="p">,</span> <span class="s2">&quot;a_is_sparse&quot;</span><span class="p">,</span> <span class="n">a_is_sparse</span><span class="p">,</span> <span class="s2">&quot;b_is_sparse&quot;</span><span class="p">,</span> <span class="n">b_is_sparse</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sparse_mat_mul_eager_fallback</span><span class="p">(</span>
            <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="n">transpose_a</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="n">transpose_b</span><span class="p">,</span>
            <span class="n">a_is_sparse</span><span class="o">=</span><span class="n">a_is_sparse</span><span class="p">,</span> <span class="n">b_is_sparse</span><span class="o">=</span><span class="n">b_is_sparse</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">transpose_a</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">transpose_a</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">transpose_a</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">transpose_a</span><span class="p">,</span> <span class="s2">&quot;transpose_a&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">transpose_b</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">transpose_b</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">transpose_b</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">transpose_b</span><span class="p">,</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">a_is_sparse</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">a_is_sparse</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">a_is_sparse</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">a_is_sparse</span><span class="p">,</span> <span class="s2">&quot;a_is_sparse&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">b_is_sparse</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">b_is_sparse</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">b_is_sparse</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">b_is_sparse</span><span class="p">,</span> <span class="s2">&quot;b_is_sparse&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SparseMatMul&quot;</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="n">transpose_a</span><span class="p">,</span>
                        <span class="n">transpose_b</span><span class="o">=</span><span class="n">transpose_b</span><span class="p">,</span> <span class="n">a_is_sparse</span><span class="o">=</span><span class="n">a_is_sparse</span><span class="p">,</span>
                        <span class="n">b_is_sparse</span><span class="o">=</span><span class="n">b_is_sparse</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;transpose_a&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;transpose_a&quot;</span><span class="p">),</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;transpose_b&quot;</span><span class="p">),</span> <span class="s2">&quot;a_is_sparse&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;a_is_sparse&quot;</span><span class="p">),</span> <span class="s2">&quot;b_is_sparse&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;b_is_sparse&quot;</span><span class="p">),</span> <span class="s2">&quot;Ta&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Ta&quot;</span><span class="p">),</span> <span class="s2">&quot;Tb&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tb&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseMatMul&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SparseMatMul</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SparseMatMul&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sparse_mat_mul</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sparse_mat_mul_eager_fallback</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">transpose_a</span><span class="p">,</span> <span class="n">transpose_b</span><span class="p">,</span> <span class="n">a_is_sparse</span><span class="p">,</span> <span class="n">b_is_sparse</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">transpose_a</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">transpose_a</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">transpose_a</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">transpose_a</span><span class="p">,</span> <span class="s2">&quot;transpose_a&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">transpose_b</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">transpose_b</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">transpose_b</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">transpose_b</span><span class="p">,</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">a_is_sparse</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">a_is_sparse</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">a_is_sparse</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">a_is_sparse</span><span class="p">,</span> <span class="s2">&quot;a_is_sparse&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">b_is_sparse</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">b_is_sparse</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">b_is_sparse</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">b_is_sparse</span><span class="p">,</span> <span class="s2">&quot;b_is_sparse&quot;</span><span class="p">)</span>
  <span class="n">_attr_Ta</span><span class="p">,</span> <span class="p">(</span><span class="n">a</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">a</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_attr_Tb</span><span class="p">,</span> <span class="p">(</span><span class="n">b</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">b</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;transpose_a&quot;</span><span class="p">,</span> <span class="n">transpose_a</span><span class="p">,</span> <span class="s2">&quot;transpose_b&quot;</span><span class="p">,</span> <span class="n">transpose_b</span><span class="p">,</span>
  <span class="s2">&quot;a_is_sparse&quot;</span><span class="p">,</span> <span class="n">a_is_sparse</span><span class="p">,</span> <span class="s2">&quot;b_is_sparse&quot;</span><span class="p">,</span> <span class="n">b_is_sparse</span><span class="p">,</span> <span class="s2">&quot;Ta&quot;</span><span class="p">,</span> <span class="n">_attr_Ta</span><span class="p">,</span>
  <span class="s2">&quot;Tb&quot;</span><span class="p">,</span> <span class="n">_attr_Tb</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SparseMatMul&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseMatMul&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sparse_segment_mean</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the mean along sparse segments of a tensor.</span>

<span class="sd">  See `tf.sparse.segment_sum` for usage examples.</span>

<span class="sd">  Like `SegmentMean`, but `segment_ids` can have rank less than `data`&#39;s first</span>
<span class="sd">  dimension, selecting a subset of dimension 0, specified by `indices`.</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A 1-D tensor. Has same rank as `segment_ids`.</span>
<span class="sd">    segment_ids: A `Tensor` of type `int32`.</span>
<span class="sd">      A 1-D tensor. Values should be sorted and can be repeated.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SparseSegmentMean&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sparse_segment_mean_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentMean&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                             <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentMean&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SparseSegmentMean</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SparseSegmentMean&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sparse_segment_mean</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sparse_segment_mean_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SparseSegmentMean&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentMean&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sparse_segment_mean_grad</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">output_dim0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes gradients for SparseSegmentMean.</span>

<span class="sd">  Returns tensor &quot;output&quot; with same shape as grad, except for dimension 0 whose</span>
<span class="sd">  value is output_dim0.</span>

<span class="sd">  Args:</span>
<span class="sd">    grad: A `Tensor`. Must be one of the following types: `float32`, `float64`.</span>
<span class="sd">      gradient propagated to the SparseSegmentMean op.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      indices passed to the corresponding SparseSegmentMean op.</span>
<span class="sd">    segment_ids: A `Tensor` of type `int32`.</span>
<span class="sd">      segment_ids passed to the corresponding SparseSegmentMean op.</span>
<span class="sd">    output_dim0: A `Tensor` of type `int32`.</span>
<span class="sd">      dimension 0 of &quot;data&quot; passed to SparseSegmentMean op.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `grad`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SparseSegmentMeanGrad&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">output_dim0</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sparse_segment_mean_grad_eager_fallback</span><span class="p">(</span>
            <span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">output_dim0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentMeanGrad&quot;</span><span class="p">,</span> <span class="n">grad</span><span class="o">=</span><span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                                 <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                                 <span class="n">output_dim0</span><span class="o">=</span><span class="n">output_dim0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentMeanGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SparseSegmentMeanGrad</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SparseSegmentMeanGrad&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sparse_segment_mean_grad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sparse_segment_mean_grad_eager_fallback</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">output_dim0</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">grad</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">grad</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">output_dim0</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">output_dim0</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">output_dim0</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SparseSegmentMeanGrad&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentMeanGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sparse_segment_mean_with_num_segments</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the mean along sparse segments of a tensor.</span>

<span class="sd">  Like `SparseSegmentMean`, but allows missing ids in `segment_ids`. If an id is</span>
<span class="sd">  misisng, the `output` tensor at that position will be zeroed.</span>

<span class="sd">  Read</span>
<span class="sd">  [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)</span>
<span class="sd">  for an explanation of segments.</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A 1-D tensor. Has same rank as `segment_ids`.</span>
<span class="sd">    segment_ids: A `Tensor` of type `int32`.</span>
<span class="sd">      A 1-D tensor. Values should be sorted and can be repeated.</span>
<span class="sd">    num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      Should equal the number of distinct segment IDs.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span>
        <span class="s2">&quot;SparseSegmentMeanWithNumSegments&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sparse_segment_mean_with_num_segments_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentMeanWithNumSegments&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                                            <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                                            <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span>
                                            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">),</span> <span class="s2">&quot;Tnumsegments&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tnumsegments&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentMeanWithNumSegments&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SparseSegmentMeanWithNumSegments</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SparseSegmentMeanWithNumSegments&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sparse_segment_mean_with_num_segments</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sparse_segment_mean_with_num_segments_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_attr_Tnumsegments</span><span class="p">,</span> <span class="p">(</span><span class="n">num_segments</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">num_segments</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="s2">&quot;Tnumsegments&quot;</span><span class="p">,</span>
  <span class="n">_attr_Tnumsegments</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SparseSegmentMeanWithNumSegments&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentMeanWithNumSegments&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sparse_segment_sqrt_n</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the sum along sparse segments of a tensor divided by the sqrt of N.</span>

<span class="sd">  N is the size of the segment being reduced.</span>

<span class="sd">  See `tf.sparse.segment_sum` for usage examples.</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A 1-D tensor. Has same rank as `segment_ids`.</span>
<span class="sd">    segment_ids: A `Tensor` of type `int32`.</span>
<span class="sd">      A 1-D tensor. Values should be sorted and can be repeated.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SparseSegmentSqrtN&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sparse_segment_sqrt_n_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSqrtN&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                              <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSqrtN&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SparseSegmentSqrtN</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SparseSegmentSqrtN&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sparse_segment_sqrt_n</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sparse_segment_sqrt_n_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SparseSegmentSqrtN&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSqrtN&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sparse_segment_sqrt_n_grad</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">output_dim0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes gradients for SparseSegmentSqrtN.</span>

<span class="sd">  Returns tensor &quot;output&quot; with same shape as grad, except for dimension 0 whose</span>
<span class="sd">  value is output_dim0.</span>

<span class="sd">  Args:</span>
<span class="sd">    grad: A `Tensor`. Must be one of the following types: `float32`, `float64`.</span>
<span class="sd">      gradient propagated to the SparseSegmentSqrtN op.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      indices passed to the corresponding SparseSegmentSqrtN op.</span>
<span class="sd">    segment_ids: A `Tensor` of type `int32`.</span>
<span class="sd">      segment_ids passed to the corresponding SparseSegmentSqrtN op.</span>
<span class="sd">    output_dim0: A `Tensor` of type `int32`.</span>
<span class="sd">      dimension 0 of &quot;data&quot; passed to SparseSegmentSqrtN op.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `grad`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SparseSegmentSqrtNGrad&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">output_dim0</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sparse_segment_sqrt_n_grad_eager_fallback</span><span class="p">(</span>
            <span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">output_dim0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSqrtNGrad&quot;</span><span class="p">,</span> <span class="n">grad</span><span class="o">=</span><span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                                  <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                                  <span class="n">output_dim0</span><span class="o">=</span><span class="n">output_dim0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSqrtNGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SparseSegmentSqrtNGrad</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SparseSegmentSqrtNGrad&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sparse_segment_sqrt_n_grad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sparse_segment_sqrt_n_grad_eager_fallback</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">output_dim0</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">grad</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">grad</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">output_dim0</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">output_dim0</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">grad</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">output_dim0</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SparseSegmentSqrtNGrad&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSqrtNGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sparse_segment_sqrt_n_with_num_segments</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the sum along sparse segments of a tensor divided by the sqrt of N.</span>

<span class="sd">  N is the size of the segment being reduced.</span>

<span class="sd">  Like `SparseSegmentSqrtN`, but allows missing ids in `segment_ids`. If an id is</span>
<span class="sd">  misisng, the `output` tensor at that position will be zeroed.</span>

<span class="sd">  Read</span>
<span class="sd">  [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)</span>
<span class="sd">  for an explanation of segments.</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A 1-D tensor. Has same rank as `segment_ids`.</span>
<span class="sd">    segment_ids: A `Tensor` of type `int32`.</span>
<span class="sd">      A 1-D tensor. Values should be sorted and can be repeated.</span>
<span class="sd">    num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      Should equal the number of distinct segment IDs.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span>
        <span class="s2">&quot;SparseSegmentSqrtNWithNumSegments&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sparse_segment_sqrt_n_with_num_segments_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSqrtNWithNumSegments&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                                             <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                                             <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span>
                                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">),</span> <span class="s2">&quot;Tnumsegments&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tnumsegments&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSqrtNWithNumSegments&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SparseSegmentSqrtNWithNumSegments</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SparseSegmentSqrtNWithNumSegments&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sparse_segment_sqrt_n_with_num_segments</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sparse_segment_sqrt_n_with_num_segments_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_attr_Tnumsegments</span><span class="p">,</span> <span class="p">(</span><span class="n">num_segments</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">num_segments</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="s2">&quot;Tnumsegments&quot;</span><span class="p">,</span>
  <span class="n">_attr_Tnumsegments</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SparseSegmentSqrtNWithNumSegments&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSqrtNWithNumSegments&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sparse_segment_sum</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the sum along sparse segments of a tensor.</span>

<span class="sd">  Read</span>
<span class="sd">  [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)</span>
<span class="sd">  for an explanation of segments.</span>

<span class="sd">  Like `SegmentSum`, but `segment_ids` can have rank less than `data`&#39;s first</span>
<span class="sd">  dimension, selecting a subset of dimension 0, specified by `indices`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```python</span>
<span class="sd">  c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])</span>

<span class="sd">  # Select two rows, one segment.</span>
<span class="sd">  tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 0]))</span>
<span class="sd">  # =&gt; [[0 0 0 0]]</span>

<span class="sd">  # Select two rows, two segment.</span>
<span class="sd">  tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 1]))</span>
<span class="sd">  # =&gt; [[ 1  2  3  4]</span>
<span class="sd">  #     [-1 -2 -3 -4]]</span>

<span class="sd">  # Select all rows, two segments.</span>
<span class="sd">  tf.sparse_segment_sum(c, tf.constant([0, 1, 2]), tf.constant([0, 0, 1]))</span>
<span class="sd">  # =&gt; [[0 0 0 0]</span>
<span class="sd">  #     [5 6 7 8]]</span>

<span class="sd">  # Which is equivalent to:</span>
<span class="sd">  tf.segment_sum(c, tf.constant([0, 0, 1]))</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A 1-D tensor. Has same rank as `segment_ids`.</span>
<span class="sd">    segment_ids: A `Tensor` of type `int32`.</span>
<span class="sd">      A 1-D tensor. Values should be sorted and can be repeated.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SparseSegmentSum&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sparse_segment_sum_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSum&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                            <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSum&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SparseSegmentSum</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SparseSegmentSum&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sparse_segment_sum</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sparse_segment_sum_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SparseSegmentSum&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSum&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sparse_segment_sum_with_num_segments</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the sum along sparse segments of a tensor.</span>

<span class="sd">  Like `SparseSegmentSum`, but allows missing ids in `segment_ids`. If an id is</span>
<span class="sd">  misisng, the `output` tensor at that position will be zeroed.</span>

<span class="sd">  Read</span>
<span class="sd">  [the section on segmentation](https://tensorflow.org/api_docs/python/tf/sparse#Segmentation)</span>
<span class="sd">  for an explanation of segments.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```python</span>
<span class="sd">  c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])</span>

<span class="sd">  tf.sparse_segment_sum_with_num_segments(</span>
<span class="sd">      c, tf.constant([0, 1]), tf.constant([0, 0]), num_segments=3)</span>
<span class="sd">  # =&gt; [[0 0 0 0]</span>
<span class="sd">  #     [0 0 0 0]</span>
<span class="sd">  #     [0 0 0 0]]</span>

<span class="sd">  tf.sparse_segment_sum_with_num_segments(c,</span>
<span class="sd">                                          tf.constant([0, 1]),</span>
<span class="sd">                                          tf.constant([0, 2],</span>
<span class="sd">                                          num_segments=4))</span>
<span class="sd">  # =&gt; [[ 1  2  3  4]</span>
<span class="sd">  #     [ 0  0  0  0]</span>
<span class="sd">  #     [-1 -2 -3 -4]</span>
<span class="sd">  #     [ 0  0  0  0]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A 1-D tensor. Has same rank as `segment_ids`.</span>
<span class="sd">    segment_ids: A `Tensor` of type `int32`.</span>
<span class="sd">      A 1-D tensor. Values should be sorted and can be repeated.</span>
<span class="sd">    num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      Should equal the number of distinct segment IDs.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span>
        <span class="s2">&quot;SparseSegmentSumWithNumSegments&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span>
        <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sparse_segment_sum_with_num_segments_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSumWithNumSegments&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                                           <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                                           <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span>
                                           <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">),</span> <span class="s2">&quot;Tnumsegments&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tnumsegments&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSumWithNumSegments&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SparseSegmentSumWithNumSegments</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SparseSegmentSumWithNumSegments&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sparse_segment_sum_with_num_segments</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sparse_segment_sum_with_num_segments_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_attr_Tnumsegments</span><span class="p">,</span> <span class="p">(</span><span class="n">num_segments</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">num_segments</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">segment_ids</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="s2">&quot;Tnumsegments&quot;</span><span class="p">,</span>
  <span class="n">_attr_Tnumsegments</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SparseSegmentSumWithNumSegments&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SparseSegmentSumWithNumSegments&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes square root of x element-wise.</span>

<span class="sd">  I.e., \\(y = \sqrt{x} = x^{1/2}\\).</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Sqrt&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sqrt_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Sqrt&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Sqrt&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Sqrt</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Sqrt&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sqrt</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sqrt_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Sqrt&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Sqrt&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sqrt_grad</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the gradient for the sqrt of `x` wrt its input.</span>

<span class="sd">  Specifically, `grad = dy * 0.5 / y`, where `y = sqrt(x)`, and `dy`</span>
<span class="sd">  is the corresponding input gradient.</span>

<span class="sd">  Args:</span>
<span class="sd">    y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    dy: A `Tensor`. Must have the same type as `y`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `y`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SqrtGrad&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sqrt_grad_eager_fallback</span><span class="p">(</span>
            <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SqrtGrad&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SqrtGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SqrtGrad</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SqrtGrad&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sqrt_grad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sqrt_grad_eager_fallback</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SqrtGrad&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SqrtGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="square"><a class="viewcode-back" href="../../../../index.html#tensorflow.square">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.square&#39;</span><span class="p">,</span> <span class="s1">&#39;square&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">square</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes square of x element-wise.</span>

<span class="sd">  I.e., \\(y = x * x = x^2\\).</span>

<span class="sd">  &gt;&gt;&gt; tf.math.square([-2., 0., 3.])</span>
<span class="sd">  &lt;tf.Tensor: shape=(3,), dtype=float32, numpy=array([4., 0., 9.], dtype=float32)&gt;</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Square&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">square_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">square</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Square&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">square</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Square&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Square</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Square&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">square</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">square_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Square&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Square&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.squared_difference&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.squared_difference&#39;</span><span class="p">,</span> <span class="s1">&#39;squared_difference&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;squared_difference&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">squared_difference</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns (x - y)(x - y) element-wise.</span>

<span class="sd">  *NOTE*: `math.squared_difference` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SquaredDifference&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">squared_difference_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">squared_difference</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SquaredDifference&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">squared_difference</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SquaredDifference&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SquaredDifference</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SquaredDifference&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">squared_difference</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">squared_difference_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SquaredDifference&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SquaredDifference&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns x - y element-wise.</span>

<span class="sd">  *NOTE*: `Subtract` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Sub&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sub_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Sub&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Sub&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Sub</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Sub&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">sub</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">sub_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Sub&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Sub&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">_sum</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the sum of elements across dimensions of a tensor.</span>

<span class="sd">  Reduces `input` along the dimensions given in `axis`. Unless</span>
<span class="sd">  `keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in</span>
<span class="sd">  `axis`. If `keep_dims` is true, the reduced dimensions are</span>
<span class="sd">  retained with length 1.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">      The tensor to reduce.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      The dimensions to reduce. Must be in the range</span>
<span class="sd">      `[-rank(input), rank(input))`.</span>
<span class="sd">    keep_dims: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If true, retain reduced dimensions with length 1.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Sum&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_sum_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Sum&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="n">keep_dims</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Sum&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Sum</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Sum&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">_sum</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_sum_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">keep_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">keep_dims</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">keep_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;keep_dims&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;keep_dims&quot;</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Sum&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Sum&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="tan"><a class="viewcode-back" href="../../../../index.html#tensorflow.tan">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.tan&#39;</span><span class="p">,</span> <span class="s1">&#39;tan&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">tan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes tan of x element-wise.</span>

<span class="sd">    Given an input tensor, this function computes tangent of every</span>
<span class="sd">    element in the tensor. Input range is `(-inf, inf)` and</span>
<span class="sd">    output range is `(-inf, inf)`. If input lies outside the boundary, `nan`</span>
<span class="sd">    is returned.</span>

<span class="sd">    ```python</span>
<span class="sd">    x = tf.constant([-float(&quot;inf&quot;), -9, -0.5, 1, 1.2, 200, 10000, float(&quot;inf&quot;)])</span>
<span class="sd">    tf.math.tan(x) ==&gt; [nan 0.45231566 -0.5463025 1.5574077 2.572152 -1.7925274 0.32097113 nan]</span>
<span class="sd">    ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Tan&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tan_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">tan</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Tan&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">tan</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Tan&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Tan</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Tan&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">tan</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">tan_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Tan&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Tan&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="tanh"><a class="viewcode-back" href="../../../../index.html#tensorflow.tanh">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.tanh&#39;</span><span class="p">,</span> <span class="s1">&#39;nn.tanh&#39;</span><span class="p">,</span> <span class="s1">&#39;tanh&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes hyperbolic tangent of `x` element-wise.</span>

<span class="sd">    Given an input tensor, this function computes hyperbolic tangent of every</span>
<span class="sd">    element in the tensor. Input range is `[-inf, inf]` and</span>
<span class="sd">    output range is `[-1,1]`.</span>

<span class="sd">    ```python</span>
<span class="sd">    x = tf.constant([-float(&quot;inf&quot;), -5, -0.5, 1, 1.2, 2, 3, float(&quot;inf&quot;)])</span>
<span class="sd">    tf.math.tanh(x) ==&gt; [-1. -0.99990916 -0.46211717 0.7615942 0.8336547 0.9640276 0.9950547 1.]</span>
<span class="sd">    ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Tanh&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tanh_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">tanh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Tanh&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">tanh</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Tanh&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Tanh</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Tanh&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">tanh</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">tanh_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Tanh&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Tanh&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">tanh_grad</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the gradient for the tanh of `x` wrt its input.</span>

<span class="sd">  Specifically, `grad = dy * (1 - y*y)`, where `y = tanh(x)`, and `dy`</span>
<span class="sd">  is the corresponding input gradient.</span>

<span class="sd">  Args:</span>
<span class="sd">    y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    dy: A `Tensor`. Must have the same type as `y`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `y`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;TanhGrad&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tanh_grad_eager_fallback</span><span class="p">(</span>
            <span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;TanhGrad&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TanhGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">TanhGrad</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.TanhGrad&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">tanh_grad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">tanh_grad_eager_fallback</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">,</span> <span class="n">dy</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;TanhGrad&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TanhGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;truncatediv&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">truncate_div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns x / y element-wise for integer types.</span>

<span class="sd">  Truncation designates that negative numbers will round fractional quantities</span>
<span class="sd">  toward zero. I.e. -7 / 5 = -1. This matches C semantics but it is different</span>
<span class="sd">  than Python semantics. See `FloorDiv` for a division function that matches</span>
<span class="sd">  Python Semantics.</span>

<span class="sd">  *NOTE*: `truncatediv` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;TruncateDiv&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">truncate_div_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">truncate_div</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;TruncateDiv&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">truncate_div</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TruncateDiv&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">TruncateDiv</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.TruncateDiv&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">truncate_div</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">truncate_div_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;TruncateDiv&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TruncateDiv&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;truncatemod&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">truncate_mod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns element-wise remainder of division. This emulates C semantics in that</span>

<span class="sd">  the result here is consistent with a truncating divide. E.g. `truncate(x / y) *</span>
<span class="sd">  y + truncate_mod(x, y) = x`.</span>

<span class="sd">  *NOTE*: `truncatemod` supports broadcasting. More about broadcasting</span>
<span class="sd">  [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;TruncateMod&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">truncate_mod_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">truncate_mod</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;TruncateMod&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">truncate_mod</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TruncateMod&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">TruncateMod</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.TruncateMod&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">truncate_mod</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">truncate_mod_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;TruncateMod&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TruncateMod&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.unsorted_segment_max&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.unsorted_segment_max&#39;</span><span class="p">,</span> <span class="s1">&#39;unsorted_segment_max&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;unsorted_segment_max&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">unsorted_segment_max</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the maximum along segments of a tensor.</span>

<span class="sd">  Read</span>
<span class="sd">  [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)</span>
<span class="sd">  for an explanation of segments.</span>

<span class="sd">  This operator is similar to the unsorted segment sum operator found</span>
<span class="sd">  [(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).</span>
<span class="sd">  Instead of computing the sum over segments, it computes the maximum such that:</span>

<span class="sd">  \\(output_i = \max_{j...} data[j...]\\) where max is over tuples `j...` such</span>
<span class="sd">  that `segment_ids[j...] == i`.</span>

<span class="sd">  If the maximum is empty for a given segment ID `i`, it outputs the smallest</span>
<span class="sd">  possible value for the specific numeric type,</span>
<span class="sd">  `output[i] = numeric_limits&lt;T&gt;::lowest()`.</span>

<span class="sd">  If the given segment ID `i` is negative, then the corresponding value is</span>
<span class="sd">  dropped, and will not be included in the result.</span>

<span class="sd">  &lt;div style=&quot;width:70%; margin:auto; margin-bottom:10px; margin-top:20px;&quot;&gt;</span>
<span class="sd">  &lt;img style=&quot;width:100%&quot; src=&quot;https://www.tensorflow.org/images/UnsortedSegmentMax.png&quot; alt&gt;</span>
<span class="sd">  &lt;/div&gt;</span>

<span class="sd">  For example:</span>

<span class="sd">  ``` python</span>
<span class="sd">  c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])</span>
<span class="sd">  tf.unsorted_segment_max(c, tf.constant([0, 1, 0]), num_segments=2)</span>
<span class="sd">  # ==&gt; [[ 4,  3, 3, 4],</span>
<span class="sd">  #       [5,  6, 7, 8]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A tensor whose shape is a prefix of `data.shape`.</span>
<span class="sd">    num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;UnsortedSegmentMax&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">unsorted_segment_max_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">unsorted_segment_max</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                                    <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;UnsortedSegmentMax&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                              <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">unsorted_segment_max</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                                <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">),</span> <span class="s2">&quot;Tnumsegments&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tnumsegments&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UnsortedSegmentMax&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">UnsortedSegmentMax</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.UnsortedSegmentMax&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">unsorted_segment_max</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">unsorted_segment_max_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">segment_ids</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">segment_ids</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tnumsegments</span><span class="p">,</span> <span class="p">(</span><span class="n">num_segments</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">num_segments</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="s2">&quot;Tnumsegments&quot;</span><span class="p">,</span>
  <span class="n">_attr_Tnumsegments</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;UnsortedSegmentMax&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UnsortedSegmentMax&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.unsorted_segment_min&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.unsorted_segment_min&#39;</span><span class="p">,</span> <span class="s1">&#39;unsorted_segment_min&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;unsorted_segment_min&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">unsorted_segment_min</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the minimum along segments of a tensor.</span>

<span class="sd">  Read</span>
<span class="sd">  [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)</span>
<span class="sd">  for an explanation of segments.</span>

<span class="sd">  This operator is similar to the unsorted segment sum operator found</span>
<span class="sd">  [(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).</span>
<span class="sd">  Instead of computing the sum over segments, it computes the minimum such that:</span>

<span class="sd">  \\(output_i = \min_{j...} data_[j...]\\) where min is over tuples `j...` such</span>
<span class="sd">  that `segment_ids[j...] == i`.</span>

<span class="sd">  If the minimum is empty for a given segment ID `i`, it outputs the largest</span>
<span class="sd">  possible value for the specific numeric type,</span>
<span class="sd">  `output[i] = numeric_limits&lt;T&gt;::max()`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ``` python</span>
<span class="sd">  c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])</span>
<span class="sd">  tf.unsorted_segment_min(c, tf.constant([0, 1, 0]), num_segments=2)</span>
<span class="sd">  # ==&gt; [[ 1,  2, 2, 1],</span>
<span class="sd">  #       [5,  6, 7, 8]]</span>
<span class="sd">  ```</span>

<span class="sd">  If the given segment ID `i` is negative, then the corresponding value is</span>
<span class="sd">  dropped, and will not be included in the result.</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A tensor whose shape is a prefix of `data.shape`.</span>
<span class="sd">    num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;UnsortedSegmentMin&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">unsorted_segment_min_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">unsorted_segment_min</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                                    <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;UnsortedSegmentMin&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                              <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">unsorted_segment_min</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                                <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">),</span> <span class="s2">&quot;Tnumsegments&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tnumsegments&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UnsortedSegmentMin&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">UnsortedSegmentMin</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.UnsortedSegmentMin&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">unsorted_segment_min</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">unsorted_segment_min_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">segment_ids</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">segment_ids</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tnumsegments</span><span class="p">,</span> <span class="p">(</span><span class="n">num_segments</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">num_segments</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="s2">&quot;Tnumsegments&quot;</span><span class="p">,</span>
  <span class="n">_attr_Tnumsegments</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;UnsortedSegmentMin&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UnsortedSegmentMin&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.unsorted_segment_prod&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.unsorted_segment_prod&#39;</span><span class="p">,</span> <span class="s1">&#39;unsorted_segment_prod&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;unsorted_segment_prod&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">unsorted_segment_prod</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the product along segments of a tensor.</span>

<span class="sd">  Read</span>
<span class="sd">  [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)</span>
<span class="sd">  for an explanation of segments.</span>

<span class="sd">  This operator is similar to the unsorted segment sum operator found</span>
<span class="sd">  [(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).</span>
<span class="sd">  Instead of computing the sum over segments, it computes the product of all</span>
<span class="sd">  entries belonging to a segment such that:</span>

<span class="sd">  \\(output_i = \prod_{j...} data[j...]\\) where the product is over tuples</span>
<span class="sd">  `j...` such that `segment_ids[j...] == i`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ``` python</span>
<span class="sd">  c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])</span>
<span class="sd">  tf.unsorted_segment_prod(c, tf.constant([0, 1, 0]), num_segments=2)</span>
<span class="sd">  # ==&gt; [[ 4,  6, 6, 4],</span>
<span class="sd">  #       [5,  6, 7, 8]]</span>
<span class="sd">  ```</span>

<span class="sd">  If there is no entry for a given segment ID `i`, it outputs 1.</span>

<span class="sd">  If the given segment ID `i` is negative, then the corresponding value is</span>
<span class="sd">  dropped, and will not be included in the result.</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A tensor whose shape is a prefix of `data.shape`.</span>
<span class="sd">    num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;UnsortedSegmentProd&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">unsorted_segment_prod_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">unsorted_segment_prod</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                                     <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;UnsortedSegmentProd&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                               <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">unsorted_segment_prod</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                                 <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">),</span> <span class="s2">&quot;Tnumsegments&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tnumsegments&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UnsortedSegmentProd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">UnsortedSegmentProd</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.UnsortedSegmentProd&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">unsorted_segment_prod</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">unsorted_segment_prod_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">segment_ids</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">segment_ids</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tnumsegments</span><span class="p">,</span> <span class="p">(</span><span class="n">num_segments</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">num_segments</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="s2">&quot;Tnumsegments&quot;</span><span class="p">,</span>
  <span class="n">_attr_Tnumsegments</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;UnsortedSegmentProd&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UnsortedSegmentProd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.unsorted_segment_sum&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.unsorted_segment_sum&#39;</span><span class="p">,</span> <span class="s1">&#39;unsorted_segment_sum&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;unsorted_segment_sum&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">unsorted_segment_sum</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the sum along segments of a tensor.</span>

<span class="sd">  Read</span>
<span class="sd">  [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)</span>
<span class="sd">  for an explanation of segments.</span>

<span class="sd">  Computes a tensor such that</span>
<span class="sd">  \\(output[i] = \sum_{j...} data[j...]\\) where the sum is over tuples `j...` such</span>
<span class="sd">  that `segment_ids[j...] == i`.  Unlike `SegmentSum`, `segment_ids`</span>
<span class="sd">  need not be sorted and need not cover all values in the full</span>
<span class="sd">  range of valid values.</span>

<span class="sd">  If the sum is empty for a given segment ID `i`, `output[i] = 0`.</span>
<span class="sd">  If the given segment ID `i` is negative, the value is dropped and will not be</span>
<span class="sd">  added to the sum of the segment.</span>

<span class="sd">  `num_segments` should equal the number of distinct segment IDs.</span>

<span class="sd">  &lt;div style=&quot;width:70%; margin:auto; margin-bottom:10px; margin-top:20px;&quot;&gt;</span>
<span class="sd">  &lt;img style=&quot;width:100%&quot; src=&quot;https://www.tensorflow.org/images/UnsortedSegmentSum.png&quot; alt&gt;</span>
<span class="sd">  &lt;/div&gt;</span>

<span class="sd">  ``` python</span>
<span class="sd">  c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])</span>
<span class="sd">  tf.unsorted_segment_sum(c, tf.constant([0, 1, 0]), num_segments=2)</span>
<span class="sd">  # ==&gt; [[ 5,  5, 5, 5],</span>
<span class="sd">  #       [5,  6, 7, 8]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.</span>
<span class="sd">    segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A tensor whose shape is a prefix of `data.shape`.</span>
<span class="sd">    num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `data`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;UnsortedSegmentSum&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">unsorted_segment_sum_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">unsorted_segment_sum</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                                    <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;UnsortedSegmentSum&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                              <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">unsorted_segment_sum</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="o">=</span><span class="n">segment_ids</span><span class="p">,</span>
                                <span class="n">num_segments</span><span class="o">=</span><span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">),</span> <span class="s2">&quot;Tnumsegments&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tnumsegments&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UnsortedSegmentSum&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">UnsortedSegmentSum</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.UnsortedSegmentSum&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">unsorted_segment_sum</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">unsorted_segment_sum_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">segment_ids</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">segment_ids</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tnumsegments</span><span class="p">,</span> <span class="p">(</span><span class="n">num_segments</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">num_segments</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">num_segments</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="s2">&quot;Tnumsegments&quot;</span><span class="p">,</span>
  <span class="n">_attr_Tnumsegments</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;UnsortedSegmentSum&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UnsortedSegmentSum&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.xdivy&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">xdivy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns 0 if x == 0, and x / y otherwise, elementwise.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Xdivy&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">xdivy_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">xdivy</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Xdivy&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">xdivy</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Xdivy&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Xdivy</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Xdivy&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">xdivy</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">xdivy_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Xdivy&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Xdivy&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">xlog1py</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns 0 if x == 0, and x * log1p(y) otherwise, elementwise.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Xlog1py&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">xlog1py_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Xlog1py&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Xlog1py&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Xlog1py</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Xlog1py&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">xlog1py</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">xlog1py_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Xlog1py&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Xlog1py&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.xlogy&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">xlogy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns 0 if x == 0, and x * log(y) otherwise, elementwise.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Xlogy&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">xlogy_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">xlogy</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Xlogy&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">xlogy</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Xlogy&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Xlogy</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Xlogy&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">xlogy</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">xlogy_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Xlogy&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Xlogy&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.zeta&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.zeta&#39;</span><span class="p">,</span> <span class="s1">&#39;zeta&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;zeta&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">zeta</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the Hurwitz zeta function \\(\zeta(x, q)\\).</span>

<span class="sd">  The Hurwitz zeta function is defined as:</span>


<span class="sd">  \\(\zeta(x, q) = \sum_{n=0}^{\infty} (q + n)^{-x}\\)</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `float32`, `float64`.</span>
<span class="sd">    q: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Zeta&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">zeta_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">zeta</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Zeta&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">zeta</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Zeta&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Zeta</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Zeta&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">zeta</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">zeta_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">q</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Zeta&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Zeta&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright - Wei MEI (Nick Cafferry).

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>
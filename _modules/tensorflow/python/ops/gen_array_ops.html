

<!DOCTYPE html>
<html class="writer-html5" lang="Chinese" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tensorflow.python.ops.gen_array_ops &mdash; tensorflow 0.1.3 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../../../_static/GCC.png"/>
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/language_data.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #343131" >
          

          
            <a href="../../../../index.html" class="icon icon-home" alt="Documentation Home"> tensorflow
          

          
            
            <img src="../../../../_static/GCC.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.1.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">从TensorFlow开始 (Getting Started)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html">TensorFlow如何工作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id1">变量和张量的声明</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id2">使用占位符和变量</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id3">矩阵</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id4">操作符的声明</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id5">载入激活函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id6">数据资源</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id7">资源库</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../01_Introduction/index.html#id8">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">TensorFlow方式 (TensorFlow Way)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html">计算图</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id2">分层嵌套操作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id3">多层操作</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id4">载入损失函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id5">载入反向传播</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id6">随机和批量训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id7">结合训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id8">模型评估</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../02_TensorFlow_Way/index.html#id9">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">线性回归 (Linear Regression)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html">矩阵转置</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#id2">矩阵分解法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#tensorflow">TensorFLow的线性回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#id3">线性回归的损失函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#deming">Deming回归(全回归)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#lasso-ridge">套索(Lasso)回归和岭(Ridge)回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#elastic-net">弹性网(Elastic Net)回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#logistic">逻辑(Logistic)回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../03_Linear_Regression/index.html#id4">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">支持向量机(Support Vector Machines)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_Support_Vector_Machines/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_Support_Vector_Machines/index.html#id2">线性支持向量机</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_Support_Vector_Machines/index.html#id3">回归线性回归</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_Support_Vector_Machines/index.html#tensorflow">TensorFlow中的核</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_Support_Vector_Machines/index.html#id4">非线性支持向量机</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_Support_Vector_Machines/index.html#id5">多类支持向量机</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../04_Support_Vector_Machines/index.html#id6">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">最近邻法 (Nearest Neighbor Methods)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_Nearest_Neighbor_Methods/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_Nearest_Neighbor_Methods/index.html#id2">最近邻法的使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_Nearest_Neighbor_Methods/index.html#id3">文本距离函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_Nearest_Neighbor_Methods/index.html#id4">计算混合距离函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_Nearest_Neighbor_Methods/index.html#id5">地址匹配</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_Nearest_Neighbor_Methods/index.html#id6">图像处理的近邻法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../05_Nearest_Neighbor_Methods/index.html#id7">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">神经元网络 (Neural Networks)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id2">载入操作门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id3">门运算和激活函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id4">载入一层神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id5">载入多层神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id6">使用多层神经网络</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id7">线性模型预测改善</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id8">神经网络学习井字棋</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../06_Neural_Networks/index.html#id9">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">自然语言处理(NLP)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#bag-of-words">词袋 (Bag of Words)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#tf-idf">词频-逆文本频率 (TF-IDF)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#skip-gram">运用Skip-Gram</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#cbow-continuous-bag-fo-words">CBOW (Continuous Bag fo Words)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#word2vec">Word2Vec应用实例</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#doc2vec-sentiment-analysis">Doc2Vec情感分析 (Sentiment Analysis)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#id2">神经网络学习井字棋</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../07_Natural_Language_Processing/index.html#id3">本章学习模块</a></li>
</ul>
<p class="caption"><span class="caption-text">卷积神经网络(CNN)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../08_Convolutional_Neural_Networks/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../08_Convolutional_Neural_Networks/index.html#simple-cnns">简单卷积神经网络 (Simple CNNs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../08_Convolutional_Neural_Networks/index.html#advanced-cnns">高级卷积神经网络 (Advanced CNNs)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../08_Convolutional_Neural_Networks/index.html#id2">重新训练一个存在架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../08_Convolutional_Neural_Networks/index.html#stylenet-neural-style">使用Stylenet/Neural-Style</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../08_Convolutional_Neural_Networks/index.html#deep-dream">运用Deep Dream</a></li>
</ul>
<p class="caption"><span class="caption-text">递归神经网络(RNN)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../09_Recurrent_Neural_Networks/index.html">引言</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../09_Recurrent_Neural_Networks/index.html#id2">卷积神经网络模型用于垃圾信息检测</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../09_Recurrent_Neural_Networks/index.html#lstm">LSTM模型用于文本生成</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../09_Recurrent_Neural_Networks/index.html#id3">堆叠多层LSTM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../09_Recurrent_Neural_Networks/index.html#seq2seq">创建段对段模型翻译 (Seq2Seq)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../09_Recurrent_Neural_Networks/index.html#siamese">训练Siamese相似度测量</a></li>
</ul>
<p class="caption"><span class="caption-text">TensorFlow的应用技巧</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../10_Taking_TensorFlow_to_Production/index.html">单元测试</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../10_Taking_TensorFlow_to_Production/index.html#id2">使用多个执行器 (设备)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../10_Taking_TensorFlow_to_Production/index.html#tensorflow">TensorFlow平行化</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../10_Taking_TensorFlow_to_Production/index.html#id3">TensorFlow开发贴士</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../10_Taking_TensorFlow_to_Production/index.html#id4">TensorFlow开发实例</a></li>
</ul>
<p class="caption"><span class="caption-text">TensorFlow的更多功能</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../11_More_with_TensorFlow/index.html">计算图可视化(用Tensorboard)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../11_More_with_TensorFlow/index.html#id1">遗传算法</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../11_More_with_TensorFlow/index.html#k-means">K-means聚类分析</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../11_More_with_TensorFlow/index.html#id2">解决体系常微分方程</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../11_More_with_TensorFlow/index.html#id3">随机森林</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../11_More_with_TensorFlow/index.html#tensorflowkeras">TensorFlow中的Keras</a></li>
</ul>
<p class="caption"><span class="caption-text">TF Cookbook</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html">书籍介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id2">第一章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id3">第二章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id4">第三章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id5">第四章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id6">第五章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id7">第六章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id8">第七章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id9">第八章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id10">第九章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id11">第十章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id12">第十一章</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bookindex.html#id13">索引</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">tensorflow</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>tensorflow.python.ops.gen_array_ops</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for tensorflow.python.ops.gen_array_ops</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Python wrappers around TensorFlow ops.</span>

<span class="sd">This file is MACHINE GENERATED! Do not edit.</span>
<span class="sd">Original C++ source file: array_ops.cc</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">collections</span>

<span class="kn">from</span> <span class="nn">tensorflow.python</span> <span class="k">import</span> <span class="n">pywrap_tfe</span> <span class="k">as</span> <span class="n">pywrap_tfe</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager</span> <span class="k">import</span> <span class="n">context</span> <span class="k">as</span> <span class="n">_context</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager</span> <span class="k">import</span> <span class="n">core</span> <span class="k">as</span> <span class="n">_core</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.eager</span> <span class="k">import</span> <span class="n">execute</span> <span class="k">as</span> <span class="n">_execute</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">dtypes</span> <span class="k">as</span> <span class="n">_dtypes</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">op_def_registry</span> <span class="k">as</span> <span class="n">_op_def_registry</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">ops</span> <span class="k">as</span> <span class="n">_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">op_def_library</span> <span class="k">as</span> <span class="n">_op_def_library</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util.deprecation</span> <span class="k">import</span> <span class="n">deprecated_endpoints</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util</span> <span class="k">import</span> <span class="n">dispatch</span> <span class="k">as</span> <span class="n">_dispatch</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util.tf_export</span> <span class="k">import</span> <span class="n">tf_export</span>


<span class="k">def</span> <span class="nf">batch_matrix_band_part</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">num_lower</span><span class="p">,</span> <span class="n">num_upper</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;TODO: add doc.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    num_lower: A `Tensor` of type `int64`.</span>
<span class="sd">    num_upper: A `Tensor` of type `int64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;BatchMatrixBandPart&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">num_lower</span><span class="p">,</span> <span class="n">num_upper</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">batch_matrix_band_part_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">num_lower</span><span class="p">,</span> <span class="n">num_upper</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatrixBandPart&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">num_lower</span><span class="o">=</span><span class="n">num_lower</span><span class="p">,</span>
                               <span class="n">num_upper</span><span class="o">=</span><span class="n">num_upper</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatrixBandPart&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">BatchMatrixBandPart</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.BatchMatrixBandPart&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">batch_matrix_band_part</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">batch_matrix_band_part_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">num_lower</span><span class="p">,</span> <span class="n">num_upper</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">num_lower</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">num_lower</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="n">num_upper</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">num_upper</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">num_lower</span><span class="p">,</span> <span class="n">num_upper</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;BatchMatrixBandPart&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatrixBandPart&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">batch_matrix_diag</span><span class="p">(</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;TODO: add doc.</span>

<span class="sd">  Args:</span>
<span class="sd">    diagonal: A `Tensor`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `diagonal`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;BatchMatrixDiag&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">batch_matrix_diag_eager_fallback</span><span class="p">(</span>
            <span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatrixDiag&quot;</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatrixDiag&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">BatchMatrixDiag</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.BatchMatrixDiag&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">batch_matrix_diag</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">batch_matrix_diag_eager_fallback</span><span class="p">(</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">diagonal</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">diagonal</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">diagonal</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;BatchMatrixDiag&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatrixDiag&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">batch_matrix_diag_part</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;TODO: add doc.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;BatchMatrixDiagPart&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">batch_matrix_diag_part_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatrixDiagPart&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatrixDiagPart&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">BatchMatrixDiagPart</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.BatchMatrixDiagPart&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">batch_matrix_diag_part</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">batch_matrix_diag_part_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;BatchMatrixDiagPart&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatrixDiagPart&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">batch_matrix_set_diag</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;TODO: add doc.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    diagonal: A `Tensor`. Must have the same type as `input`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;BatchMatrixSetDiag&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">batch_matrix_set_diag_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatrixSetDiag&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatrixSetDiag&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">BatchMatrixSetDiag</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.BatchMatrixSetDiag&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">batch_matrix_set_diag</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">batch_matrix_set_diag_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;BatchMatrixSetDiag&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchMatrixSetDiag&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">batch_to_space</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">crops</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;BatchToSpace for 4-D tensors of type T.</span>

<span class="sd">  This is a legacy version of the more general BatchToSpaceND.</span>

<span class="sd">  Rearranges (permutes) data from batch into blocks of spatial data, followed by</span>
<span class="sd">  cropping. This is the reverse transformation of SpaceToBatch. More specifically,</span>
<span class="sd">  this op outputs a copy of the input tensor where values from the `batch`</span>
<span class="sd">  dimension are moved in spatial blocks to the `height` and `width` dimensions,</span>
<span class="sd">  followed by cropping along the `height` and `width` dimensions.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. 4-D tensor with shape</span>
<span class="sd">      `[batch*block_size*block_size, height_pad/block_size, width_pad/block_size,</span>
<span class="sd">        depth]`. Note that the batch size of the input tensor must be divisible by</span>
<span class="sd">      `block_size * block_size`.</span>
<span class="sd">    crops: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      2-D tensor of non-negative integers with shape `[2, 2]`. It specifies</span>
<span class="sd">      how many elements to crop from the intermediate result across the spatial</span>
<span class="sd">      dimensions as follows:</span>

<span class="sd">          crops = [[crop_top, crop_bottom], [crop_left, crop_right]]</span>
<span class="sd">    block_size: An `int` that is `&gt;= 2`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;BatchToSpace&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">crops</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">,</span> <span class="n">block_size</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">batch_to_space_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">crops</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">block_size</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;BatchToSpace&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">crops</span><span class="o">=</span><span class="n">crops</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span>
                        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;block_size&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;block_size&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchToSpace&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">BatchToSpace</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.BatchToSpace&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">batch_to_space</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">batch_to_space_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">crops</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">block_size</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">crops</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">crops</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">crops</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;BatchToSpace&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchToSpace&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;batch_to_space_nd&#39;</span><span class="p">,</span> <span class="s1">&#39;manip.batch_to_space_nd&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;batch_to_space_nd&#39;</span><span class="p">,</span> <span class="s1">&#39;manip.batch_to_space_nd&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">batch_to_space_nd</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="p">,</span> <span class="n">crops</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;BatchToSpace for N-D tensors of type T.</span>

<span class="sd">  This operation reshapes the &quot;batch&quot; dimension 0 into `M + 1` dimensions of shape</span>
<span class="sd">  `block_shape + [batch]`, interleaves these blocks back into the grid defined by</span>
<span class="sd">  the spatial dimensions `[1, ..., M]`, to obtain a result with the same rank as</span>
<span class="sd">  the input.  The spatial dimensions of this intermediate result are then</span>
<span class="sd">  optionally cropped according to `crops` to produce the output.  This is the</span>
<span class="sd">  reverse of SpaceToBatch.  See below for a precise description.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">      N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,</span>
<span class="sd">      where spatial_shape has M dimensions.</span>
<span class="sd">    block_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      1-D with shape `[M]`, all values must be &gt;= 1.</span>
<span class="sd">    crops: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      2-D with shape `[M, 2]`, all values must be &gt;= 0.</span>
<span class="sd">        `crops[i] = [crop_start, crop_end]` specifies the amount to crop from input</span>
<span class="sd">        dimension `i + 1`, which corresponds to spatial dimension `i`.  It is</span>
<span class="sd">        required that</span>
<span class="sd">        `crop_start[i] + crop_end[i] &lt;= block_shape[i] * input_shape[i + 1]`.</span>

<span class="sd">      This operation is equivalent to the following steps:</span>

<span class="sd">      1. Reshape `input` to `reshaped` of shape:</span>
<span class="sd">           [block_shape[0], ..., block_shape[M-1],</span>
<span class="sd">            batch / prod(block_shape),</span>
<span class="sd">            input_shape[1], ..., input_shape[N-1]]</span>

<span class="sd">      2. Permute dimensions of `reshaped` to produce `permuted` of shape</span>
<span class="sd">           [batch / prod(block_shape),</span>

<span class="sd">            input_shape[1], block_shape[0],</span>
<span class="sd">            ...,</span>
<span class="sd">            input_shape[M], block_shape[M-1],</span>

<span class="sd">            input_shape[M+1], ..., input_shape[N-1]]</span>

<span class="sd">      3. Reshape `permuted` to produce `reshaped_permuted` of shape</span>
<span class="sd">           [batch / prod(block_shape),</span>

<span class="sd">            input_shape[1] * block_shape[0],</span>
<span class="sd">            ...,</span>
<span class="sd">            input_shape[M] * block_shape[M-1],</span>

<span class="sd">            input_shape[M+1],</span>
<span class="sd">            ...,</span>
<span class="sd">            input_shape[N-1]]</span>

<span class="sd">      4. Crop the start and end of dimensions `[1, ..., M]` of</span>
<span class="sd">         `reshaped_permuted` according to `crops` to produce the output of shape:</span>
<span class="sd">           [batch / prod(block_shape),</span>

<span class="sd">            input_shape[1] * block_shape[0] - crops[0,0] - crops[0,1],</span>
<span class="sd">            ...,</span>
<span class="sd">            input_shape[M] * block_shape[M-1] - crops[M-1,0] - crops[M-1,1],</span>

<span class="sd">            input_shape[M+1], ..., input_shape[N-1]]</span>

<span class="sd">      Some examples:</span>

<span class="sd">      (1) For the following input of shape `[4, 1, 1, 1]`, `block_shape = [2, 2]`, and</span>
<span class="sd">          `crops = [[0, 0], [0, 0]]`:</span>

<span class="sd">      ```</span>
<span class="sd">      [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      The output tensor has shape `[1, 2, 2, 1]` and value:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1], [2]], [[3], [4]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      (2) For the following input of shape `[4, 1, 1, 3]`, `block_shape = [2, 2]`, and</span>
<span class="sd">          `crops = [[0, 0], [0, 0]]`:</span>

<span class="sd">      ```</span>
<span class="sd">      [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      The output tensor has shape `[1, 2, 2, 3]` and value:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1, 2, 3], [4, 5, 6]],</span>
<span class="sd">            [[7, 8, 9], [10, 11, 12]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      (3) For the following input of shape `[4, 2, 2, 1]`, `block_shape = [2, 2]`, and</span>
<span class="sd">          `crops = [[0, 0], [0, 0]]`:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1], [3]], [[9], [11]]],</span>
<span class="sd">           [[[2], [4]], [[10], [12]]],</span>
<span class="sd">           [[[5], [7]], [[13], [15]]],</span>
<span class="sd">           [[[6], [8]], [[14], [16]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      The output tensor has shape `[1, 4, 4, 1]` and value:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1],   [2],  [3],  [4]],</span>
<span class="sd">           [[5],   [6],  [7],  [8]],</span>
<span class="sd">           [[9],  [10], [11],  [12]],</span>
<span class="sd">           [[13], [14], [15],  [16]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      (4) For the following input of shape `[8, 1, 3, 1]`, `block_shape = [2, 2]`, and</span>
<span class="sd">          `crops = [[0, 0], [2, 0]]`:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[0], [1], [3]]], [[[0], [9], [11]]],</span>
<span class="sd">           [[[0], [2], [4]]], [[[0], [10], [12]]],</span>
<span class="sd">           [[[0], [5], [7]]], [[[0], [13], [15]]],</span>
<span class="sd">           [[[0], [6], [8]]], [[[0], [14], [16]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      The output tensor has shape `[2, 2, 4, 1]` and value:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1],   [2],  [3],  [4]],</span>
<span class="sd">            [[5],   [6],  [7],  [8]]],</span>
<span class="sd">           [[[9],  [10], [11],  [12]],</span>
<span class="sd">            [[13], [14], [15],  [16]]]]</span>
<span class="sd">      ```</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;BatchToSpaceND&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="p">,</span> <span class="n">crops</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">batch_to_space_nd_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="p">,</span> <span class="n">crops</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">batch_to_space_nd</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="o">=</span><span class="n">block_shape</span><span class="p">,</span>
                                 <span class="n">crops</span><span class="o">=</span><span class="n">crops</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;BatchToSpaceND&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="o">=</span><span class="n">block_shape</span><span class="p">,</span> <span class="n">crops</span><span class="o">=</span><span class="n">crops</span><span class="p">,</span>
                          <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">batch_to_space_nd</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="o">=</span><span class="n">block_shape</span><span class="p">,</span>
                             <span class="n">crops</span><span class="o">=</span><span class="n">crops</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tblock_shape&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tblock_shape&quot;</span><span class="p">),</span> <span class="s2">&quot;Tcrops&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tcrops&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchToSpaceND&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">BatchToSpaceND</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.BatchToSpaceND&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">batch_to_space_nd</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">batch_to_space_nd_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="p">,</span> <span class="n">crops</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tblock_shape</span><span class="p">,</span> <span class="p">(</span><span class="n">block_shape</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">block_shape</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_attr_Tcrops</span><span class="p">,</span> <span class="p">(</span><span class="n">crops</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">crops</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="p">,</span> <span class="n">crops</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tblock_shape&quot;</span><span class="p">,</span> <span class="n">_attr_Tblock_shape</span><span class="p">,</span> <span class="s2">&quot;Tcrops&quot;</span><span class="p">,</span>
  <span class="n">_attr_Tcrops</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;BatchToSpaceND&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BatchToSpaceND&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="bitcast"><a class="viewcode-back" href="../../../../index.html#tensorflow.bitcast">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;bitcast&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">bitcast</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="nb">type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Bitcasts a tensor from one type to another without copying data.</span>

<span class="sd">  Given a tensor `input`, this operation returns a tensor that has the same buffer</span>
<span class="sd">  data as `input` with datatype `type`.</span>

<span class="sd">  If the input datatype `T` is larger than the output datatype `type` then the</span>
<span class="sd">  shape changes from [...] to [..., sizeof(`T`)/sizeof(`type`)].</span>

<span class="sd">  If `T` is smaller than `type`, the operator requires that the rightmost</span>
<span class="sd">  dimension be equal to sizeof(`type`)/sizeof(`T`). The shape then goes from</span>
<span class="sd">  [..., sizeof(`type`)/sizeof(`T`)] to [...].</span>

<span class="sd">  tf.bitcast() and tf.cast() work differently when real dtype is casted as a complex dtype</span>
<span class="sd">  (e.g. tf.complex64 or tf.complex128) as tf.cast() make imaginary part 0 while tf.bitcast()</span>
<span class="sd">  gives module error.</span>
<span class="sd">  For example,</span>

<span class="sd">  Example 1:</span>

<span class="sd">  &gt;&gt;&gt; a = [1., 2., 3.]</span>
<span class="sd">  &gt;&gt;&gt; equality_bitcast = tf.bitcast(a, tf.complex128)</span>
<span class="sd">  Traceback (most recent call last):</span>
<span class="sd">  ...</span>
<span class="sd">  InvalidArgumentError: Cannot bitcast from 1 to 18 [Op:Bitcast]</span>
<span class="sd">  &gt;&gt;&gt; equality_cast = tf.cast(a, tf.complex128)</span>
<span class="sd">  &gt;&gt;&gt; print(equality_cast)</span>
<span class="sd">  tf.Tensor([1.+0.j 2.+0.j 3.+0.j], shape=(3,), dtype=complex128)</span>

<span class="sd">  Example 2:</span>

<span class="sd">  &gt;&gt;&gt; tf.bitcast(tf.constant(0xffffffff, dtype=tf.uint32), tf.uint8)</span>
<span class="sd">  &lt;tf.Tensor: shape=(4,), dtype=uint8, numpy=array([255, 255, 255, 255], dtype=uint8)&gt;</span>

<span class="sd">  Example 3:</span>

<span class="sd">  &gt;&gt;&gt; x = [1., 2., 3.]</span>
<span class="sd">  &gt;&gt;&gt; y = [0., 2., 3.]</span>
<span class="sd">  &gt;&gt;&gt; equality= tf.equal(x,y)</span>
<span class="sd">  &gt;&gt;&gt; equality_cast = tf.cast(equality,tf.float32)</span>
<span class="sd">  &gt;&gt;&gt; equality_bitcast = tf.bitcast(equality_cast,tf.uint8)</span>
<span class="sd">  &gt;&gt;&gt; print(equality)</span>
<span class="sd">  tf.Tensor([False True True], shape=(3,), dtype=bool)</span>
<span class="sd">  &gt;&gt;&gt; print(equality_cast)</span>
<span class="sd">  tf.Tensor([0. 1. 1.], shape=(3,), dtype=float32)</span>
<span class="sd">  &gt;&gt;&gt; print(equality_bitcast)</span>
<span class="sd">  tf.Tensor(</span>
<span class="sd">      [[  0   0   0   0]</span>
<span class="sd">       [  0   0 128  63]</span>
<span class="sd">       [  0   0 128  63]], shape=(3, 4), dtype=uint8)</span>

<span class="sd">  *NOTE*: Bitcast is implemented as a low-level cast, so machines with different</span>
<span class="sd">  endian orderings will give different results.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int64`, `int32`, `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `complex64`, `complex128`, `qint8`, `quint8`, `qint16`, `quint16`, `qint32`.</span>
<span class="sd">    type: A `tf.DType` from: `tf.bfloat16, tf.half, tf.float32, tf.float64, tf.int64, tf.int32, tf.uint8, tf.uint16, tf.uint32, tf.uint64, tf.int8, tf.int16, tf.complex64, tf.complex128, tf.qint8, tf.quint8, tf.qint16, tf.quint16, tf.qint32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `type`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Bitcast&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;type&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">bitcast_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">bitcast</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="nb">type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="nb">type</span><span class="p">,</span> <span class="s2">&quot;type&quot;</span><span class="p">)</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Bitcast&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">bitcast</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;type&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;type&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Bitcast&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Bitcast</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Bitcast&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">bitcast</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">bitcast_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="nb">type</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="nb">type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="nb">type</span><span class="p">,</span> <span class="s2">&quot;type&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;type&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Bitcast&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Bitcast&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">broadcast_args</span><span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return the shape of s0 op s1 with broadcast.</span>

<span class="sd">  Given `s0` and `s1`, tensors that represent shapes, compute `r0`, the</span>
<span class="sd">  broadcasted shape. `s0`, `s1` and `r0` are all integer vectors.</span>

<span class="sd">  Args:</span>
<span class="sd">    s0: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    s1: A `Tensor`. Must have the same type as `s0`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `s0`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;BroadcastArgs&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">broadcast_args_eager_fallback</span><span class="p">(</span>
            <span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;BroadcastArgs&quot;</span><span class="p">,</span> <span class="n">s0</span><span class="o">=</span><span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="o">=</span><span class="n">s1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BroadcastArgs&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">BroadcastArgs</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.BroadcastArgs&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">broadcast_args</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">broadcast_args_eager_fallback</span><span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;BroadcastArgs&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BroadcastArgs&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_BroadcastGradientArgsOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;BroadcastGradientArgs&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;r0&quot;</span><span class="p">,</span> <span class="s2">&quot;r1&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">broadcast_gradient_args</span><span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return the reduction indices for computing gradients of s0 op s1 with broadcast.</span>

<span class="sd">  This is typically used by gradient computations for a broadcasting operation.</span>

<span class="sd">  Args:</span>
<span class="sd">    s0: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    s1: A `Tensor`. Must have the same type as `s0`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (r0, r1).</span>

<span class="sd">    r0: A `Tensor`. Has the same type as `s0`.</span>
<span class="sd">    r1: A `Tensor`. Has the same type as `s0`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;BroadcastGradientArgs&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_BroadcastGradientArgsOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">broadcast_gradient_args_eager_fallback</span><span class="p">(</span>
            <span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;BroadcastGradientArgs&quot;</span><span class="p">,</span> <span class="n">s0</span><span class="o">=</span><span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="o">=</span><span class="n">s1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BroadcastGradientArgs&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_BroadcastGradientArgsOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">BroadcastGradientArgs</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.BroadcastGradientArgs&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">broadcast_gradient_args</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">broadcast_gradient_args_eager_fallback</span><span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">s0</span><span class="p">,</span> <span class="n">s1</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;BroadcastGradientArgs&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BroadcastGradientArgs&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_BroadcastGradientArgsOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="broadcast_to"><a class="viewcode-back" href="../../../../index.html#tensorflow.broadcast_to">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;broadcast_to&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">broadcast_to</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Broadcast an array for a compatible shape.</span>

<span class="sd">  Broadcasting is the process of making arrays to have compatible shapes</span>
<span class="sd">  for arithmetic operations. Two shapes are compatible if for each</span>
<span class="sd">  dimension pair they are either equal or one of them is one. When trying</span>
<span class="sd">  to broadcast a Tensor to a shape, it starts with the trailing dimensions,</span>
<span class="sd">  and works its way forward.</span>

<span class="sd">  For example,</span>

<span class="sd">  &gt;&gt;&gt; x = tf.constant([1, 2, 3])</span>
<span class="sd">  &gt;&gt;&gt; y = tf.broadcast_to(x, [3, 3])</span>
<span class="sd">  &gt;&gt;&gt; print(y)</span>
<span class="sd">  tf.Tensor(</span>
<span class="sd">      [[1 2 3]</span>
<span class="sd">       [1 2 3]</span>
<span class="sd">       [1 2 3]], shape=(3, 3), dtype=int32)</span>

<span class="sd">  In the above example, the input Tensor with the shape of `[1, 3]`</span>
<span class="sd">  is broadcasted to output Tensor with shape of `[3, 3]`.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. A Tensor to broadcast.</span>
<span class="sd">    shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      An 1-D `int` Tensor. The shape of the desired output.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;BroadcastTo&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">broadcast_to_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">broadcast_to</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;BroadcastTo&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">broadcast_to</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BroadcastTo&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">BroadcastTo</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.BroadcastTo&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">broadcast_to</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">broadcast_to_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">shape</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;BroadcastTo&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;BroadcastTo&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;debugging.check_numerics&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;debugging.check_numerics&#39;</span><span class="p">,</span> <span class="s1">&#39;check_numerics&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;check_numerics&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">check_numerics</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">message</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Checks a tensor for NaN and Inf values.</span>

<span class="sd">  When run, reports an `InvalidArgument` error if `tensor` has any values</span>
<span class="sd">  that are not a number (NaN) or infinity (Inf). Otherwise, passes `tensor` as-is.</span>

<span class="sd">  Args:</span>
<span class="sd">    tensor: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    message: A `string`. Prefix of the error message.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;CheckNumerics&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="s2">&quot;message&quot;</span><span class="p">,</span> <span class="n">message</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">check_numerics_eager_fallback</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">message</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">check_numerics</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">message</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">message</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="s2">&quot;message&quot;</span><span class="p">)</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;CheckNumerics&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">message</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">check_numerics</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">message</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;message&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;message&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;CheckNumerics&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">CheckNumerics</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.CheckNumerics&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">check_numerics</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">check_numerics_eager_fallback</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">message</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">message</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="s2">&quot;message&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">tensor</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">tensor</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;message&quot;</span><span class="p">,</span> <span class="n">message</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;CheckNumerics&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;CheckNumerics&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">check_numerics_v2</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">message</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Checks a tensor for NaN, -Inf and +Inf values.</span>

<span class="sd">  When run, reports an `InvalidArgument` error if `tensor` has any values</span>
<span class="sd">  that are not a number (NaN) or infinity (Inf). Otherwise, passes `tensor` as-is.</span>
<span class="sd">  Unlike CheckNumerics (V1), CheckNumericsV2 distinguishes -Inf and +Inf in the</span>
<span class="sd">  errors it throws.</span>

<span class="sd">  Args:</span>
<span class="sd">    tensor: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    message: A `string`. Prefix of the error message.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;CheckNumericsV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="s2">&quot;message&quot;</span><span class="p">,</span> <span class="n">message</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">check_numerics_v2_eager_fallback</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">message</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">message</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="s2">&quot;message&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;CheckNumericsV2&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">message</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;message&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;message&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;CheckNumericsV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">CheckNumericsV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.CheckNumericsV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">check_numerics_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">check_numerics_v2_eager_fallback</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">message</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">message</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="s2">&quot;message&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">tensor</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">tensor</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;message&quot;</span><span class="p">,</span> <span class="n">message</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;CheckNumericsV2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;CheckNumericsV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">concat</span><span class="p">(</span><span class="n">concat_dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Concatenates tensors along one dimension.</span>

<span class="sd">  Args:</span>
<span class="sd">    concat_dim: A `Tensor` of type `int32`.</span>
<span class="sd">      0-D.  The dimension along which to concatenate.  Must be in the</span>
<span class="sd">      range [0, rank(values)).</span>
<span class="sd">    values: A list of at least 2 `Tensor` objects with the same type.</span>
<span class="sd">      The `N` Tensors to concatenate. Their ranks and types must match,</span>
<span class="sd">      and their sizes must match in all dimensions except `concat_dim`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `values`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Concat&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">concat_dim</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">concat_eager_fallback</span><span class="p">(</span>
            <span class="n">concat_dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;values&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;concat&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">values</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Concat&quot;</span><span class="p">,</span> <span class="n">concat_dim</span><span class="o">=</span><span class="n">concat_dim</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Concat&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Concat</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Concat&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">concat</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">concat_eager_fallback</span><span class="p">(</span><span class="n">concat_dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;values&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;concat&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">values</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">values</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">concat_dim</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">concat_dim</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">concat_dim</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_attr_N</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Concat&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Concat&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">concat_offset</span><span class="p">(</span><span class="n">concat_dim</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes offsets of concat inputs within its output.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;x&#39; is [2, 2, 7]</span>
<span class="sd">  # &#39;y&#39; is [2, 3, 7]</span>
<span class="sd">  # &#39;z&#39; is [2, 5, 7]</span>
<span class="sd">  concat_offset(2, [x, y, z]) =&gt; [0, 0, 0], [0, 2, 0], [0, 5, 0]</span>
<span class="sd">  ```</span>

<span class="sd">  This is typically used by gradient computations for a concat operation.</span>

<span class="sd">  Args:</span>
<span class="sd">    concat_dim: A `Tensor` of type `int32`.</span>
<span class="sd">      The dimension along which to concatenate.</span>
<span class="sd">    shape: A list of at least 2 `Tensor` objects with type `int32`.</span>
<span class="sd">      The `N` int32 vectors representing shape of tensors being concatenated.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A list with the same length as `shape` of `Tensor` objects with type `int32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ConcatOffset&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">concat_dim</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">concat_offset_eager_fallback</span><span class="p">(</span>
            <span class="n">concat_dim</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;shape&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;concat_offset&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">shape</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ConcatOffset&quot;</span><span class="p">,</span> <span class="n">concat_dim</span><span class="o">=</span><span class="n">concat_dim</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ConcatOffset&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ConcatOffset</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ConcatOffset&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">concat_offset</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">concat_offset_eager_fallback</span><span class="p">(</span><span class="n">concat_dim</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;shape&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;concat_offset&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">shape</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">concat_dim</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">concat_dim</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_n_to_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">concat_dim</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_attr_N</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ConcatOffset&quot;</span><span class="p">,</span> <span class="n">_attr_N</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ConcatOffset&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">concat_v2</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Concatenates tensors along one dimension.</span>

<span class="sd">  Args:</span>
<span class="sd">    values: A list of at least 2 `Tensor` objects with the same type.</span>
<span class="sd">      List of `N` Tensors to concatenate. Their ranks and types must match,</span>
<span class="sd">      and their sizes must match in all dimensions except `concat_dim`.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      0-D.  The dimension along which to concatenate.  Must be in the</span>
<span class="sd">      range [-rank(values), rank(values)).</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `values`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ConcatV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">concat_v2_eager_fallback</span><span class="p">(</span>
            <span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;values&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;concat_v2&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">values</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ConcatV2&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
              <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ConcatV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ConcatV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ConcatV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">concat_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">concat_v2_eager_fallback</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;values&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;concat_v2&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">values</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">values</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">values</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_attr_N</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ConcatV2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ConcatV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">conjugate_transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Shuffle dimensions of x according to a permutation and conjugate the result.</span>

<span class="sd">  The output `y` has the same rank as `x`. The shapes of `x` and `y` satisfy:</span>
<span class="sd">    `y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]`</span>
<span class="sd">    `y[i,j,k,...,s,t,u] == conj(x[perm[i], perm[j], perm[k],...,perm[s], perm[t], perm[u]])`</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`.</span>
<span class="sd">    perm: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ConjugateTranspose&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">conjugate_transpose_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ConjugateTranspose&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tperm&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tperm&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ConjugateTranspose&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ConjugateTranspose</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ConjugateTranspose&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">conjugate_transpose</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">conjugate_transpose_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tperm</span><span class="p">,</span> <span class="p">(</span><span class="n">perm</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">perm</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tperm&quot;</span><span class="p">,</span> <span class="n">_attr_Tperm</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ConjugateTranspose&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ConjugateTranspose&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">const</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns a constant tensor.</span>

<span class="sd">  Args:</span>
<span class="sd">    value: A `tf.TensorProto`. Attr `value` is the tensor to return.</span>
<span class="sd">    dtype: A `tf.DType`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `dtype`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Const&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">const_eager_fallback</span><span class="p">(</span>
            <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">value</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">)</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Const&quot;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">),</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Const&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Const</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Const&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">const</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">const_eager_fallback</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">value</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">)</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Const&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Const&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">debug_gradient_identity</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Identity op for gradient debugging.</span>

<span class="sd">  This op is hidden from public in Python. It is used by TensorFlow Debugger to</span>
<span class="sd">  register gradient tensors for gradient debugging.</span>
<span class="sd">  This op operates on non-reference-type tensors.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;DebugGradientIdentity&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">debug_gradient_identity_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;DebugGradientIdentity&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;DebugGradientIdentity&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">DebugGradientIdentity</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.DebugGradientIdentity&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">debug_gradient_identity</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">debug_gradient_identity_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;DebugGradientIdentity&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;DebugGradientIdentity&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">debug_gradient_ref_identity</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Identity op for gradient debugging.</span>

<span class="sd">  This op is hidden from public in Python. It is used by TensorFlow Debugger to</span>
<span class="sd">  register gradient tensors for gradient debugging.</span>
<span class="sd">  This op operates on reference-type tensors.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A mutable `Tensor`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A mutable `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;debug_gradient_ref_identity op does not support eager execution. Arg &#39;output&#39; is a ref.&quot;</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;DebugGradientRefIdentity&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;DebugGradientRefIdentity&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">DebugGradientRefIdentity</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.DebugGradientRefIdentity&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">debug_gradient_ref_identity</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">debug_gradient_ref_identity_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;debug_gradient_ref_identity op does not support eager execution. Arg &#39;output&#39; is a ref.&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">deep_copy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Makes a copy of `x`.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. The source tensor of type `T`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;DeepCopy&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">deep_copy_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;DeepCopy&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;DeepCopy&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">DeepCopy</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.DeepCopy&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">deep_copy</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">deep_copy_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;DeepCopy&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;DeepCopy&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">depth_to_space</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;NHWC&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;DepthToSpace for tensors of type T.</span>

<span class="sd">  Rearranges data from depth into blocks of spatial data.</span>
<span class="sd">  This is the reverse transformation of SpaceToDepth. More specifically,</span>
<span class="sd">  this op outputs a copy of the input tensor where values from the `depth`</span>
<span class="sd">  dimension are moved in spatial blocks to the `height` and `width` dimensions.</span>
<span class="sd">  The attr `block_size` indicates the input block size and how the data is moved.</span>

<span class="sd">    * Chunks of data of size `block_size * block_size` from depth are rearranged</span>
<span class="sd">      into non-overlapping blocks of size `block_size x block_size`</span>
<span class="sd">    * The width the output tensor is `input_depth * block_size`, whereas the</span>
<span class="sd">      height is `input_height * block_size`.</span>
<span class="sd">    * The Y, X coordinates within each block of the output image are determined</span>
<span class="sd">      by the high order component of the input channel index.</span>
<span class="sd">    * The depth of the input tensor must be divisible by</span>
<span class="sd">      `block_size * block_size`.</span>

<span class="sd">  The `data_format` attr specifies the layout of the input and output tensors</span>
<span class="sd">  with the following options:</span>
<span class="sd">    &quot;NHWC&quot;: `[ batch, height, width, channels ]`</span>
<span class="sd">    &quot;NCHW&quot;: `[ batch, channels, height, width ]`</span>
<span class="sd">    &quot;NCHW_VECT_C&quot;:</span>
<span class="sd">        `qint8 [ batch, channels / 4, height, width, 4 ]`</span>

<span class="sd">  It is useful to consider the operation as transforming a 6-D Tensor.</span>
<span class="sd">  e.g. for data_format = NHWC,</span>
<span class="sd">       Each element in the input tensor can be specified via 6 coordinates,</span>
<span class="sd">       ordered by decreasing memory layout significance as:</span>
<span class="sd">       n,iY,iX,bY,bX,oC  (where n=batch index, iX, iY means X or Y coordinates</span>
<span class="sd">                          within the input image, bX, bY means coordinates</span>
<span class="sd">                          within the output block, oC means output channels).</span>
<span class="sd">       The output would be the input transposed to the following layout:</span>
<span class="sd">       n,iY,bY,iX,bX,oC</span>

<span class="sd">  This operation is useful for resizing the activations between convolutions</span>
<span class="sd">  (but keeping all data), e.g. instead of pooling. It is also useful for training</span>
<span class="sd">  purely convolutional models.</span>

<span class="sd">  For example, given an input of shape `[1, 1, 1, 4]`, data_format = &quot;NHWC&quot; and</span>
<span class="sd">  block_size = 2:</span>

<span class="sd">  ```</span>
<span class="sd">  x = [[[[1, 2, 3, 4]]]]</span>

<span class="sd">  ```</span>

<span class="sd">  This operation will output a tensor of shape `[1, 2, 2, 1]`:</span>

<span class="sd">  ```</span>
<span class="sd">     [[[[1], [2]],</span>
<span class="sd">       [[3], [4]]]]</span>
<span class="sd">  ```</span>

<span class="sd">  Here, the input has a batch of 1 and each batch element has shape `[1, 1, 4]`,</span>
<span class="sd">  the corresponding output will have 2x2 elements and will have a depth of</span>
<span class="sd">  1 channel (1 = `4 / (block_size * block_size)`).</span>
<span class="sd">  The output element shape is `[2, 2, 1]`.</span>

<span class="sd">  For an input tensor with larger depth, here of shape `[1, 1, 1, 12]`, e.g.</span>

<span class="sd">  ```</span>
<span class="sd">  x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]</span>
<span class="sd">  ```</span>

<span class="sd">  This operation, for block size of 2, will return the following tensor of shape</span>
<span class="sd">  `[1, 2, 2, 3]`</span>

<span class="sd">  ```</span>
<span class="sd">     [[[[1, 2, 3], [4, 5, 6]],</span>
<span class="sd">       [[7, 8, 9], [10, 11, 12]]]]</span>

<span class="sd">  ```</span>

<span class="sd">  Similarly, for the following input of shape `[1 2 2 4]`, and a block size of 2:</span>

<span class="sd">  ```</span>
<span class="sd">  x =  [[[[1, 2, 3, 4],</span>
<span class="sd">         [5, 6, 7, 8]],</span>
<span class="sd">        [[9, 10, 11, 12],</span>
<span class="sd">         [13, 14, 15, 16]]]]</span>
<span class="sd">  ```</span>

<span class="sd">  the operator will return the following tensor of shape `[1 4 4 1]`:</span>

<span class="sd">  ```</span>
<span class="sd">  x = [[[ [1],   [2],  [5],  [6]],</span>
<span class="sd">        [ [3],   [4],  [7],  [8]],</span>
<span class="sd">        [ [9],  [10], [13],  [14]],</span>
<span class="sd">        [ [11], [12], [15],  [16]]]]</span>

<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    block_size: An `int` that is `&gt;= 2`.</span>
<span class="sd">      The size of the spatial block, same as in Space2Depth.</span>
<span class="sd">    data_format: An optional `string` from: `&quot;NHWC&quot;, &quot;NCHW&quot;, &quot;NCHW_VECT_C&quot;`. Defaults to `&quot;NHWC&quot;`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;DepthToSpace&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="s2">&quot;data_format&quot;</span><span class="p">,</span>
        <span class="n">data_format</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">depth_to_space_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">block_size</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">data_format</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">data_format</span> <span class="o">=</span> <span class="s2">&quot;NHWC&quot;</span>
  <span class="n">data_format</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="s2">&quot;data_format&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;DepthToSpace&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span>
                        <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;block_size&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;block_size&quot;</span><span class="p">),</span> <span class="s2">&quot;data_format&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;data_format&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;DepthToSpace&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">DepthToSpace</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.DepthToSpace&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">depth_to_space</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">depth_to_space_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">data_format</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">block_size</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">data_format</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">data_format</span> <span class="o">=</span> <span class="s2">&quot;NHWC&quot;</span>
  <span class="n">data_format</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="s2">&quot;data_format&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="s2">&quot;data_format&quot;</span><span class="p">,</span>
  <span class="n">data_format</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;DepthToSpace&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;DepthToSpace&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">dequantize</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">min_range</span><span class="p">,</span> <span class="n">max_range</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;MIN_COMBINED&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Dequantize the &#39;input&#39; tensor into a float or bfloat16 Tensor.</span>

<span class="sd">  [min_range, max_range] are scalar floats that specify the range for</span>
<span class="sd">  the output. The &#39;mode&#39; attribute controls exactly which calculations are</span>
<span class="sd">  used to convert the float values to their quantized equivalents.</span>

<span class="sd">  In &#39;MIN_COMBINED&#39; mode, each value of the tensor will undergo the following:</span>

<span class="sd">  ```</span>
<span class="sd">  if T == qint8: in[i] += (range(T) + 1)/ 2.0</span>
<span class="sd">  out[i] = min_range + (in[i]* (max_range - min_range) / range(T))</span>
<span class="sd">  ```</span>
<span class="sd">  here `range(T) = numeric_limits&lt;T&gt;::max() - numeric_limits&lt;T&gt;::min()`</span>

<span class="sd">  *MIN_COMBINED Mode Example*</span>

<span class="sd">  If the input comes from a QuantizedRelu6, the output type is</span>
<span class="sd">  quint8 (range of 0-255) but the possible range of QuantizedRelu6 is</span>
<span class="sd">  0-6.  The min_range and max_range values are therefore 0.0 and 6.0.</span>
<span class="sd">  Dequantize on quint8 will take each value, cast to float, and multiply</span>
<span class="sd">  by 6 / 255.</span>
<span class="sd">  Note that if quantizedtype is qint8, the operation will additionally add</span>
<span class="sd">  each value by 128 prior to casting.</span>

<span class="sd">  If the mode is &#39;MIN_FIRST&#39;, then this approach is used:</span>

<span class="sd">  ```c++</span>
<span class="sd">  num_discrete_values = 1 &lt;&lt; (# of bits in T)</span>
<span class="sd">  range_adjust = num_discrete_values / (num_discrete_values - 1)</span>
<span class="sd">  range = (range_max - range_min) * range_adjust</span>
<span class="sd">  range_scale = range / num_discrete_values</span>
<span class="sd">  const double offset_input = static_cast&lt;double&gt;(input) - lowest_quantized;</span>
<span class="sd">  result = range_min + ((input - numeric_limits&lt;T&gt;::min()) * range_scale)</span>
<span class="sd">  ```</span>

<span class="sd">  If the mode is `SCALED`, dequantization is performed by multiplying each</span>
<span class="sd">  input value by a scaling_factor. (Thus an input of 0 always maps to 0.0).</span>

<span class="sd">  The scaling_factor is determined from `min_range`, `max_range`, and</span>
<span class="sd">  `narrow_range` in a way that is compatible with `QuantizeAndDequantize{V2|V3}`</span>
<span class="sd">  and `QuantizeV2`, using the following algorithm:</span>

<span class="sd">  ```c++</span>

<span class="sd">    const int min_expected_T = std::numeric_limits&lt;T&gt;::min() +</span>
<span class="sd">      (narrow_range ? 1 : 0);</span>
<span class="sd">    const int max_expected_T = std::numeric_limits&lt;T&gt;::max();</span>
<span class="sd">    const float max_expected_T = std::numeric_limits&lt;float&gt;::max();</span>

<span class="sd">    const float scale_factor =</span>
<span class="sd">      (std::numeric_limits&lt;T&gt;::min() == 0) ? (max_range / max_expected_T)</span>
<span class="sd">                                           : std::max(min_range / min_expected_T,</span>
<span class="sd">                                                      max_range / max_expected_T);</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.</span>
<span class="sd">    min_range: A `Tensor` of type `float32`.</span>
<span class="sd">      The minimum scalar value possibly produced for the input.</span>
<span class="sd">    max_range: A `Tensor` of type `float32`.</span>
<span class="sd">      The maximum scalar value possibly produced for the input.</span>
<span class="sd">    mode: An optional `string` from: `&quot;MIN_COMBINED&quot;, &quot;MIN_FIRST&quot;, &quot;SCALED&quot;`. Defaults to `&quot;MIN_COMBINED&quot;`.</span>
<span class="sd">    narrow_range: An optional `bool`. Defaults to `False`.</span>
<span class="sd">    axis: An optional `int`. Defaults to `-1`.</span>
<span class="sd">    dtype: An optional `tf.DType` from: `tf.bfloat16, tf.float32`. Defaults to `tf.float32`.</span>
<span class="sd">      Type of the output tensor. Currently Dequantize supports float and bfloat16.</span>
<span class="sd">      If &#39;dtype&#39; is &#39;bfloat16&#39;, it only supports &#39;MIN_COMBINED&#39; mode.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `dtype`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Dequantize&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">min_range</span><span class="p">,</span> <span class="n">max_range</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span>
        <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dequantize_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">min_range</span><span class="p">,</span> <span class="n">max_range</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
            <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">mode</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;MIN_COMBINED&quot;</span>
  <span class="n">mode</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Dequantize&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">min_range</span><span class="o">=</span><span class="n">min_range</span><span class="p">,</span> <span class="n">max_range</span><span class="o">=</span><span class="n">max_range</span><span class="p">,</span>
                      <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
                      <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;mode&quot;</span><span class="p">),</span>
              <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;narrow_range&quot;</span><span class="p">),</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;axis&quot;</span><span class="p">),</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Dequantize&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Dequantize</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Dequantize&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">dequantize</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">dequantize_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">min_range</span><span class="p">,</span> <span class="n">max_range</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">mode</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;MIN_COMBINED&quot;</span>
  <span class="n">mode</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">min_range</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">min_range</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">max_range</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">max_range</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">min_range</span><span class="p">,</span> <span class="n">max_range</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span>
  <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Dequantize&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Dequantize&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;linalg.tensor_diag&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;linalg.tensor_diag&#39;</span><span class="p">,</span> <span class="s1">&#39;diag&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;diag&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns a diagonal tensor with a given diagonal values.</span>

<span class="sd">  Given a `diagonal`, this operation returns a tensor with the `diagonal` and</span>
<span class="sd">  everything else padded with zeros. The diagonal is computed as follows:</span>

<span class="sd">  Assume `diagonal` has dimensions [D1,..., Dk], then the output is a tensor of</span>
<span class="sd">  rank 2k with dimensions [D1,..., Dk, D1,..., Dk] where:</span>

<span class="sd">  `output[i1,..., ik, i1,..., ik] = diagonal[i1, ..., ik]` and 0 everywhere else.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;diagonal&#39; is [1, 2, 3, 4]</span>
<span class="sd">  tf.diag(diagonal) ==&gt; [[1, 0, 0, 0]</span>
<span class="sd">                         [0, 2, 0, 0]</span>
<span class="sd">                         [0, 0, 3, 0]</span>
<span class="sd">                         [0, 0, 0, 4]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    diagonal: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">      Rank k tensor where k is at most 1.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `diagonal`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Diag&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">diagonal</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">diag_eager_fallback</span><span class="p">(</span>
            <span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">diag</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Diag&quot;</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">diag</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Diag&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Diag</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Diag&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">diag</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">diag_eager_fallback</span><span class="p">(</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">diagonal</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">diagonal</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">diagonal</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Diag&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Diag&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;linalg.tensor_diag_part&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;linalg.tensor_diag_part&#39;</span><span class="p">,</span> <span class="s1">&#39;diag_part&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;diag_part&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">diag_part</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the diagonal part of the tensor.</span>

<span class="sd">  This operation returns a tensor with the `diagonal` part</span>
<span class="sd">  of the `input`. The `diagonal` part is computed as follows:</span>

<span class="sd">  Assume `input` has dimensions `[D1,..., Dk, D1,..., Dk]`, then the output is a</span>
<span class="sd">  tensor of rank `k` with dimensions `[D1,..., Dk]` where:</span>

<span class="sd">  `diagonal[i1,..., ik] = input[i1, ..., ik, i1,..., ik]`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;input&#39; is [[1, 0, 0, 0]</span>
<span class="sd">                [0, 2, 0, 0]</span>
<span class="sd">                [0, 0, 3, 0]</span>
<span class="sd">                [0, 0, 0, 4]]</span>

<span class="sd">  tf.diag_part(input) ==&gt; [1, 2, 3, 4]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.</span>
<span class="sd">      Rank k tensor where k is even and not zero.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;DiagPart&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">diag_part_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">diag_part</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;DiagPart&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">diag_part</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;DiagPart&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">DiagPart</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.DiagPart&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">diag_part</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">diag_part_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;DiagPart&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;DiagPart&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">edit_distance</span><span class="p">(</span><span class="n">hypothesis_indices</span><span class="p">,</span> <span class="n">hypothesis_values</span><span class="p">,</span> <span class="n">hypothesis_shape</span><span class="p">,</span> <span class="n">truth_indices</span><span class="p">,</span> <span class="n">truth_values</span><span class="p">,</span> <span class="n">truth_shape</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the (possibly normalized) Levenshtein Edit Distance.</span>

<span class="sd">  The inputs are variable-length sequences provided by SparseTensors</span>
<span class="sd">    (hypothesis_indices, hypothesis_values, hypothesis_shape)</span>
<span class="sd">  and</span>
<span class="sd">    (truth_indices, truth_values, truth_shape).</span>

<span class="sd">  The inputs are:</span>

<span class="sd">  Args:</span>
<span class="sd">    hypothesis_indices: A `Tensor` of type `int64`.</span>
<span class="sd">      The indices of the hypothesis list SparseTensor.</span>
<span class="sd">      This is an N x R int64 matrix.</span>
<span class="sd">    hypothesis_values: A `Tensor`.</span>
<span class="sd">      The values of the hypothesis list SparseTensor.</span>
<span class="sd">      This is an N-length vector.</span>
<span class="sd">    hypothesis_shape: A `Tensor` of type `int64`.</span>
<span class="sd">      The shape of the hypothesis list SparseTensor.</span>
<span class="sd">      This is an R-length vector.</span>
<span class="sd">    truth_indices: A `Tensor` of type `int64`.</span>
<span class="sd">      The indices of the truth list SparseTensor.</span>
<span class="sd">      This is an M x R int64 matrix.</span>
<span class="sd">    truth_values: A `Tensor`. Must have the same type as `hypothesis_values`.</span>
<span class="sd">      The values of the truth list SparseTensor.</span>
<span class="sd">      This is an M-length vector.</span>
<span class="sd">    truth_shape: A `Tensor` of type `int64`. truth indices, vector.</span>
<span class="sd">    normalize: An optional `bool`. Defaults to `True`.</span>
<span class="sd">      boolean (if true, edit distances are normalized by length of truth).</span>

<span class="sd">      The output is:</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;EditDistance&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">hypothesis_indices</span><span class="p">,</span> <span class="n">hypothesis_values</span><span class="p">,</span>
        <span class="n">hypothesis_shape</span><span class="p">,</span> <span class="n">truth_indices</span><span class="p">,</span> <span class="n">truth_values</span><span class="p">,</span> <span class="n">truth_shape</span><span class="p">,</span>
        <span class="s2">&quot;normalize&quot;</span><span class="p">,</span> <span class="n">normalize</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">edit_distance_eager_fallback</span><span class="p">(</span>
            <span class="n">hypothesis_indices</span><span class="p">,</span> <span class="n">hypothesis_values</span><span class="p">,</span> <span class="n">hypothesis_shape</span><span class="p">,</span>
            <span class="n">truth_indices</span><span class="p">,</span> <span class="n">truth_values</span><span class="p">,</span> <span class="n">truth_shape</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">normalize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">normalize</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">normalize</span><span class="p">,</span> <span class="s2">&quot;normalize&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;EditDistance&quot;</span><span class="p">,</span> <span class="n">hypothesis_indices</span><span class="o">=</span><span class="n">hypothesis_indices</span><span class="p">,</span>
                        <span class="n">hypothesis_values</span><span class="o">=</span><span class="n">hypothesis_values</span><span class="p">,</span>
                        <span class="n">hypothesis_shape</span><span class="o">=</span><span class="n">hypothesis_shape</span><span class="p">,</span>
                        <span class="n">truth_indices</span><span class="o">=</span><span class="n">truth_indices</span><span class="p">,</span>
                        <span class="n">truth_values</span><span class="o">=</span><span class="n">truth_values</span><span class="p">,</span> <span class="n">truth_shape</span><span class="o">=</span><span class="n">truth_shape</span><span class="p">,</span>
                        <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;normalize&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;normalize&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;EditDistance&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">EditDistance</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.EditDistance&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">edit_distance</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">edit_distance_eager_fallback</span><span class="p">(</span><span class="n">hypothesis_indices</span><span class="p">,</span> <span class="n">hypothesis_values</span><span class="p">,</span> <span class="n">hypothesis_shape</span><span class="p">,</span> <span class="n">truth_indices</span><span class="p">,</span> <span class="n">truth_values</span><span class="p">,</span> <span class="n">truth_shape</span><span class="p">,</span> <span class="n">normalize</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">normalize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">normalize</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">normalize</span><span class="p">,</span> <span class="s2">&quot;normalize&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">hypothesis_values</span><span class="p">,</span> <span class="n">truth_values</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">hypothesis_values</span><span class="p">,</span> <span class="n">truth_values</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">hypothesis_indices</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">hypothesis_indices</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="n">hypothesis_shape</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">hypothesis_shape</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="n">truth_indices</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">truth_indices</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="n">truth_shape</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">truth_shape</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">hypothesis_indices</span><span class="p">,</span> <span class="n">hypothesis_values</span><span class="p">,</span> <span class="n">hypothesis_shape</span><span class="p">,</span> <span class="n">truth_indices</span><span class="p">,</span> <span class="n">truth_values</span><span class="p">,</span> <span class="n">truth_shape</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;normalize&quot;</span><span class="p">,</span> <span class="n">normalize</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;EditDistance&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;EditDistance&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">empty</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Creates a tensor with the given shape.</span>

<span class="sd">This operation creates a tensor of `shape` and `dtype`.</span>

<span class="sd">  Args:</span>
<span class="sd">    shape: A `Tensor` of type `int32`.</span>
<span class="sd">      1-D. Represents the shape of the output tensor.</span>
<span class="sd">    dtype: A `tf.DType`.</span>
<span class="sd">    init: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If True, initialize the returned tensor with the default value of dtype.  Otherwise, the implementation is free not to initializethe tensor&#39;s content.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `dtype`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Empty&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;init&quot;</span><span class="p">,</span> <span class="n">init</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">empty_eager_fallback</span><span class="p">(</span>
            <span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">init</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">init</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">init</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="s2">&quot;init&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Empty&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">),</span> <span class="s2">&quot;init&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;init&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Empty&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Empty</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Empty&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">empty</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">empty_eager_fallback</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">init</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">init</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">init</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">init</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="s2">&quot;init&quot;</span><span class="p">)</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">shape</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;init&quot;</span><span class="p">,</span> <span class="n">init</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Empty&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Empty&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">ensure_shape</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Ensures that the tensor&#39;s shape matches the expected shape.</span>

<span class="sd">  Raises an error if the input tensor&#39;s shape does not match the specified shape.</span>
<span class="sd">  Returns the input tensor otherwise.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. A tensor, whose shape is to be validated.</span>
<span class="sd">    shape: A `tf.TensorShape` or list of `ints`.</span>
<span class="sd">      The expected (possibly partially specified) shape of the input tensor.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;EnsureShape&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ensure_shape_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;EnsureShape&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;EnsureShape&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">EnsureShape</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.EnsureShape&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">ensure_shape</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">ensure_shape_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;EnsureShape&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;EnsureShape&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">expand_dims</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Inserts a dimension of 1 into a tensor&#39;s shape.</span>

<span class="sd">  Given a tensor `input`, this operation inserts a dimension of 1 at the</span>
<span class="sd">  dimension index `axis` of `input`&#39;s shape. The dimension index `axis` starts at</span>
<span class="sd">  zero; if you specify a negative number for `axis` it is counted backward from</span>
<span class="sd">  the end.</span>

<span class="sd">  This operation is useful if you want to add a batch dimension to a single</span>
<span class="sd">  element. For example, if you have a single image of shape `[height, width,</span>
<span class="sd">  channels]`, you can make it a batch of 1 image with `expand_dims(image, 0)`,</span>
<span class="sd">  which will make the shape `[1, height, width, channels]`.</span>

<span class="sd">  Other examples:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;t&#39; is a tensor of shape [2]</span>
<span class="sd">  shape(expand_dims(t, 0)) ==&gt; [1, 2]</span>
<span class="sd">  shape(expand_dims(t, 1)) ==&gt; [2, 1]</span>
<span class="sd">  shape(expand_dims(t, -1)) ==&gt; [2, 1]</span>

<span class="sd">  # &#39;t2&#39; is a tensor of shape [2, 3, 5]</span>
<span class="sd">  shape(expand_dims(t2, 0)) ==&gt; [1, 2, 3, 5]</span>
<span class="sd">  shape(expand_dims(t2, 2)) ==&gt; [2, 3, 1, 5]</span>
<span class="sd">  shape(expand_dims(t2, 3)) ==&gt; [2, 3, 5, 1]</span>
<span class="sd">  ```</span>

<span class="sd">  This operation requires that:</span>

<span class="sd">  `-1-input.dims() &lt;= dim &lt;= input.dims()`</span>

<span class="sd">  This operation is related to `squeeze()`, which removes dimensions of</span>
<span class="sd">  size 1.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      0-D (scalar). Specifies the dimension index at which to</span>
<span class="sd">      expand the shape of `input`. Must be in the range</span>
<span class="sd">      `[-rank(input) - 1, rank(input)]`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ExpandDims&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">expand_dims_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ExpandDims&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tdim&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tdim&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ExpandDims&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ExpandDims</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ExpandDims&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">expand_dims</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">expand_dims_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tdim</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tdim&quot;</span><span class="p">,</span> <span class="n">_attr_Tdim</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ExpandDims&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ExpandDims&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">extract_image_patches</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">ksizes</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">rates</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Extract `patches` from `images` and put them in the &quot;depth&quot; output dimension.</span>

<span class="sd">  Args:</span>
<span class="sd">    images: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `complex64`, `complex128`, `bool`.</span>
<span class="sd">      4-D Tensor with shape `[batch, in_rows, in_cols, depth]`.</span>
<span class="sd">    ksizes: A list of `ints` that has length `&gt;= 4`.</span>
<span class="sd">      The size of the sliding window for each dimension of `images`.</span>
<span class="sd">    strides: A list of `ints` that has length `&gt;= 4`.</span>
<span class="sd">      How far the centers of two consecutive patches are in</span>
<span class="sd">      the images. Must be: `[1, stride_rows, stride_cols, 1]`.</span>
<span class="sd">    rates: A list of `ints` that has length `&gt;= 4`.</span>
<span class="sd">      Must be: `[1, rate_rows, rate_cols, 1]`. This is the</span>
<span class="sd">      input stride, specifying how far two consecutive patch samples are in the</span>
<span class="sd">      input. Equivalent to extracting patches with</span>
<span class="sd">      `patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1)`, followed by</span>
<span class="sd">      subsampling them spatially by a factor of `rates`. This is equivalent to</span>
<span class="sd">      `rate` in dilated (a.k.a. Atrous) convolutions.</span>
<span class="sd">    padding: A `string` from: `&quot;SAME&quot;, &quot;VALID&quot;`.</span>
<span class="sd">      The type of padding algorithm to use.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `images`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ExtractImagePatches&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="s2">&quot;ksizes&quot;</span><span class="p">,</span> <span class="n">ksizes</span><span class="p">,</span> <span class="s2">&quot;strides&quot;</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span>
        <span class="s2">&quot;rates&quot;</span><span class="p">,</span> <span class="n">rates</span><span class="p">,</span> <span class="s2">&quot;padding&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">extract_image_patches_eager_fallback</span><span class="p">(</span>
            <span class="n">images</span><span class="p">,</span> <span class="n">ksizes</span><span class="o">=</span><span class="n">ksizes</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">rates</span><span class="o">=</span><span class="n">rates</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ksizes</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;ksizes&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;extract_image_patches&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">ksizes</span><span class="p">)</span>
  <span class="n">ksizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">_i</span><span class="p">,</span> <span class="s2">&quot;ksizes&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="n">ksizes</span><span class="p">]</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">strides</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;strides&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;extract_image_patches&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">strides</span><span class="p">)</span>
  <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">_i</span><span class="p">,</span> <span class="s2">&quot;strides&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="n">strides</span><span class="p">]</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rates</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;rates&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;extract_image_patches&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">rates</span><span class="p">)</span>
  <span class="n">rates</span> <span class="o">=</span> <span class="p">[</span><span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">_i</span><span class="p">,</span> <span class="s2">&quot;rates&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="n">rates</span><span class="p">]</span>
  <span class="n">padding</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="s2">&quot;padding&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ExtractImagePatches&quot;</span><span class="p">,</span> <span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span> <span class="n">ksizes</span><span class="o">=</span><span class="n">ksizes</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
                               <span class="n">rates</span><span class="o">=</span><span class="n">rates</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;ksizes&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;ksizes&quot;</span><span class="p">),</span> <span class="s2">&quot;strides&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;strides&quot;</span><span class="p">),</span> <span class="s2">&quot;rates&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;rates&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;padding&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;padding&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ExtractImagePatches&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ExtractImagePatches</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ExtractImagePatches&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">extract_image_patches</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">extract_image_patches_eager_fallback</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">ksizes</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">rates</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ksizes</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;ksizes&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;extract_image_patches&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">ksizes</span><span class="p">)</span>
  <span class="n">ksizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">_i</span><span class="p">,</span> <span class="s2">&quot;ksizes&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="n">ksizes</span><span class="p">]</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">strides</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;strides&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;extract_image_patches&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">strides</span><span class="p">)</span>
  <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">_i</span><span class="p">,</span> <span class="s2">&quot;strides&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="n">strides</span><span class="p">]</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rates</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;rates&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;extract_image_patches&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">rates</span><span class="p">)</span>
  <span class="n">rates</span> <span class="o">=</span> <span class="p">[</span><span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">_i</span><span class="p">,</span> <span class="s2">&quot;rates&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="n">rates</span><span class="p">]</span>
  <span class="n">padding</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="s2">&quot;padding&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">images</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">images</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;ksizes&quot;</span><span class="p">,</span> <span class="n">ksizes</span><span class="p">,</span> <span class="s2">&quot;strides&quot;</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="s2">&quot;rates&quot;</span><span class="p">,</span> <span class="n">rates</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;padding&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ExtractImagePatches&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ExtractImagePatches&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="extract_volume_patches"><a class="viewcode-back" href="../../../../index.html#tensorflow.extract_volume_patches">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;extract_volume_patches&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">extract_volume_patches</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ksizes</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Extract `patches` from `input` and put them in the &quot;depth&quot; output dimension. 3D extension of `extract_image_patches`.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.</span>
<span class="sd">      5-D Tensor with shape `[batch, in_planes, in_rows, in_cols, depth]`.</span>
<span class="sd">    ksizes: A list of `ints` that has length `&gt;= 5`.</span>
<span class="sd">      The size of the sliding window for each dimension of `input`.</span>
<span class="sd">    strides: A list of `ints` that has length `&gt;= 5`.</span>
<span class="sd">      1-D of length 5. How far the centers of two consecutive patches are in</span>
<span class="sd">      `input`. Must be: `[1, stride_planes, stride_rows, stride_cols, 1]`.</span>
<span class="sd">    padding: A `string` from: `&quot;SAME&quot;, &quot;VALID&quot;`.</span>
<span class="sd">      The type of padding algorithm to use.</span>

<span class="sd">      We specify the size-related attributes as:</span>

<span class="sd">      ```python</span>
<span class="sd">            ksizes = [1, ksize_planes, ksize_rows, ksize_cols, 1]</span>
<span class="sd">            strides = [1, stride_planes, strides_rows, strides_cols, 1]</span>
<span class="sd">      ```</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ExtractVolumePatches&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;ksizes&quot;</span><span class="p">,</span> <span class="n">ksizes</span><span class="p">,</span> <span class="s2">&quot;strides&quot;</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span>
        <span class="s2">&quot;padding&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">extract_volume_patches_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">ksizes</span><span class="o">=</span><span class="n">ksizes</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">extract_volume_patches</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">ksizes</span><span class="o">=</span><span class="n">ksizes</span><span class="p">,</span>
                                      <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                                      <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ksizes</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;ksizes&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;extract_volume_patches&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">ksizes</span><span class="p">)</span>
  <span class="n">ksizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">_i</span><span class="p">,</span> <span class="s2">&quot;ksizes&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="n">ksizes</span><span class="p">]</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">strides</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;strides&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;extract_volume_patches&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">strides</span><span class="p">)</span>
  <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">_i</span><span class="p">,</span> <span class="s2">&quot;strides&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="n">strides</span><span class="p">]</span>
  <span class="n">padding</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="s2">&quot;padding&quot;</span><span class="p">)</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ExtractVolumePatches&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">ksizes</span><span class="o">=</span><span class="n">ksizes</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">extract_volume_patches</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">ksizes</span><span class="o">=</span><span class="n">ksizes</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
                                  <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;ksizes&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;ksizes&quot;</span><span class="p">),</span> <span class="s2">&quot;strides&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;strides&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
              <span class="s2">&quot;padding&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;padding&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ExtractVolumePatches&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">ExtractVolumePatches</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ExtractVolumePatches&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">extract_volume_patches</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">extract_volume_patches_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ksizes</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ksizes</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;ksizes&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;extract_volume_patches&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">ksizes</span><span class="p">)</span>
  <span class="n">ksizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">_i</span><span class="p">,</span> <span class="s2">&quot;ksizes&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="n">ksizes</span><span class="p">]</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">strides</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;strides&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;extract_volume_patches&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">strides</span><span class="p">)</span>
  <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">_i</span><span class="p">,</span> <span class="s2">&quot;strides&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="n">strides</span><span class="p">]</span>
  <span class="n">padding</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="s2">&quot;padding&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;ksizes&quot;</span><span class="p">,</span> <span class="n">ksizes</span><span class="p">,</span> <span class="s2">&quot;strides&quot;</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;padding&quot;</span><span class="p">,</span>
  <span class="n">padding</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ExtractVolumePatches&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ExtractVolumePatches&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;quantization.fake_quant_with_min_max_args&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;quantization.fake_quant_with_min_max_args&#39;</span><span class="p">,</span> <span class="s1">&#39;fake_quant_with_min_max_args&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;fake_quant_with_min_max_args&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fake_quant_with_min_max_args</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">6</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fake-quantize the &#39;inputs&#39; tensor, type float to &#39;outputs&#39; tensor of same type.</span>

<span class="sd">  Attributes `[min; max]` define the clamping range for the `inputs` data.</span>
<span class="sd">  `inputs` values are quantized into the quantization range (`[0; 2^num_bits - 1]`</span>
<span class="sd">  when `narrow_range` is false and `[1; 2^num_bits - 1]` when it is true) and</span>
<span class="sd">  then de-quantized and output as floats in `[min; max]` interval.</span>
<span class="sd">  `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.</span>

<span class="sd">  Before quantization, `min` and `max` values are adjusted with the following</span>
<span class="sd">  logic.</span>
<span class="sd">  It is suggested to have `min &lt;= 0 &lt;= max`. If `0` is not in the range of values,</span>
<span class="sd">  the behavior can be unexpected:</span>
<span class="sd">  If `0 &lt; min &lt; max`: `min_adj = 0` and `max_adj = max - min`.</span>
<span class="sd">  If `min &lt; max &lt; 0`: `min_adj = min - max` and `max_adj = 0`.</span>
<span class="sd">  If `min &lt;= 0 &lt;= max`: `scale = (max - min) / (2^num_bits - 1) `,</span>
<span class="sd">  `min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.</span>

<span class="sd">  Quantization is called fake since the output is still in floating point.</span>

<span class="sd">  Args:</span>
<span class="sd">    inputs: A `Tensor` of type `float32`.</span>
<span class="sd">    min: An optional `float`. Defaults to `-6`.</span>
<span class="sd">    max: An optional `float`. Defaults to `6`.</span>
<span class="sd">    num_bits: An optional `int`. Defaults to `8`.</span>
<span class="sd">    narrow_range: An optional `bool`. Defaults to `False`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;FakeQuantWithMinMaxArgs&quot;</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span>
        <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fake_quant_with_min_max_args_eager_fallback</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
            <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">fake_quant_with_min_max_args</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                            <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                            <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
                                            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="nb">min</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">min</span> <span class="o">=</span> <span class="o">-</span><span class="mi">6</span>
  <span class="nb">min</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="nb">min</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">max</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">max</span> <span class="o">=</span> <span class="mi">6</span>
  <span class="nb">max</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="nb">max</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxArgs&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                   <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                   <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">fake_quant_with_min_max_args</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                        <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                        <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;min&quot;</span><span class="p">),</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;max&quot;</span><span class="p">),</span>
              <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">),</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;narrow_range&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxArgs&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">FakeQuantWithMinMaxArgs</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.FakeQuantWithMinMaxArgs&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">fake_quant_with_min_max_args</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">fake_quant_with_min_max_args_eager_fallback</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">min</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">min</span> <span class="o">=</span> <span class="o">-</span><span class="mi">6</span>
  <span class="nb">min</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="nb">min</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">max</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">max</span> <span class="o">=</span> <span class="mi">6</span>
  <span class="nb">max</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="nb">max</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="n">inputs</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
  <span class="n">narrow_range</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;FakeQuantWithMinMaxArgs&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxArgs&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;quantization.fake_quant_with_min_max_args_gradient&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;quantization.fake_quant_with_min_max_args_gradient&#39;</span><span class="p">,</span> <span class="s1">&#39;fake_quant_with_min_max_args_gradient&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;fake_quant_with_min_max_args_gradient&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fake_quant_with_min_max_args_gradient</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">6</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute gradients for a FakeQuantWithMinMaxArgs operation.</span>

<span class="sd">  Args:</span>
<span class="sd">    gradients: A `Tensor` of type `float32`.</span>
<span class="sd">      Backpropagated gradients above the FakeQuantWithMinMaxArgs operation.</span>
<span class="sd">    inputs: A `Tensor` of type `float32`.</span>
<span class="sd">      Values passed as inputs to the FakeQuantWithMinMaxArgs operation.</span>
<span class="sd">    min: An optional `float`. Defaults to `-6`.</span>
<span class="sd">    max: An optional `float`. Defaults to `6`.</span>
<span class="sd">    num_bits: An optional `int`. Defaults to `8`.</span>
<span class="sd">    narrow_range: An optional `bool`. Defaults to `False`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span>
        <span class="s2">&quot;FakeQuantWithMinMaxArgsGradient&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
        <span class="n">narrow_range</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fake_quant_with_min_max_args_gradient_eager_fallback</span><span class="p">(</span>
            <span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
            <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">fake_quant_with_min_max_args_gradient</span><span class="p">,</span> <span class="n">gradients</span><span class="o">=</span><span class="n">gradients</span><span class="p">,</span>
                                                     <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span>
                                                     <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                                     <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                                     <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
                                                     <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="nb">min</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">min</span> <span class="o">=</span> <span class="o">-</span><span class="mi">6</span>
  <span class="nb">min</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="nb">min</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">max</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">max</span> <span class="o">=</span> <span class="mi">6</span>
  <span class="nb">max</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="nb">max</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxArgsGradient&quot;</span><span class="p">,</span> <span class="n">gradients</span><span class="o">=</span><span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                                           <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                           <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                           <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
                                           <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">fake_quant_with_min_max_args_gradient</span><span class="p">,</span> <span class="n">gradients</span><span class="o">=</span><span class="n">gradients</span><span class="p">,</span>
                                                 <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span>
                                                 <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                                 <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
                                                 <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;min&quot;</span><span class="p">),</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;max&quot;</span><span class="p">),</span>
              <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">),</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;narrow_range&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxArgsGradient&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">FakeQuantWithMinMaxArgsGradient</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.FakeQuantWithMinMaxArgsGradient&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">fake_quant_with_min_max_args_gradient</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">fake_quant_with_min_max_args_gradient_eager_fallback</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">min</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">min</span> <span class="o">=</span> <span class="o">-</span><span class="mi">6</span>
  <span class="nb">min</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="nb">min</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">max</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">max</span> <span class="o">=</span> <span class="mi">6</span>
  <span class="nb">max</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="nb">max</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="n">gradients</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">inputs</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
  <span class="n">narrow_range</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;FakeQuantWithMinMaxArgsGradient&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxArgsGradient&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;quantization.fake_quant_with_min_max_vars&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;quantization.fake_quant_with_min_max_vars&#39;</span><span class="p">,</span> <span class="s1">&#39;fake_quant_with_min_max_vars&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;fake_quant_with_min_max_vars&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fake_quant_with_min_max_vars</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fake-quantize the &#39;inputs&#39; tensor of type float via global float scalars `min`</span>

<span class="sd">  and `max` to &#39;outputs&#39; tensor of same shape as `inputs`.</span>

<span class="sd">  `[min; max]` define the clamping range for the `inputs` data.</span>
<span class="sd">  `inputs` values are quantized into the quantization range (`[0; 2^num_bits - 1]`</span>
<span class="sd">  when `narrow_range` is false and `[1; 2^num_bits - 1]` when it is true) and</span>
<span class="sd">  then de-quantized and output as floats in `[min; max]` interval.</span>
<span class="sd">  `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.</span>

<span class="sd">  Before quantization, `min` and `max` values are adjusted with the following</span>
<span class="sd">  logic.</span>
<span class="sd">  It is suggested to have `min &lt;= 0 &lt;= max`. If `0` is not in the range of values,</span>
<span class="sd">  the behavior can be unexpected:</span>
<span class="sd">  If `0 &lt; min &lt; max`: `min_adj = 0` and `max_adj = max - min`.</span>
<span class="sd">  If `min &lt; max &lt; 0`: `min_adj = min - max` and `max_adj = 0`.</span>
<span class="sd">  If `min &lt;= 0 &lt;= max`: `scale = (max - min) / (2^num_bits - 1) `,</span>
<span class="sd">  `min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.</span>

<span class="sd">  This operation has a gradient and thus allows for training `min` and `max`</span>
<span class="sd">  values.</span>

<span class="sd">  Args:</span>
<span class="sd">    inputs: A `Tensor` of type `float32`.</span>
<span class="sd">    min: A `Tensor` of type `float32`.</span>
<span class="sd">    max: A `Tensor` of type `float32`.</span>
<span class="sd">    num_bits: An optional `int`. Defaults to `8`.</span>
<span class="sd">    narrow_range: An optional `bool`. Defaults to `False`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;FakeQuantWithMinMaxVars&quot;</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span>
        <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fake_quant_with_min_max_vars_eager_fallback</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">fake_quant_with_min_max_vars</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                            <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                            <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
                                            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVars&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                   <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                   <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">fake_quant_with_min_max_vars</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                        <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                        <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">),</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;narrow_range&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVars&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">FakeQuantWithMinMaxVars</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.FakeQuantWithMinMaxVars&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">fake_quant_with_min_max_vars</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">fake_quant_with_min_max_vars_eager_fallback</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="n">inputs</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="nb">min</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="nb">min</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="nb">max</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="nb">max</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;FakeQuantWithMinMaxVars&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVars&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_FakeQuantWithMinMaxVarsGradientOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;FakeQuantWithMinMaxVarsGradient&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;backprops_wrt_input&quot;</span><span class="p">,</span> <span class="s2">&quot;backprop_wrt_min&quot;</span><span class="p">,</span> <span class="s2">&quot;backprop_wrt_max&quot;</span><span class="p">])</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;quantization.fake_quant_with_min_max_vars_gradient&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;quantization.fake_quant_with_min_max_vars_gradient&#39;</span><span class="p">,</span> <span class="s1">&#39;fake_quant_with_min_max_vars_gradient&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;fake_quant_with_min_max_vars_gradient&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fake_quant_with_min_max_vars_gradient</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute gradients for a FakeQuantWithMinMaxVars operation.</span>

<span class="sd">  Args:</span>
<span class="sd">    gradients: A `Tensor` of type `float32`.</span>
<span class="sd">      Backpropagated gradients above the FakeQuantWithMinMaxVars operation.</span>
<span class="sd">    inputs: A `Tensor` of type `float32`.</span>
<span class="sd">      Values passed as inputs to the FakeQuantWithMinMaxVars operation.</span>
<span class="sd">      min, max: Quantization interval, scalar floats.</span>
<span class="sd">    min: A `Tensor` of type `float32`.</span>
<span class="sd">    max: A `Tensor` of type `float32`.</span>
<span class="sd">    num_bits: An optional `int`. Defaults to `8`.</span>
<span class="sd">      The bitwidth of the quantization; between 2 and 8, inclusive.</span>
<span class="sd">    narrow_range: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      Whether to quantize into 2^num_bits - 1 distinct values.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (backprops_wrt_input, backprop_wrt_min, backprop_wrt_max).</span>

<span class="sd">    backprops_wrt_input: A `Tensor` of type `float32`.</span>
<span class="sd">    backprop_wrt_min: A `Tensor` of type `float32`.</span>
<span class="sd">    backprop_wrt_max: A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVarsGradient&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_FakeQuantWithMinMaxVarsGradientOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fake_quant_with_min_max_vars_gradient_eager_fallback</span><span class="p">(</span>
            <span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
            <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">fake_quant_with_min_max_vars_gradient</span><span class="p">,</span> <span class="n">gradients</span><span class="o">=</span><span class="n">gradients</span><span class="p">,</span>
                                                     <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span>
                                                     <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                                     <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                                     <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
                                                     <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVarsGradient&quot;</span><span class="p">,</span> <span class="n">gradients</span><span class="o">=</span><span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                                           <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                           <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                           <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
                                           <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">fake_quant_with_min_max_vars_gradient</span><span class="p">,</span> <span class="n">gradients</span><span class="o">=</span><span class="n">gradients</span><span class="p">,</span>
                                                 <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span>
                                                 <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                                 <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
                                                 <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">),</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;narrow_range&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVarsGradient&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_FakeQuantWithMinMaxVarsGradientOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">FakeQuantWithMinMaxVarsGradient</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.FakeQuantWithMinMaxVarsGradient&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">fake_quant_with_min_max_vars_gradient</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">fake_quant_with_min_max_vars_gradient_eager_fallback</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="n">gradients</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">inputs</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="nb">min</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="nb">min</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="nb">max</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="nb">max</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;FakeQuantWithMinMaxVarsGradient&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVarsGradient&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_FakeQuantWithMinMaxVarsGradientOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;quantization.fake_quant_with_min_max_vars_per_channel&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;quantization.fake_quant_with_min_max_vars_per_channel&#39;</span><span class="p">,</span> <span class="s1">&#39;fake_quant_with_min_max_vars_per_channel&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;fake_quant_with_min_max_vars_per_channel&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fake_quant_with_min_max_vars_per_channel</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fake-quantize the &#39;inputs&#39; tensor of type float and one of the shapes: `[d]`,</span>

<span class="sd">  `[b, d]` `[b, h, w, d]` via per-channel floats `min` and `max` of shape `[d]`</span>
<span class="sd">  to &#39;outputs&#39; tensor of same shape as `inputs`.</span>

<span class="sd">  `[min; max]` define the clamping range for the `inputs` data.</span>
<span class="sd">  `inputs` values are quantized into the quantization range (`[0; 2^num_bits - 1]`</span>
<span class="sd">  when `narrow_range` is false and `[1; 2^num_bits - 1]` when it is true) and</span>
<span class="sd">  then de-quantized and output as floats in `[min; max]` interval.</span>
<span class="sd">  `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.</span>

<span class="sd">  Before quantization, `min` and `max` values are adjusted with the following</span>
<span class="sd">  logic.</span>
<span class="sd">  It is suggested to have `min &lt;= 0 &lt;= max`. If `0` is not in the range of values,</span>
<span class="sd">  the behavior can be unexpected:</span>
<span class="sd">  If `0 &lt; min &lt; max`: `min_adj = 0` and `max_adj = max - min`.</span>
<span class="sd">  If `min &lt; max &lt; 0`: `min_adj = min - max` and `max_adj = 0`.</span>
<span class="sd">  If `min &lt;= 0 &lt;= max`: `scale = (max - min) / (2^num_bits - 1) `,</span>
<span class="sd">  `min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.</span>

<span class="sd">  This operation has a gradient and thus allows for training `min` and `max`</span>
<span class="sd">  values.</span>

<span class="sd">  Args:</span>
<span class="sd">    inputs: A `Tensor` of type `float32`.</span>
<span class="sd">    min: A `Tensor` of type `float32`.</span>
<span class="sd">    max: A `Tensor` of type `float32`.</span>
<span class="sd">    num_bits: An optional `int`. Defaults to `8`.</span>
<span class="sd">    narrow_range: An optional `bool`. Defaults to `False`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVarsPerChannel&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span>
        <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fake_quant_with_min_max_vars_per_channel_eager_fallback</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">fake_quant_with_min_max_vars_per_channel</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                                                        <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                                        <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                                        <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
                                                        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVarsPerChannel&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                             <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                             <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
                                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">fake_quant_with_min_max_vars_per_channel</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span>
                                                    <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                                    <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                                    <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
                                                    <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">),</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;narrow_range&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVarsPerChannel&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">FakeQuantWithMinMaxVarsPerChannel</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.FakeQuantWithMinMaxVarsPerChannel&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">fake_quant_with_min_max_vars_per_channel</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">fake_quant_with_min_max_vars_per_channel_eager_fallback</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="n">inputs</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="nb">min</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="nb">min</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="nb">max</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="nb">max</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;FakeQuantWithMinMaxVarsPerChannel&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVarsPerChannel&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_FakeQuantWithMinMaxVarsPerChannelGradientOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;FakeQuantWithMinMaxVarsPerChannelGradient&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;backprops_wrt_input&quot;</span><span class="p">,</span> <span class="s2">&quot;backprop_wrt_min&quot;</span><span class="p">,</span> <span class="s2">&quot;backprop_wrt_max&quot;</span><span class="p">])</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;quantization.fake_quant_with_min_max_vars_per_channel_gradient&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;quantization.fake_quant_with_min_max_vars_per_channel_gradient&#39;</span><span class="p">,</span> <span class="s1">&#39;fake_quant_with_min_max_vars_per_channel_gradient&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;fake_quant_with_min_max_vars_per_channel_gradient&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fake_quant_with_min_max_vars_per_channel_gradient</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.</span>

<span class="sd">  Args:</span>
<span class="sd">    gradients: A `Tensor` of type `float32`.</span>
<span class="sd">      Backpropagated gradients above the FakeQuantWithMinMaxVars operation,</span>
<span class="sd">      shape one of: `[d]`, `[b, d]`,  `[b, h, w, d]`.</span>
<span class="sd">    inputs: A `Tensor` of type `float32`.</span>
<span class="sd">      Values passed as inputs to the FakeQuantWithMinMaxVars operation, shape</span>
<span class="sd">        same as `gradients`.</span>
<span class="sd">      min, max: Quantization interval, floats of shape `[d]`.</span>
<span class="sd">    min: A `Tensor` of type `float32`.</span>
<span class="sd">    max: A `Tensor` of type `float32`.</span>
<span class="sd">    num_bits: An optional `int`. Defaults to `8`.</span>
<span class="sd">      The bitwidth of the quantization; between 2 and 16, inclusive.</span>
<span class="sd">    narrow_range: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      Whether to quantize into 2^num_bits - 1 distinct values.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (backprops_wrt_input, backprop_wrt_min, backprop_wrt_max).</span>

<span class="sd">    backprops_wrt_input: A `Tensor` of type `float32`.</span>
<span class="sd">    backprop_wrt_min: A `Tensor` of type `float32`.</span>
<span class="sd">    backprop_wrt_max: A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVarsPerChannelGradient&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
        <span class="n">narrow_range</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_FakeQuantWithMinMaxVarsPerChannelGradientOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fake_quant_with_min_max_vars_per_channel_gradient_eager_fallback</span><span class="p">(</span>
            <span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
            <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">fake_quant_with_min_max_vars_per_channel_gradient</span><span class="p">,</span> <span class="n">gradients</span><span class="o">=</span><span class="n">gradients</span><span class="p">,</span>
                                                                 <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                                                                 <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span>
                                                                 <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                                                 <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                                                 <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
                                                                 <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVarsPerChannelGradient&quot;</span><span class="p">,</span> <span class="n">gradients</span><span class="o">=</span><span class="n">gradients</span><span class="p">,</span>
                                                     <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span>
                                                     <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                                     <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                                     <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
                                                     <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">fake_quant_with_min_max_vars_per_channel_gradient</span><span class="p">,</span> <span class="n">gradients</span><span class="o">=</span><span class="n">gradients</span><span class="p">,</span>
                                                             <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                                                             <span class="nb">min</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span>
                                                             <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                                             <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span>
                                                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">),</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;narrow_range&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVarsPerChannelGradient&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_FakeQuantWithMinMaxVarsPerChannelGradientOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">FakeQuantWithMinMaxVarsPerChannelGradient</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.FakeQuantWithMinMaxVarsPerChannelGradient&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">fake_quant_with_min_max_vars_per_channel_gradient</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">fake_quant_with_min_max_vars_per_channel_gradient_eager_fallback</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="n">gradients</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">inputs</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="nb">min</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="nb">min</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="nb">max</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="nb">max</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">gradients</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;FakeQuantWithMinMaxVarsPerChannelGradient&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;FakeQuantWithMinMaxVarsPerChannelGradient&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_FakeQuantWithMinMaxVarsPerChannelGradientOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">fill</span><span class="p">(</span><span class="n">dims</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Creates a tensor filled with a scalar value.</span>

<span class="sd">  This operation creates a tensor of shape `dims` and fills it with `value`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # Output tensor has shape [2, 3].</span>
<span class="sd">  fill([2, 3], 9) ==&gt; [[9, 9, 9]</span>
<span class="sd">                       [9, 9, 9]]</span>
<span class="sd">  ```</span>

<span class="sd">  `tf.fill` differs from `tf.constant` in a few ways:</span>

<span class="sd">  *   `tf.fill` only supports scalar contents, whereas `tf.constant` supports</span>
<span class="sd">      Tensor values.</span>
<span class="sd">  *   `tf.fill` creates an Op in the computation graph that constructs the actual</span>
<span class="sd">      Tensor value at runtime. This is in contrast to `tf.constant` which embeds</span>
<span class="sd">      the entire Tensor into the graph with a `Const` node.</span>
<span class="sd">  *   Because `tf.fill` evaluates at graph runtime, it supports dynamic shapes</span>
<span class="sd">      based on other runtime Tensors, unlike `tf.constant`.</span>

<span class="sd">  Args:</span>
<span class="sd">    dims: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      1-D. Represents the shape of the output tensor.</span>
<span class="sd">    value: A `Tensor`. 0-D (scalar). Value to fill the returned tensor.</span>

<span class="sd">      @compatibility(numpy)</span>
<span class="sd">      Equivalent to np.full</span>
<span class="sd">      @end_compatibility</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `value`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Fill&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">dims</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fill_eager_fallback</span><span class="p">(</span>
            <span class="n">dims</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Fill&quot;</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;index_type&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;index_type&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Fill&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Fill</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Fill&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">fill</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">fill_eager_fallback</span><span class="p">(</span><span class="n">dims</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">value</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">value</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_index_type</span><span class="p">,</span> <span class="p">(</span><span class="n">dims</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">dims</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">dims</span><span class="p">,</span> <span class="n">value</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;index_type&quot;</span><span class="p">,</span> <span class="n">_attr_index_type</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Fill&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Fill&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">fingerprint</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Generates fingerprint values.</span>

<span class="sd">  Generates fingerprint values of `data`.</span>

<span class="sd">  Fingerprint op considers the first dimension of `data` as the batch dimension,</span>
<span class="sd">  and `output[i]` contains the fingerprint value generated from contents in</span>
<span class="sd">  `data[i, ...]` for all `i`.</span>

<span class="sd">  Fingerprint op writes fingerprint values as byte arrays. For example, the</span>
<span class="sd">  default method `farmhash64` generates a 64-bit fingerprint value at a time.</span>
<span class="sd">  This 8-byte value is written out as an `uint8` array of size 8, in little-endian</span>
<span class="sd">  order.</span>

<span class="sd">  For example, suppose that `data` has data type `DT_INT32` and shape (2, 3, 4),</span>
<span class="sd">  and that the fingerprint method is `farmhash64`. In this case, the output shape</span>
<span class="sd">  is (2, 8), where 2 is the batch dimension size of `data`, and 8 is the size of</span>
<span class="sd">  each fingerprint value in bytes. `output[0, :]` is generated from 12 integers in</span>
<span class="sd">  `data[0, :, :]` and similarly `output[1, :]` is generated from other 12 integers</span>
<span class="sd">  in `data[1, :, :]`.</span>

<span class="sd">  Note that this op fingerprints the raw underlying buffer, and it does not</span>
<span class="sd">  fingerprint Tensor&#39;s metadata such as data type and/or shape. For example, the</span>
<span class="sd">  fingerprint values are invariant under reshapes and bitcasts as long as the</span>
<span class="sd">  batch dimension remain the same:</span>

<span class="sd">  ```</span>
<span class="sd">  Fingerprint(data) == Fingerprint(Reshape(data, ...))</span>
<span class="sd">  Fingerprint(data) == Fingerprint(Bitcast(data, ...))</span>
<span class="sd">  ```</span>

<span class="sd">  For string data, one should expect `Fingerprint(data) !=</span>
<span class="sd">  Fingerprint(ReduceJoin(data))` in general.</span>

<span class="sd">  Args:</span>
<span class="sd">    data: A `Tensor`. Must have rank 1 or higher.</span>
<span class="sd">    method: A `Tensor` of type `string`.</span>
<span class="sd">      Fingerprint method used by this op. Currently available method is</span>
<span class="sd">      `farmhash::fingerprint64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `uint8`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Fingerprint&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">method</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fingerprint_eager_fallback</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Fingerprint&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Fingerprint&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Fingerprint</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Fingerprint&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">fingerprint</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">fingerprint_eager_fallback</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">data</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">method</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">string</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">method</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Fingerprint&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Fingerprint&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">gather</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">validate_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Gather slices from `params` according to `indices`.</span>

<span class="sd">  `indices` must be an integer tensor of any dimension (usually 0-D or 1-D).</span>
<span class="sd">  Produces an output tensor with shape `indices.shape + params.shape[1:]` where:</span>

<span class="sd">  ```python</span>
<span class="sd">      # Scalar indices</span>
<span class="sd">      output[:, ..., :] = params[indices, :, ... :]</span>

<span class="sd">      # Vector indices</span>
<span class="sd">      output[i, :, ..., :] = params[indices[i], :, ... :]</span>

<span class="sd">      # Higher rank indices</span>
<span class="sd">      output[i, ..., j, :, ... :] = params[indices[i, ..., j], :, ..., :]</span>
<span class="sd">  ```</span>

<span class="sd">  If `indices` is a permutation and `len(indices) == params.shape[0]` then</span>
<span class="sd">  this operation will permute `params` accordingly.</span>

<span class="sd">  `validate_indices`: DEPRECATED. If this operation is assigned to CPU, values in</span>
<span class="sd">  `indices` are always validated to be within range. If assigned to GPU,</span>
<span class="sd">  out-of-bound indices result in safe but unspecified behavior, which may include</span>
<span class="sd">  raising an error.</span>

<span class="sd">  &lt;div style=&quot;width:70%; margin:auto; margin-bottom:10px; margin-top:20px;&quot;&gt;</span>
<span class="sd">  &lt;img style=&quot;width:100%&quot; src=&quot;https://www.tensorflow.org/images/Gather.png&quot; alt&gt;</span>
<span class="sd">  &lt;/div&gt;</span>

<span class="sd">  Args:</span>
<span class="sd">    params: A `Tensor`.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    validate_indices: An optional `bool`. Defaults to `True`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `params`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Gather&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="s2">&quot;validate_indices&quot;</span><span class="p">,</span>
        <span class="n">validate_indices</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gather_eager_fallback</span><span class="p">(</span>
            <span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">validate_indices</span><span class="o">=</span><span class="n">validate_indices</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">validate_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">validate_indices</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">validate_indices</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">validate_indices</span><span class="p">,</span> <span class="s2">&quot;validate_indices&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Gather&quot;</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                  <span class="n">validate_indices</span><span class="o">=</span><span class="n">validate_indices</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;validate_indices&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;validate_indices&quot;</span><span class="p">),</span>
              <span class="s2">&quot;Tparams&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tparams&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Gather&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Gather</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Gather&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">gather</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">gather_eager_fallback</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">validate_indices</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">validate_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">validate_indices</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">validate_indices</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">validate_indices</span><span class="p">,</span> <span class="s2">&quot;validate_indices&quot;</span><span class="p">)</span>
  <span class="n">_attr_Tparams</span><span class="p">,</span> <span class="p">(</span><span class="n">params</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">params</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;validate_indices&quot;</span><span class="p">,</span> <span class="n">validate_indices</span><span class="p">,</span> <span class="s2">&quot;Tparams&quot;</span><span class="p">,</span> <span class="n">_attr_Tparams</span><span class="p">,</span>
  <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Gather&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Gather&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">gather_nd</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Gather slices from `params` into a Tensor with shape specified by `indices`.</span>

<span class="sd">  `indices` is a K-dimensional integer tensor, best thought of as a</span>
<span class="sd">  (K-1)-dimensional tensor of indices into `params`, where each element defines a</span>
<span class="sd">  slice of `params`:</span>

<span class="sd">      output[\\(i_0, ..., i_{K-2}\\)] = params[indices[\\(i_0, ..., i_{K-2}\\)]]</span>

<span class="sd">  Whereas in `tf.gather` `indices` defines slices into the `axis`</span>
<span class="sd">  dimension of `params`, in `tf.gather_nd`, `indices` defines slices into the</span>
<span class="sd">  first `N` dimensions of `params`, where `N = indices.shape[-1]`.</span>

<span class="sd">  The last dimension of `indices` can be at most the rank of</span>
<span class="sd">  `params`:</span>

<span class="sd">      indices.shape[-1] &lt;= params.rank</span>

<span class="sd">  The last dimension of `indices` corresponds to elements</span>
<span class="sd">  (if `indices.shape[-1] == params.rank`) or slices</span>
<span class="sd">  (if `indices.shape[-1] &lt; params.rank`) along dimension `indices.shape[-1]`</span>
<span class="sd">  of `params`.  The output tensor has shape</span>

<span class="sd">      indices.shape[:-1] + params.shape[indices.shape[-1]:]</span>

<span class="sd">  Note that on CPU, if an out of bound index is found, an error is returned.</span>
<span class="sd">  On GPU, if an out of bound index is found, a 0 is stored in the</span>
<span class="sd">  corresponding output value.</span>

<span class="sd">  Some examples below.</span>

<span class="sd">  Simple indexing into a matrix:</span>

<span class="sd">  ```python</span>
<span class="sd">      indices = [[0, 0], [1, 1]]</span>
<span class="sd">      params = [[&#39;a&#39;, &#39;b&#39;], [&#39;c&#39;, &#39;d&#39;]]</span>
<span class="sd">      output = [&#39;a&#39;, &#39;d&#39;]</span>
<span class="sd">  ```</span>

<span class="sd">  Slice indexing into a matrix:</span>

<span class="sd">  ```python</span>
<span class="sd">      indices = [[1], [0]]</span>
<span class="sd">      params = [[&#39;a&#39;, &#39;b&#39;], [&#39;c&#39;, &#39;d&#39;]]</span>
<span class="sd">      output = [[&#39;c&#39;, &#39;d&#39;], [&#39;a&#39;, &#39;b&#39;]]</span>
<span class="sd">  ```</span>

<span class="sd">  Indexing into a 3-tensor:</span>

<span class="sd">  ```python</span>
<span class="sd">      indices = [[1]]</span>
<span class="sd">      params = [[[&#39;a0&#39;, &#39;b0&#39;], [&#39;c0&#39;, &#39;d0&#39;]],</span>
<span class="sd">                [[&#39;a1&#39;, &#39;b1&#39;], [&#39;c1&#39;, &#39;d1&#39;]]]</span>
<span class="sd">      output = [[[&#39;a1&#39;, &#39;b1&#39;], [&#39;c1&#39;, &#39;d1&#39;]]]</span>


<span class="sd">      indices = [[0, 1], [1, 0]]</span>
<span class="sd">      params = [[[&#39;a0&#39;, &#39;b0&#39;], [&#39;c0&#39;, &#39;d0&#39;]],</span>
<span class="sd">                [[&#39;a1&#39;, &#39;b1&#39;], [&#39;c1&#39;, &#39;d1&#39;]]]</span>
<span class="sd">      output = [[&#39;c0&#39;, &#39;d0&#39;], [&#39;a1&#39;, &#39;b1&#39;]]</span>


<span class="sd">      indices = [[0, 0, 1], [1, 0, 1]]</span>
<span class="sd">      params = [[[&#39;a0&#39;, &#39;b0&#39;], [&#39;c0&#39;, &#39;d0&#39;]],</span>
<span class="sd">                [[&#39;a1&#39;, &#39;b1&#39;], [&#39;c1&#39;, &#39;d1&#39;]]]</span>
<span class="sd">      output = [&#39;b0&#39;, &#39;b1&#39;]</span>
<span class="sd">  ```</span>

<span class="sd">  Batched indexing into a matrix:</span>

<span class="sd">  ```python</span>
<span class="sd">      indices = [[[0, 0]], [[0, 1]]]</span>
<span class="sd">      params = [[&#39;a&#39;, &#39;b&#39;], [&#39;c&#39;, &#39;d&#39;]]</span>
<span class="sd">      output = [[&#39;a&#39;], [&#39;b&#39;]]</span>
<span class="sd">  ```</span>

<span class="sd">  Batched slice indexing into a matrix:</span>

<span class="sd">  ```python</span>
<span class="sd">      indices = [[[1]], [[0]]]</span>
<span class="sd">      params = [[&#39;a&#39;, &#39;b&#39;], [&#39;c&#39;, &#39;d&#39;]]</span>
<span class="sd">      output = [[[&#39;c&#39;, &#39;d&#39;]], [[&#39;a&#39;, &#39;b&#39;]]]</span>
<span class="sd">  ```</span>

<span class="sd">  Batched indexing into a 3-tensor:</span>

<span class="sd">  ```python</span>
<span class="sd">      indices = [[[1]], [[0]]]</span>
<span class="sd">      params = [[[&#39;a0&#39;, &#39;b0&#39;], [&#39;c0&#39;, &#39;d0&#39;]],</span>
<span class="sd">                [[&#39;a1&#39;, &#39;b1&#39;], [&#39;c1&#39;, &#39;d1&#39;]]]</span>
<span class="sd">      output = [[[[&#39;a1&#39;, &#39;b1&#39;], [&#39;c1&#39;, &#39;d1&#39;]]],</span>
<span class="sd">                [[[&#39;a0&#39;, &#39;b0&#39;], [&#39;c0&#39;, &#39;d0&#39;]]]]</span>

<span class="sd">      indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]]</span>
<span class="sd">      params = [[[&#39;a0&#39;, &#39;b0&#39;], [&#39;c0&#39;, &#39;d0&#39;]],</span>
<span class="sd">                [[&#39;a1&#39;, &#39;b1&#39;], [&#39;c1&#39;, &#39;d1&#39;]]]</span>
<span class="sd">      output = [[[&#39;c0&#39;, &#39;d0&#39;], [&#39;a1&#39;, &#39;b1&#39;]],</span>
<span class="sd">                [[&#39;a0&#39;, &#39;b0&#39;], [&#39;c1&#39;, &#39;d1&#39;]]]</span>


<span class="sd">      indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]]</span>
<span class="sd">      params = [[[&#39;a0&#39;, &#39;b0&#39;], [&#39;c0&#39;, &#39;d0&#39;]],</span>
<span class="sd">                [[&#39;a1&#39;, &#39;b1&#39;], [&#39;c1&#39;, &#39;d1&#39;]]]</span>
<span class="sd">      output = [[&#39;b0&#39;, &#39;b1&#39;], [&#39;d0&#39;, &#39;c1&#39;]]</span>
<span class="sd">  ```</span>

<span class="sd">  See also `tf.gather` and `tf.batch_gather`.</span>

<span class="sd">  Args:</span>
<span class="sd">    params: A `Tensor`. The tensor from which to gather values.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      Index tensor.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `params`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;GatherNd&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gather_nd_eager_fallback</span><span class="p">(</span>
            <span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;GatherNd&quot;</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Tparams&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tparams&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;GatherNd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">GatherNd</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.GatherNd&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">gather_nd</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">gather_nd_eager_fallback</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_Tparams</span><span class="p">,</span> <span class="p">(</span><span class="n">params</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">params</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Tparams&quot;</span><span class="p">,</span> <span class="n">_attr_Tparams</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;GatherNd&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;GatherNd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">gather_v2</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">batch_dims</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Gather slices from `params` axis `axis` according to `indices`.</span>

<span class="sd">  `indices` must be an integer tensor of any dimension (usually 0-D or 1-D).</span>
<span class="sd">  Produces an output tensor with shape `params.shape[:axis] + indices.shape +</span>
<span class="sd">  params.shape[axis + 1:]` where:</span>

<span class="sd">  ```python</span>
<span class="sd">      # Scalar indices (output is rank(params) - 1).</span>
<span class="sd">      output[a_0, ..., a_n, b_0, ..., b_n] =</span>
<span class="sd">        params[a_0, ..., a_n, indices, b_0, ..., b_n]</span>

<span class="sd">      # Vector indices (output is rank(params)).</span>
<span class="sd">      output[a_0, ..., a_n, i, b_0, ..., b_n] =</span>
<span class="sd">        params[a_0, ..., a_n, indices[i], b_0, ..., b_n]</span>

<span class="sd">      # Higher rank indices (output is rank(params) + rank(indices) - 1).</span>
<span class="sd">      output[a_0, ..., a_n, i, ..., j, b_0, ... b_n] =</span>
<span class="sd">        params[a_0, ..., a_n, indices[i, ..., j], b_0, ..., b_n]</span>
<span class="sd">  ```</span>

<span class="sd">  &lt;div style=&quot;width:70%; margin:auto; margin-bottom:10px; margin-top:20px;&quot;&gt;</span>
<span class="sd">  &lt;img style=&quot;width:100%&quot; src=&quot;https://www.tensorflow.org/images/Gather.png&quot; alt&gt;</span>
<span class="sd">  &lt;/div&gt;</span>

<span class="sd">  Note that on CPU, if an out of bound index is found, an error is returned.</span>
<span class="sd">  On GPU, if an out of bound index is found, a 0 is stored in the</span>
<span class="sd">  corresponding output value.</span>

<span class="sd">  See also `tf.batch_gather` and `tf.gather_nd`.</span>

<span class="sd">  Args:</span>
<span class="sd">    params: A `Tensor`.</span>
<span class="sd">      The tensor from which to gather values. Must be at least rank</span>
<span class="sd">      `axis + 1`.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      Index tensor. Must be in range `[0, params.shape[axis])`.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      The axis in `params` to gather `indices` from. Defaults to the first</span>
<span class="sd">      dimension. Supports negative indexes.</span>
<span class="sd">    batch_dims: An optional `int`. Defaults to `0`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `params`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;GatherV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;batch_dims&quot;</span><span class="p">,</span> <span class="n">batch_dims</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gather_v2_eager_fallback</span><span class="p">(</span>
            <span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">batch_dims</span><span class="o">=</span><span class="n">batch_dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">batch_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">batch_dims</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">batch_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">,</span> <span class="s2">&quot;batch_dims&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;GatherV2&quot;</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
                    <span class="n">batch_dims</span><span class="o">=</span><span class="n">batch_dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;batch_dims&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;batch_dims&quot;</span><span class="p">),</span> <span class="s2">&quot;Tparams&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tparams&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">),</span> <span class="s2">&quot;Taxis&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Taxis&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;GatherV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">GatherV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.GatherV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">gather_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">gather_v2_eager_fallback</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">batch_dims</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">batch_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">batch_dims</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">batch_dims</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">batch_dims</span><span class="p">,</span> <span class="s2">&quot;batch_dims&quot;</span><span class="p">)</span>
  <span class="n">_attr_Tparams</span><span class="p">,</span> <span class="p">(</span><span class="n">params</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">params</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Taxis</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">params</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;batch_dims&quot;</span><span class="p">,</span> <span class="n">batch_dims</span><span class="p">,</span> <span class="s2">&quot;Tparams&quot;</span><span class="p">,</span> <span class="n">_attr_Tparams</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="s2">&quot;Taxis&quot;</span><span class="p">,</span> <span class="n">_attr_Taxis</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;GatherV2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;GatherV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="guarantee_const"><a class="viewcode-back" href="../../../../index.html#tensorflow.guarantee_const">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;guarantee_const&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">guarantee_const</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Gives a guarantee to the TF runtime that the input tensor is a constant.</span>

<span class="sd">  The runtime is then free to make optimizations based on this.</span>

<span class="sd">  Only accepts value typed tensors as inputs and rejects resource variable handles</span>
<span class="sd">  as input.</span>

<span class="sd">  Returns the input tensor without modification.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;GuaranteeConst&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">guarantee_const_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">guarantee_const</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;GuaranteeConst&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">guarantee_const</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;GuaranteeConst&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">GuaranteeConst</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.GuaranteeConst&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">guarantee_const</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">guarantee_const_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;GuaranteeConst&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;GuaranteeConst&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">identity</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return a tensor with the same shape and contents as the input tensor or value.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Identity&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">identity_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Identity&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Identity&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Identity</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Identity&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">identity</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">identity_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Identity&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Identity&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="identity_n"><a class="viewcode-back" href="../../../../index.html#tensorflow.identity_n">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;identity_n&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">identity_n</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns a list of tensors with the same shapes and contents as the input</span>

<span class="sd">  tensors.</span>

<span class="sd">  This op can be used to override the gradient for complicated functions. For</span>
<span class="sd">  example, suppose y = f(x) and we wish to apply a custom function g for backprop</span>
<span class="sd">  such that dx = g(dy). In Python,</span>

<span class="sd">  ```python</span>
<span class="sd">  with tf.get_default_graph().gradient_override_map(</span>
<span class="sd">      {&#39;IdentityN&#39;: &#39;OverrideGradientWithG&#39;}):</span>
<span class="sd">    y, _ = identity_n([f(x), x])</span>

<span class="sd">  @tf.RegisterGradient(&#39;OverrideGradientWithG&#39;)</span>
<span class="sd">  def ApplyG(op, dy, _):</span>
<span class="sd">    return [None, g(dy)]  # Do not backprop to f(x).</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A list of `Tensor` objects.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A list of `Tensor` objects. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;IdentityN&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">identity_n_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">identity_n</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;IdentityN&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">identity_n</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;IdentityN&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">IdentityN</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.IdentityN&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">identity_n</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">identity_n_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">convert_to_mixed_eager_tensors</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;IdentityN&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;IdentityN&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">immutable_const</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">memory_region_name</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns immutable tensor from memory region.</span>

<span class="sd">  The current implementation memmaps the tensor from a file.</span>

<span class="sd">  Args:</span>
<span class="sd">    dtype: A `tf.DType`. Type of the returned tensor.</span>
<span class="sd">    shape: A `tf.TensorShape` or list of `ints`. Shape of the returned tensor.</span>
<span class="sd">    memory_region_name: A `string`.</span>
<span class="sd">      Name of readonly memory region used by the tensor, see</span>
<span class="sd">      NewReadOnlyMemoryRegionFromFile in tensorflow::Env.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `dtype`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ImmutableConst&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span>
        <span class="s2">&quot;memory_region_name&quot;</span><span class="p">,</span> <span class="n">memory_region_name</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">immutable_const_eager_fallback</span><span class="p">(</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">memory_region_name</span><span class="o">=</span><span class="n">memory_region_name</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span>
  <span class="n">memory_region_name</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">memory_region_name</span><span class="p">,</span> <span class="s2">&quot;memory_region_name&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ImmutableConst&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
                          <span class="n">memory_region_name</span><span class="o">=</span><span class="n">memory_region_name</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">),</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">),</span> <span class="s2">&quot;memory_region_name&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;memory_region_name&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ImmutableConst&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ImmutableConst</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ImmutableConst&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">immutable_const</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">immutable_const_eager_fallback</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">memory_region_name</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span>
  <span class="n">memory_region_name</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">memory_region_name</span><span class="p">,</span> <span class="s2">&quot;memory_region_name&quot;</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;memory_region_name&quot;</span><span class="p">,</span>
  <span class="n">memory_region_name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ImmutableConst&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ImmutableConst&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">inplace_add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;    Adds v into specified rows of x.</span>

<span class="sd">    Computes y = x; y[i, :] += v; return y.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. A `Tensor` of type T.</span>
<span class="sd">    i: A `Tensor` of type `int32`.</span>
<span class="sd">      A vector. Indices into the left-most dimension of `x`.</span>
<span class="sd">    v: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">      A `Tensor` of type T. Same dimension sizes as x except the first dimension, which must be the same as i&#39;s size.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;InplaceAdd&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">inplace_add_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;InplaceAdd&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">v</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;InplaceAdd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">InplaceAdd</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.InplaceAdd&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">inplace_add</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">inplace_add_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">i</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;InplaceAdd&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;InplaceAdd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">inplace_sub</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;    Subtracts `v` into specified rows of `x`.</span>

<span class="sd">    Computes y = x; y[i, :] -= v; return y.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. A `Tensor` of type T.</span>
<span class="sd">    i: A `Tensor` of type `int32`.</span>
<span class="sd">      A vector. Indices into the left-most dimension of `x`.</span>
<span class="sd">    v: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">      A `Tensor` of type T. Same dimension sizes as x except the first dimension, which must be the same as i&#39;s size.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;InplaceSub&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">inplace_sub_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;InplaceSub&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">v</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;InplaceSub&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">InplaceSub</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.InplaceSub&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">inplace_sub</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">inplace_sub_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">i</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;InplaceSub&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;InplaceSub&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">inplace_update</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;    Updates specified rows with values in `v`.</span>

<span class="sd">    Computes `x[i, :] = v; return x`.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. A tensor of type `T`.</span>
<span class="sd">    i: A `Tensor` of type `int32`.</span>
<span class="sd">      A vector. Indices into the left-most dimension of `x`.</span>
<span class="sd">    v: A `Tensor`. Must have the same type as `x`.</span>
<span class="sd">      A `Tensor` of type T. Same dimension sizes as x except the first dimension, which must be the same as i&#39;s size.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;InplaceUpdate&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">inplace_update_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;InplaceUpdate&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">v</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;InplaceUpdate&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">InplaceUpdate</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.InplaceUpdate&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">inplace_update</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">inplace_update_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">i</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;InplaceUpdate&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;InplaceUpdate&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;math.invert_permutation&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math.invert_permutation&#39;</span><span class="p">,</span> <span class="s1">&#39;invert_permutation&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;invert_permutation&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">invert_permutation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the inverse permutation of a tensor.</span>

<span class="sd">  This operation computes the inverse of an index permutation. It takes a 1-D</span>
<span class="sd">  integer tensor `x`, which represents the indices of a zero-based array, and</span>
<span class="sd">  swaps each value with its index position. In other words, for an output tensor</span>
<span class="sd">  `y` and an input tensor `x`, this operation computes the following:</span>

<span class="sd">  `y[x[i]] = i for i in [0, 1, ..., len(x) - 1]`</span>

<span class="sd">  The values must include 0. There can be no duplicate values or negative values.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor `x` is [3, 4, 0, 2, 1]</span>
<span class="sd">  invert_permutation(x) ==&gt; [2, 4, 3, 0, 1]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `int32`, `int64`. 1-D.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;InvertPermutation&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">invert_permutation_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">invert_permutation</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;InvertPermutation&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">invert_permutation</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;InvertPermutation&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">InvertPermutation</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.InvertPermutation&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">invert_permutation</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">invert_permutation_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;InvertPermutation&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;InvertPermutation&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_ListDiffOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;ListDiff&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;out&quot;</span><span class="p">,</span> <span class="s2">&quot;idx&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">list_diff</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the difference between two lists of numbers or strings.</span>

<span class="sd">  Given a list `x` and a list `y`, this operation returns a list `out` that</span>
<span class="sd">  represents all values that are in `x` but not in `y`. The returned list `out`</span>
<span class="sd">  is sorted in the same order that the numbers appear in `x` (duplicates are</span>
<span class="sd">  preserved). This operation also returns a list `idx` that represents the</span>
<span class="sd">  position of each `out` element in `x`. In other words:</span>

<span class="sd">  `out[i] = x[idx[i]] for i in [0, 1, ..., len(out) - 1]`</span>

<span class="sd">  For example, given this input:</span>

<span class="sd">  ```</span>
<span class="sd">  x = [1, 2, 3, 4, 5, 6]</span>
<span class="sd">  y = [1, 3, 5]</span>
<span class="sd">  ```</span>

<span class="sd">  This operation would return:</span>

<span class="sd">  ```</span>
<span class="sd">  out ==&gt; [2, 4, 6]</span>
<span class="sd">  idx ==&gt; [1, 3, 5]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. 1-D. Values to keep.</span>
<span class="sd">    y: A `Tensor`. Must have the same type as `x`. 1-D. Values to remove.</span>
<span class="sd">    out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (out, idx).</span>

<span class="sd">    out: A `Tensor`. Has the same type as `x`.</span>
<span class="sd">    idx: A `Tensor` of type `out_idx`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ListDiff&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_ListDiffOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">list_diff_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">out_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_idx</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ListDiff&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;out_idx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ListDiff&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_ListDiffOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ListDiff</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ListDiff&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">list_diff</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">list_diff_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">out_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_idx</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ListDiff&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ListDiff&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_ListDiffOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">lower_bound</span><span class="p">(</span><span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Applies lower_bound(sorted_search_values, values) along each row.</span>

<span class="sd">  Each set of rows with the same index in (sorted_inputs, values) is treated</span>
<span class="sd">  independently.  The resulting row is the equivalent of calling</span>
<span class="sd">  `np.searchsorted(sorted_inputs, values, side=&#39;left&#39;)`.</span>

<span class="sd">  The result is not a global index to the entire</span>
<span class="sd">  `Tensor`, but rather just the index in the last dimension.</span>

<span class="sd">  A 2-D example:</span>
<span class="sd">    sorted_sequence = [[0, 3, 9, 9, 10],</span>
<span class="sd">                       [1, 2, 3, 4, 5]]</span>
<span class="sd">    values = [[2, 4, 9],</span>
<span class="sd">              [0, 2, 6]]</span>

<span class="sd">    result = LowerBound(sorted_sequence, values)</span>

<span class="sd">    result == [[1, 2, 2],</span>
<span class="sd">               [0, 1, 5]]</span>

<span class="sd">  Args:</span>
<span class="sd">    sorted_inputs: A `Tensor`. 2-D Tensor where each row is ordered.</span>
<span class="sd">    values: A `Tensor`. Must have the same type as `sorted_inputs`.</span>
<span class="sd">      2-D Tensor with the same numbers of rows as `sorted_search_values`. Contains</span>
<span class="sd">      the values that will be searched for in `sorted_search_values`.</span>
<span class="sd">    out_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `out_type`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;LowerBound&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">lower_bound_eager_fallback</span><span class="p">(</span>
            <span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">out_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;LowerBound&quot;</span><span class="p">,</span> <span class="n">sorted_inputs</span><span class="o">=</span><span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span>
                      <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;out_type&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;LowerBound&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">LowerBound</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.LowerBound&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">lower_bound</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">lower_bound_eager_fallback</span><span class="p">(</span><span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">out_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;LowerBound&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;LowerBound&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;linalg.band_part&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;linalg.band_part&#39;</span><span class="p">,</span> <span class="s1">&#39;matrix_band_part&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;matrix_band_part&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">matrix_band_part</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">num_lower</span><span class="p">,</span> <span class="n">num_upper</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Copy a tensor setting everything outside a central band in each innermost matrix</span>

<span class="sd">  to zero.</span>

<span class="sd">  The `band` part is computed as follows:</span>
<span class="sd">  Assume `input` has `k` dimensions `[I, J, K, ..., M, N]`, then the output is a</span>
<span class="sd">  tensor with the same shape where</span>

<span class="sd">  `band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]`.</span>

<span class="sd">  The indicator function</span>

<span class="sd">  `in_band(m, n) = (num_lower &lt; 0 || (m-n) &lt;= num_lower)) &amp;&amp;</span>
<span class="sd">                   (num_upper &lt; 0 || (n-m) &lt;= num_upper)`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # if &#39;input&#39; is [[ 0,  1,  2, 3]</span>
<span class="sd">                   [-1,  0,  1, 2]</span>
<span class="sd">                   [-2, -1,  0, 1]</span>
<span class="sd">                   [-3, -2, -1, 0]],</span>

<span class="sd">  tf.matrix_band_part(input, 1, -1) ==&gt; [[ 0,  1,  2, 3]</span>
<span class="sd">                                         [-1,  0,  1, 2]</span>
<span class="sd">                                         [ 0, -1,  0, 1]</span>
<span class="sd">                                         [ 0,  0, -1, 0]],</span>

<span class="sd">  tf.matrix_band_part(input, 2, 1) ==&gt; [[ 0,  1,  0, 0]</span>
<span class="sd">                                        [-1,  0,  1, 0]</span>
<span class="sd">                                        [-2, -1,  0, 1]</span>
<span class="sd">                                        [ 0, -2, -1, 0]]</span>
<span class="sd">  ```</span>

<span class="sd">  Useful special cases:</span>

<span class="sd">  ```</span>
<span class="sd">   tf.matrix_band_part(input, 0, -1) ==&gt; Upper triangular part.</span>
<span class="sd">   tf.matrix_band_part(input, -1, 0) ==&gt; Lower triangular part.</span>
<span class="sd">   tf.matrix_band_part(input, 0, 0) ==&gt; Diagonal.</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Rank `k` tensor.</span>
<span class="sd">    num_lower: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      0-D tensor. Number of subdiagonals to keep. If negative, keep entire</span>
<span class="sd">      lower triangle.</span>
<span class="sd">    num_upper: A `Tensor`. Must have the same type as `num_lower`.</span>
<span class="sd">      0-D tensor. Number of superdiagonals to keep. If negative, keep</span>
<span class="sd">      entire upper triangle.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;MatrixBandPart&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">num_lower</span><span class="p">,</span> <span class="n">num_upper</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">matrix_band_part_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">num_lower</span><span class="p">,</span> <span class="n">num_upper</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">matrix_band_part</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">num_lower</span><span class="o">=</span><span class="n">num_lower</span><span class="p">,</span>
                                <span class="n">num_upper</span><span class="o">=</span><span class="n">num_upper</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;MatrixBandPart&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">num_lower</span><span class="o">=</span><span class="n">num_lower</span><span class="p">,</span>
                          <span class="n">num_upper</span><span class="o">=</span><span class="n">num_upper</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">matrix_band_part</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">num_lower</span><span class="o">=</span><span class="n">num_lower</span><span class="p">,</span>
                            <span class="n">num_upper</span><span class="o">=</span><span class="n">num_upper</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindex&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindex&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixBandPart&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">MatrixBandPart</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.MatrixBandPart&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">matrix_band_part</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">matrix_band_part_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">num_lower</span><span class="p">,</span> <span class="n">num_upper</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tindex</span><span class="p">,</span> <span class="n">_inputs_Tindex</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">num_lower</span><span class="p">,</span> <span class="n">num_upper</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="p">(</span><span class="n">num_lower</span><span class="p">,</span> <span class="n">num_upper</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_Tindex</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">num_lower</span><span class="p">,</span> <span class="n">num_upper</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindex&quot;</span><span class="p">,</span> <span class="n">_attr_Tindex</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;MatrixBandPart&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixBandPart&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">matrix_diag</span><span class="p">(</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns a batched diagonal tensor with a given batched diagonal values.</span>

<span class="sd">  Given a `diagonal`, this operation returns a tensor with the `diagonal` and</span>
<span class="sd">  everything else padded with zeros. The diagonal is computed as follows:</span>

<span class="sd">  Assume `diagonal` has `k` dimensions `[I, J, K, ..., N]`, then the output is a</span>
<span class="sd">  tensor of rank `k+1` with dimensions [I, J, K, ..., N, N]` where:</span>

<span class="sd">  `output[i, j, k, ..., m, n] = 1{m=n} * diagonal[i, j, k, ..., n]`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;diagonal&#39; is [[1, 2, 3, 4], [5, 6, 7, 8]]</span>

<span class="sd">  and diagonal.shape = (2, 4)</span>

<span class="sd">  tf.matrix_diag(diagonal) ==&gt; [[[1, 0, 0, 0]</span>
<span class="sd">                                       [0, 2, 0, 0]</span>
<span class="sd">                                       [0, 0, 3, 0]</span>
<span class="sd">                                       [0, 0, 0, 4]],</span>
<span class="sd">                                      [[5, 0, 0, 0]</span>
<span class="sd">                                       [0, 6, 0, 0]</span>
<span class="sd">                                       [0, 0, 7, 0]</span>
<span class="sd">                                       [0, 0, 0, 8]]]</span>

<span class="sd">  which has shape (2, 4, 4)</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    diagonal: A `Tensor`. Rank `k`, where `k &gt;= 1`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `diagonal`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;MatrixDiag&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">matrix_diag_eager_fallback</span><span class="p">(</span>
            <span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiag&quot;</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiag&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">MatrixDiag</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.MatrixDiag&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">matrix_diag</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">matrix_diag_eager_fallback</span><span class="p">(</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">diagonal</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">diagonal</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">diagonal</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;MatrixDiag&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiag&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">matrix_diag_part</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the batched diagonal part of a batched tensor.</span>

<span class="sd">  This operation returns a tensor with the `diagonal` part</span>
<span class="sd">  of the batched `input`. The `diagonal` part is computed as follows:</span>

<span class="sd">  Assume `input` has `k` dimensions `[I, J, K, ..., M, N]`, then the output is a</span>
<span class="sd">  tensor of rank `k - 1` with dimensions `[I, J, K, ..., min(M, N)]` where:</span>

<span class="sd">  `diagonal[i, j, k, ..., n] = input[i, j, k, ..., n, n]`.</span>

<span class="sd">  The input must be at least a matrix.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;input&#39; is [[[1, 0, 0, 0]</span>
<span class="sd">                 [0, 2, 0, 0]</span>
<span class="sd">                 [0, 0, 3, 0]</span>
<span class="sd">                 [0, 0, 0, 4]],</span>
<span class="sd">                [[5, 0, 0, 0]</span>
<span class="sd">                 [0, 6, 0, 0]</span>
<span class="sd">                 [0, 0, 7, 0]</span>
<span class="sd">                 [0, 0, 0, 8]]]</span>

<span class="sd">  and input.shape = (2, 4, 4)</span>

<span class="sd">  tf.matrix_diag_part(input) ==&gt; [[1, 2, 3, 4], [5, 6, 7, 8]]</span>

<span class="sd">  which has shape (2, 4)</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Rank `k` tensor where `k &gt;= 2`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;MatrixDiagPart&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">matrix_diag_part_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagPart&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagPart&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">MatrixDiagPart</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.MatrixDiagPart&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">matrix_diag_part</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">matrix_diag_part_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;MatrixDiagPart&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagPart&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">matrix_diag_part_v2</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the batched diagonal part of a batched tensor.</span>

<span class="sd">  Returns a tensor with the `k[0]`-th to `k[1]`-th diagonals of the batched</span>
<span class="sd">  `input`.</span>

<span class="sd">  Assume `input` has `r` dimensions `[I, J, ..., L, M, N]`.</span>
<span class="sd">  Let `max_diag_len` be the maximum length among all diagonals to be extracted,</span>
<span class="sd">  `max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))`</span>
<span class="sd">  Let `num_diags` be the number of diagonals to extract,</span>
<span class="sd">  `num_diags = k[1] - k[0] + 1`.</span>

<span class="sd">  If `num_diags == 1`, the output tensor is of rank `r - 1` with shape</span>
<span class="sd">  `[I, J, ..., L, max_diag_len]` and values:</span>

<span class="sd">  ```</span>
<span class="sd">  diagonal[i, j, ..., l, n]</span>
<span class="sd">    = input[i, j, ..., l, n+y, n+x] ; if 0 &lt;= n+y &lt; M and 0 &lt;= n+x &lt; N,</span>
<span class="sd">      padding_value                 ; otherwise.</span>
<span class="sd">  ```</span>
<span class="sd">  where `y = max(-k[1], 0)`, `x = max(k[1], 0)`.</span>

<span class="sd">  Otherwise, the output tensor has rank `r` with dimensions</span>
<span class="sd">  `[I, J, ..., L, num_diags, max_diag_len]` with values:</span>

<span class="sd">  ```</span>
<span class="sd">  diagonal[i, j, ..., l, m, n]</span>
<span class="sd">    = input[i, j, ..., l, n+y, n+x] ; if 0 &lt;= n+y &lt; M and 0 &lt;= n+x &lt; N,</span>
<span class="sd">      padding_value                 ; otherwise.</span>
<span class="sd">  ```</span>
<span class="sd">  where `d = k[1] - m`, `y = max(-d, 0)`, and `x = max(d, 0)`.</span>

<span class="sd">  The input must be at least a matrix.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  input = np.array([[[1, 2, 3, 4],  # Input shape: (2, 3, 4)</span>
<span class="sd">                     [5, 6, 7, 8],</span>
<span class="sd">                     [9, 8, 7, 6]],</span>
<span class="sd">                    [[5, 4, 3, 2],</span>
<span class="sd">                     [1, 2, 3, 4],</span>
<span class="sd">                     [5, 6, 7, 8]]])</span>

<span class="sd">  # A main diagonal from each batch.</span>
<span class="sd">  tf.matrix_diag_part(input) ==&gt; [[1, 6, 7],  # Output shape: (2, 3)</span>
<span class="sd">                                  [5, 2, 7]]</span>

<span class="sd">  # A superdiagonal from each batch.</span>
<span class="sd">  tf.matrix_diag_part(input, k = 1)</span>
<span class="sd">    ==&gt; [[2, 7, 6],  # Output shape: (2, 3)</span>
<span class="sd">         [4, 3, 8]]</span>

<span class="sd">  # A tridiagonal band from each batch.</span>
<span class="sd">  tf.matrix_diag_part(input, k = (-1, 1))</span>
<span class="sd">    ==&gt; [[[2, 7, 6],  # Output shape: (2, 3, 3)</span>
<span class="sd">          [1, 6, 7],</span>
<span class="sd">          [5, 8, 0]],</span>
<span class="sd">         [[4, 3, 8],</span>
<span class="sd">          [5, 2, 7],</span>
<span class="sd">          [1, 6, 0]]]</span>

<span class="sd">  # Padding value = 9</span>
<span class="sd">  tf.matrix_diag_part(input, k = (1, 3), padding_value = 9)</span>
<span class="sd">    ==&gt; [[[4, 9, 9],  # Output shape: (2, 3, 3)</span>
<span class="sd">          [3, 8, 9],</span>
<span class="sd">          [2, 7, 6]],</span>
<span class="sd">         [[2, 9, 9],</span>
<span class="sd">          [3, 4, 9],</span>
<span class="sd">          [4, 3, 8]]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Rank `r` tensor where `r &gt;= 2`.</span>
<span class="sd">    k: A `Tensor` of type `int32`.</span>
<span class="sd">      Diagonal offset(s). Positive value means superdiagonal, 0 refers to the main</span>
<span class="sd">      diagonal, and negative value means subdiagonals. `k` can be a single integer</span>
<span class="sd">      (for a single diagonal) or a pair of integers specifying the low and high ends</span>
<span class="sd">      of a matrix band. `k[0]` must not be larger than `k[1]`.</span>
<span class="sd">    padding_value: A `Tensor`. Must have the same type as `input`.</span>
<span class="sd">      The value to fill the area outside the specified diagonal band with.</span>
<span class="sd">      Default is 0.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;MatrixDiagPartV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">matrix_diag_part_v2_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagPartV2&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=</span><span class="n">padding_value</span><span class="p">,</span>
                            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagPartV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">MatrixDiagPartV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.MatrixDiagPartV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">matrix_diag_part_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">matrix_diag_part_v2_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;MatrixDiagPartV2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagPartV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">matrix_diag_part_v3</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s2">&quot;RIGHT_LEFT&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the batched diagonal part of a batched tensor.</span>

<span class="sd">  Returns a tensor with the `k[0]`-th to `k[1]`-th diagonals of the batched</span>
<span class="sd">  `input`.</span>

<span class="sd">  Assume `input` has `r` dimensions `[I, J, ..., L, M, N]`.</span>
<span class="sd">  Let `max_diag_len` be the maximum length among all diagonals to be extracted,</span>
<span class="sd">  `max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))`</span>
<span class="sd">  Let `num_diags` be the number of diagonals to extract,</span>
<span class="sd">  `num_diags = k[1] - k[0] + 1`.</span>

<span class="sd">  If `num_diags == 1`, the output tensor is of rank `r - 1` with shape</span>
<span class="sd">  `[I, J, ..., L, max_diag_len]` and values:</span>

<span class="sd">  ```</span>
<span class="sd">  diagonal[i, j, ..., l, n]</span>
<span class="sd">    = input[i, j, ..., l, n+y, n+x] ; if 0 &lt;= n+y &lt; M and 0 &lt;= n+x &lt; N,</span>
<span class="sd">      padding_value                 ; otherwise.</span>
<span class="sd">  ```</span>
<span class="sd">  where `y = max(-k[1], 0)`, `x = max(k[1], 0)`.</span>

<span class="sd">  Otherwise, the output tensor has rank `r` with dimensions</span>
<span class="sd">  `[I, J, ..., L, num_diags, max_diag_len]` with values:</span>

<span class="sd">  ```</span>
<span class="sd">  diagonal[i, j, ..., l, m, n]</span>
<span class="sd">    = input[i, j, ..., l, n+y, n+x] ; if 0 &lt;= n+y &lt; M and 0 &lt;= n+x &lt; N,</span>
<span class="sd">      padding_value                 ; otherwise.</span>
<span class="sd">  ```</span>
<span class="sd">  where `d = k[1] - m`, `y = max(-d, 0) - offset`, and `x = max(d, 0) - offset`.</span>

<span class="sd">  `offset` is zero except when the alignment of the diagonal is to the right.</span>
<span class="sd">  ```</span>
<span class="sd">  offset = max_diag_len - diag_len(d) ; if (`align` in {RIGHT_LEFT, RIGHT_RIGHT}</span>
<span class="sd">                                             and `d &gt;= 0`) or</span>
<span class="sd">                                           (`align` in {LEFT_RIGHT, RIGHT_RIGHT}</span>
<span class="sd">                                             and `d &lt;= 0`)</span>
<span class="sd">           0                          ; otherwise</span>
<span class="sd">  ```</span>
<span class="sd">  where `diag_len(d) = min(cols - max(d, 0), rows + min(d, 0))`.</span>

<span class="sd">  The input must be at least a matrix.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  input = np.array([[[1, 2, 3, 4],  # Input shape: (2, 3, 4)</span>
<span class="sd">                     [5, 6, 7, 8],</span>
<span class="sd">                     [9, 8, 7, 6]],</span>
<span class="sd">                    [[5, 4, 3, 2],</span>
<span class="sd">                     [1, 2, 3, 4],</span>
<span class="sd">                     [5, 6, 7, 8]]])</span>

<span class="sd">  # A main diagonal from each batch.</span>
<span class="sd">  tf.matrix_diag_part(input) ==&gt; [[1, 6, 7],  # Output shape: (2, 3)</span>
<span class="sd">                                  [5, 2, 7]]</span>

<span class="sd">  # A superdiagonal from each batch.</span>
<span class="sd">  tf.matrix_diag_part(input, k = 1)</span>
<span class="sd">    ==&gt; [[2, 7, 6],  # Output shape: (2, 3)</span>
<span class="sd">         [4, 3, 8]]</span>

<span class="sd">  # A band from each batch.</span>
<span class="sd">  tf.matrix_diag_part(input, k = (-1, 2))</span>
<span class="sd">    ==&gt; [[[0, 3, 8],  # Output shape: (2, 4, 3)</span>
<span class="sd">          [2, 7, 6],</span>
<span class="sd">          [1, 6, 7],</span>
<span class="sd">          [5, 8, 0]],</span>
<span class="sd">         [[0, 3, 4],</span>
<span class="sd">          [4, 3, 8],</span>
<span class="sd">          [5, 2, 7],</span>
<span class="sd">          [1, 6, 0]]]</span>

<span class="sd">  # LEFT_RIGHT alignment.</span>
<span class="sd">  tf.matrix_diag_part(input, k = (-1, 2), align=&quot;LEFT_RIGHT&quot;)</span>
<span class="sd">    ==&gt; [[[3, 8, 0],  # Output shape: (2, 4, 3)</span>
<span class="sd">          [2, 7, 6],</span>
<span class="sd">          [1, 6, 7],</span>
<span class="sd">          [0, 5, 8]],</span>
<span class="sd">         [[3, 4, 0],</span>
<span class="sd">          [4, 3, 8],</span>
<span class="sd">          [5, 2, 7],</span>
<span class="sd">          [0, 1, 6]]]</span>

<span class="sd">  # max_diag_len can be shorter than the main diagonal.</span>
<span class="sd">  tf.matrix_diag_part(input, k = (-2, -1))</span>
<span class="sd">    ==&gt; [[[5, 8],</span>
<span class="sd">          [9, 0]],</span>
<span class="sd">         [[1, 6],</span>
<span class="sd">          [5, 0]]]</span>

<span class="sd">  # padding_value = 9</span>
<span class="sd">  tf.matrix_diag_part(input, k = (1, 3), padding_value = 9)</span>
<span class="sd">    ==&gt; [[[9, 9, 4],  # Output shape: (2, 3, 3)</span>
<span class="sd">          [9, 3, 8],</span>
<span class="sd">          [2, 7, 6]],</span>
<span class="sd">         [[9, 9, 2],</span>
<span class="sd">          [9, 3, 4],</span>
<span class="sd">          [4, 3, 8]]]</span>

<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Rank `r` tensor where `r &gt;= 2`.</span>
<span class="sd">    k: A `Tensor` of type `int32`.</span>
<span class="sd">      Diagonal offset(s). Positive value means superdiagonal, 0 refers to the main</span>
<span class="sd">      diagonal, and negative value means subdiagonals. `k` can be a single integer</span>
<span class="sd">      (for a single diagonal) or a pair of integers specifying the low and high ends</span>
<span class="sd">      of a matrix band. `k[0]` must not be larger than `k[1]`.</span>
<span class="sd">    padding_value: A `Tensor`. Must have the same type as `input`.</span>
<span class="sd">      The value to fill the area outside the specified diagonal band with.</span>
<span class="sd">      Default is 0.</span>
<span class="sd">    align: An optional `string` from: `&quot;LEFT_RIGHT&quot;, &quot;RIGHT_LEFT&quot;, &quot;LEFT_LEFT&quot;, &quot;RIGHT_RIGHT&quot;`. Defaults to `&quot;RIGHT_LEFT&quot;`.</span>
<span class="sd">      Some diagonals are shorter than `max_diag_len` and need to be padded. `align` is</span>
<span class="sd">      a string specifying how superdiagonals and subdiagonals should be aligned,</span>
<span class="sd">      respectively. There are four possible alignments: &quot;RIGHT_LEFT&quot; (default),</span>
<span class="sd">      &quot;LEFT_RIGHT&quot;, &quot;LEFT_LEFT&quot;, and &quot;RIGHT_RIGHT&quot;. &quot;RIGHT_LEFT&quot; aligns superdiagonals</span>
<span class="sd">      to the right (left-pads the row) and subdiagonals to the left (right-pads the</span>
<span class="sd">      row). It is the packing format LAPACK uses. cuSPARSE uses &quot;LEFT_RIGHT&quot;, which is</span>
<span class="sd">      the opposite alignment.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;MatrixDiagPartV3&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span> <span class="s2">&quot;align&quot;</span><span class="p">,</span> <span class="n">align</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">matrix_diag_part_v3_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="n">align</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">align</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">align</span> <span class="o">=</span> <span class="s2">&quot;RIGHT_LEFT&quot;</span>
  <span class="n">align</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">align</span><span class="p">,</span> <span class="s2">&quot;align&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagPartV3&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=</span><span class="n">padding_value</span><span class="p">,</span>
                            <span class="n">align</span><span class="o">=</span><span class="n">align</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;align&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;align&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagPartV3&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">MatrixDiagPartV3</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.MatrixDiagPartV3&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">matrix_diag_part_v3</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">matrix_diag_part_v3_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span> <span class="n">align</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">align</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">align</span> <span class="o">=</span> <span class="s2">&quot;RIGHT_LEFT&quot;</span>
  <span class="n">align</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">align</span><span class="p">,</span> <span class="s2">&quot;align&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;align&quot;</span><span class="p">,</span> <span class="n">align</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;MatrixDiagPartV3&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagPartV3&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">matrix_diag_v2</span><span class="p">(</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns a batched diagonal tensor with given batched diagonal values.</span>

<span class="sd">  Returns a tensor with the contents in `diagonal` as `k[0]`-th to `k[1]`-th</span>
<span class="sd">  diagonals of a matrix, with everything else padded with `padding`. `num_rows`</span>
<span class="sd">  and `num_cols` specify the dimension of the innermost matrix of the output. If</span>
<span class="sd">  both are not specified, the op assumes the innermost matrix is square and infers</span>
<span class="sd">  its size from `k` and the innermost dimension of `diagonal`. If only one of them</span>
<span class="sd">  is specified, the op assumes the unspecified value is the smallest possible</span>
<span class="sd">  based on other criteria.</span>

<span class="sd">  Let `diagonal` have `r` dimensions `[I, J, ..., L, M, N]`. The output tensor has</span>
<span class="sd">  rank `r+1` with shape `[I, J, ..., L, M, num_rows, num_cols]` when only one</span>
<span class="sd">  diagonal is given (`k` is an integer or `k[0] == k[1]`). Otherwise, it has rank</span>
<span class="sd">  `r` with shape `[I, J, ..., L, num_rows, num_cols]`.</span>

<span class="sd">  The second innermost dimension of `diagonal` has double meaning.</span>
<span class="sd">  When `k` is scalar or `k[0] == k[1]`, `M` is part of the batch size</span>
<span class="sd">  [I, J, ..., M], and the output tensor is:</span>

<span class="sd">  ```</span>
<span class="sd">  output[i, j, ..., l, m, n]</span>
<span class="sd">    = diagonal[i, j, ..., l, n-max(d_upper, 0)] ; if n - m == d_upper</span>
<span class="sd">      padding_value                             ; otherwise</span>
<span class="sd">  ```</span>

<span class="sd">  Otherwise, `M` is treated as the number of diagonals for the matrix in the</span>
<span class="sd">  same batch (`M = k[1]-k[0]+1`), and the output tensor is:</span>

<span class="sd">  ```</span>
<span class="sd">  output[i, j, ..., l, m, n]</span>
<span class="sd">    = diagonal[i, j, ..., l, diag_index, index_in_diag] ; if k[0] &lt;= d &lt;= k[1]</span>
<span class="sd">      padding_value                                     ; otherwise</span>
<span class="sd">  ```</span>
<span class="sd">  where `d = n - m`, `diag_index = k[1] - d`, and `index_in_diag = n - max(d, 0)`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # The main diagonal.</span>
<span class="sd">  diagonal = np.array([[1, 2, 3, 4],            # Input shape: (2, 4)</span>
<span class="sd">                       [5, 6, 7, 8]])</span>
<span class="sd">  tf.matrix_diag(diagonal) ==&gt; [[[1, 0, 0, 0],  # Output shape: (2, 4, 4)</span>
<span class="sd">                                 [0, 2, 0, 0],</span>
<span class="sd">                                 [0, 0, 3, 0],</span>
<span class="sd">                                 [0, 0, 0, 4]],</span>
<span class="sd">                                [[5, 0, 0, 0],</span>
<span class="sd">                                 [0, 6, 0, 0],</span>
<span class="sd">                                 [0, 0, 7, 0],</span>
<span class="sd">                                 [0, 0, 0, 8]]]</span>

<span class="sd">  # A superdiagonal (per batch).</span>
<span class="sd">  diagonal = np.array([[1, 2, 3],  # Input shape: (2, 3)</span>
<span class="sd">                       [4, 5, 6]])</span>
<span class="sd">  tf.matrix_diag(diagonal, k = 1)</span>
<span class="sd">    ==&gt; [[[0, 1, 0, 0],  # Output shape: (2, 4, 4)</span>
<span class="sd">          [0, 0, 2, 0],</span>
<span class="sd">          [0, 0, 0, 3],</span>
<span class="sd">          [0, 0, 0, 0]],</span>
<span class="sd">         [[0, 4, 0, 0],</span>
<span class="sd">          [0, 0, 5, 0],</span>
<span class="sd">          [0, 0, 0, 6],</span>
<span class="sd">          [0, 0, 0, 0]]]</span>

<span class="sd">  # A band of diagonals.</span>
<span class="sd">  diagonals = np.array([[[1, 2, 3],  # Input shape: (2, 2, 3)</span>
<span class="sd">                         [4, 5, 0]],</span>
<span class="sd">                        [[6, 7, 9],</span>
<span class="sd">                         [9, 1, 0]]])</span>
<span class="sd">  tf.matrix_diag(diagonals, k = (-1, 0))</span>
<span class="sd">    ==&gt; [[[1, 0, 0],  # Output shape: (2, 3, 3)</span>
<span class="sd">          [4, 2, 0],</span>
<span class="sd">          [0, 5, 3]],</span>
<span class="sd">         [[6, 0, 0],</span>
<span class="sd">          [9, 7, 0],</span>
<span class="sd">          [0, 1, 9]]]</span>

<span class="sd">  # Rectangular matrix.</span>
<span class="sd">  diagonal = np.array([1, 2])  # Input shape: (2)</span>
<span class="sd">  tf.matrix_diag(diagonal, k = -1, num_rows = 3, num_cols = 4)</span>
<span class="sd">    ==&gt; [[0, 0, 0, 0],  # Output shape: (3, 4)</span>
<span class="sd">         [1, 0, 0, 0],</span>
<span class="sd">         [0, 2, 0, 0]]</span>

<span class="sd">  # Rectangular matrix with inferred num_cols and padding_value = 9.</span>
<span class="sd">  tf.matrix_diag(diagonal, k = -1, num_rows = 3, padding_value = 9)</span>
<span class="sd">    ==&gt; [[9, 9],  # Output shape: (3, 2)</span>
<span class="sd">         [1, 9],</span>
<span class="sd">         [9, 2]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    diagonal: A `Tensor`. Rank `r`, where `r &gt;= 1`</span>
<span class="sd">    k: A `Tensor` of type `int32`.</span>
<span class="sd">      Diagonal offset(s). Positive value means superdiagonal, 0 refers to the main</span>
<span class="sd">      diagonal, and negative value means subdiagonals. `k` can be a single integer</span>
<span class="sd">      (for a single diagonal) or a pair of integers specifying the low and high ends</span>
<span class="sd">      of a matrix band. `k[0]` must not be larger than `k[1]`.</span>
<span class="sd">    num_rows: A `Tensor` of type `int32`.</span>
<span class="sd">      The number of rows of the output matrix. If it is not provided, the op assumes</span>
<span class="sd">      the output matrix is a square matrix and infers the matrix size from k and the</span>
<span class="sd">      innermost dimension of `diagonal`.</span>
<span class="sd">    num_cols: A `Tensor` of type `int32`.</span>
<span class="sd">      The number of columns of the output matrix. If it is not provided, the op</span>
<span class="sd">      assumes the output matrix is a square matrix and infers the matrix size from</span>
<span class="sd">      k and the innermost dimension of `diagonal`.</span>
<span class="sd">    padding_value: A `Tensor`. Must have the same type as `diagonal`.</span>
<span class="sd">      The number to fill the area outside the specified diagonal band with.</span>
<span class="sd">      Default is 0.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `diagonal`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;MatrixDiagV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">matrix_diag_v2_eager_fallback</span><span class="p">(</span>
            <span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagV2&quot;</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">num_rows</span><span class="o">=</span><span class="n">num_rows</span><span class="p">,</span>
                        <span class="n">num_cols</span><span class="o">=</span><span class="n">num_cols</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=</span><span class="n">padding_value</span><span class="p">,</span>
                        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">MatrixDiagV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.MatrixDiagV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">matrix_diag_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">matrix_diag_v2_eager_fallback</span><span class="p">(</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">num_rows</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">num_cols</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">num_cols</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;MatrixDiagV2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">matrix_diag_v3</span><span class="p">(</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s2">&quot;RIGHT_LEFT&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns a batched diagonal tensor with given batched diagonal values.</span>

<span class="sd">  Returns a tensor with the contents in `diagonal` as `k[0]`-th to `k[1]`-th</span>
<span class="sd">  diagonals of a matrix, with everything else padded with `padding`. `num_rows`</span>
<span class="sd">  and `num_cols` specify the dimension of the innermost matrix of the output. If</span>
<span class="sd">  both are not specified, the op assumes the innermost matrix is square and infers</span>
<span class="sd">  its size from `k` and the innermost dimension of `diagonal`. If only one of them</span>
<span class="sd">  is specified, the op assumes the unspecified value is the smallest possible</span>
<span class="sd">  based on other criteria.</span>

<span class="sd">  Let `diagonal` have `r` dimensions `[I, J, ..., L, M, N]`. The output tensor has</span>
<span class="sd">  rank `r+1` with shape `[I, J, ..., L, M, num_rows, num_cols]` when only one</span>
<span class="sd">  diagonal is given (`k` is an integer or `k[0] == k[1]`). Otherwise, it has rank</span>
<span class="sd">  `r` with shape `[I, J, ..., L, num_rows, num_cols]`.</span>

<span class="sd">  The second innermost dimension of `diagonal` has double meaning.</span>
<span class="sd">  When `k` is scalar or `k[0] == k[1]`, `M` is part of the batch size</span>
<span class="sd">  [I, J, ..., M], and the output tensor is:</span>

<span class="sd">  ```</span>
<span class="sd">  output[i, j, ..., l, m, n]</span>
<span class="sd">    = diagonal[i, j, ..., l, n-max(d_upper, 0)] ; if n - m == d_upper</span>
<span class="sd">      padding_value                             ; otherwise</span>
<span class="sd">  ```</span>

<span class="sd">  Otherwise, `M` is treated as the number of diagonals for the matrix in the</span>
<span class="sd">  same batch (`M = k[1]-k[0]+1`), and the output tensor is:</span>

<span class="sd">  ```</span>
<span class="sd">  output[i, j, ..., l, m, n]</span>
<span class="sd">    = diagonal[i, j, ..., l, diag_index, index_in_diag] ; if k[0] &lt;= d &lt;= k[1]</span>
<span class="sd">      padding_value                                     ; otherwise</span>
<span class="sd">  ```</span>
<span class="sd">  where `d = n - m`, `diag_index = [k] - d`, and</span>
<span class="sd">  `index_in_diag = n - max(d, 0) + offset`.</span>

<span class="sd">  `offset` is zero except when the alignment of the diagonal is to the right.</span>
<span class="sd">  ```</span>
<span class="sd">  offset = max_diag_len - diag_len(d) ; if (`align` in {RIGHT_LEFT, RIGHT_RIGHT}</span>
<span class="sd">                                             and `d &gt;= 0`) or</span>
<span class="sd">                                           (`align` in {LEFT_RIGHT, RIGHT_RIGHT}</span>
<span class="sd">                                             and `d &lt;= 0`)</span>
<span class="sd">           0                          ; otherwise</span>
<span class="sd">  ```</span>
<span class="sd">  where `diag_len(d) = min(cols - max(d, 0), rows + min(d, 0))`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # The main diagonal.</span>
<span class="sd">  diagonal = np.array([[1, 2, 3, 4],            # Input shape: (2, 4)</span>
<span class="sd">                       [5, 6, 7, 8]])</span>
<span class="sd">  tf.matrix_diag(diagonal) ==&gt; [[[1, 0, 0, 0],  # Output shape: (2, 4, 4)</span>
<span class="sd">                                 [0, 2, 0, 0],</span>
<span class="sd">                                 [0, 0, 3, 0],</span>
<span class="sd">                                 [0, 0, 0, 4]],</span>
<span class="sd">                                [[5, 0, 0, 0],</span>
<span class="sd">                                 [0, 6, 0, 0],</span>
<span class="sd">                                 [0, 0, 7, 0],</span>
<span class="sd">                                 [0, 0, 0, 8]]]</span>

<span class="sd">  # A superdiagonal (per batch).</span>
<span class="sd">  diagonal = np.array([[1, 2, 3],  # Input shape: (2, 3)</span>
<span class="sd">                       [4, 5, 6]])</span>
<span class="sd">  tf.matrix_diag(diagonal, k = 1)</span>
<span class="sd">    ==&gt; [[[0, 1, 0, 0],  # Output shape: (2, 4, 4)</span>
<span class="sd">          [0, 0, 2, 0],</span>
<span class="sd">          [0, 0, 0, 3],</span>
<span class="sd">          [0, 0, 0, 0]],</span>
<span class="sd">         [[0, 4, 0, 0],</span>
<span class="sd">          [0, 0, 5, 0],</span>
<span class="sd">          [0, 0, 0, 6],</span>
<span class="sd">          [0, 0, 0, 0]]]</span>

<span class="sd">  # A tridiagonal band (per batch).</span>
<span class="sd">  diagonals = np.array([[[0, 8, 9],  # Input shape: (2, 2, 3)</span>
<span class="sd">                         [1, 2, 3],</span>
<span class="sd">                         [4, 5, 0]],</span>
<span class="sd">                        [[0, 2, 3],</span>
<span class="sd">                         [6, 7, 9],</span>
<span class="sd">                         [9, 1, 0]]])</span>
<span class="sd">  tf.matrix_diag(diagonals, k = (-1, 1))</span>
<span class="sd">    ==&gt; [[[1, 8, 0],  # Output shape: (2, 3, 3)</span>
<span class="sd">          [4, 2, 9],</span>
<span class="sd">          [0, 5, 3]],</span>
<span class="sd">         [[6, 2, 0],</span>
<span class="sd">          [9, 7, 3],</span>
<span class="sd">          [0, 1, 9]]]</span>

<span class="sd">  # LEFT_RIGHT alignment.</span>
<span class="sd">  diagonals = np.array([[[8, 9, 0],  # Input shape: (2, 2, 3)</span>
<span class="sd">                         [1, 2, 3],</span>
<span class="sd">                         [0, 4, 5]],</span>
<span class="sd">                        [[2, 3, 0],</span>
<span class="sd">                         [6, 7, 9],</span>
<span class="sd">                         [0, 9, 1]]])</span>
<span class="sd">  tf.matrix_diag(diagonals, k = (-1, 1), align=&quot;LEFT_RIGHT&quot;)</span>
<span class="sd">    ==&gt; [[[1, 8, 0],  # Output shape: (2, 3, 3)</span>
<span class="sd">          [4, 2, 9],</span>
<span class="sd">          [0, 5, 3]],</span>
<span class="sd">         [[6, 2, 0],</span>
<span class="sd">          [9, 7, 3],</span>
<span class="sd">          [0, 1, 9]]]</span>

<span class="sd">  # Rectangular matrix.</span>
<span class="sd">  diagonal = np.array([1, 2])  # Input shape: (2)</span>
<span class="sd">  tf.matrix_diag(diagonal, k = -1, num_rows = 3, num_cols = 4)</span>
<span class="sd">    ==&gt; [[0, 0, 0, 0],  # Output shape: (3, 4)</span>
<span class="sd">         [1, 0, 0, 0],</span>
<span class="sd">         [0, 2, 0, 0]]</span>

<span class="sd">  # Rectangular matrix with inferred num_cols and padding_value = 9.</span>
<span class="sd">  tf.matrix_diag(diagonal, k = -1, num_rows = 3, padding_value = 9)</span>
<span class="sd">    ==&gt; [[9, 9],  # Output shape: (3, 2)</span>
<span class="sd">         [1, 9],</span>
<span class="sd">         [9, 2]]</span>

<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    diagonal: A `Tensor`. Rank `r`, where `r &gt;= 1`</span>
<span class="sd">    k: A `Tensor` of type `int32`.</span>
<span class="sd">      Diagonal offset(s). Positive value means superdiagonal, 0 refers to the main</span>
<span class="sd">      diagonal, and negative value means subdiagonals. `k` can be a single integer</span>
<span class="sd">      (for a single diagonal) or a pair of integers specifying the low and high ends</span>
<span class="sd">      of a matrix band. `k[0]` must not be larger than `k[1]`.</span>
<span class="sd">    num_rows: A `Tensor` of type `int32`.</span>
<span class="sd">      The number of rows of the output matrix. If it is not provided, the op assumes</span>
<span class="sd">      the output matrix is a square matrix and infers the matrix size from k and the</span>
<span class="sd">      innermost dimension of `diagonal`.</span>
<span class="sd">    num_cols: A `Tensor` of type `int32`.</span>
<span class="sd">      The number of columns of the output matrix. If it is not provided, the op</span>
<span class="sd">      assumes the output matrix is a square matrix and infers the matrix size from</span>
<span class="sd">      k and the innermost dimension of `diagonal`.</span>
<span class="sd">    padding_value: A `Tensor`. Must have the same type as `diagonal`.</span>
<span class="sd">      The number to fill the area outside the specified diagonal band with.</span>
<span class="sd">      Default is 0.</span>
<span class="sd">    align: An optional `string` from: `&quot;LEFT_RIGHT&quot;, &quot;RIGHT_LEFT&quot;, &quot;LEFT_LEFT&quot;, &quot;RIGHT_RIGHT&quot;`. Defaults to `&quot;RIGHT_LEFT&quot;`.</span>
<span class="sd">      Some diagonals are shorter than `max_diag_len` and need to be padded. `align` is</span>
<span class="sd">      a string specifying how superdiagonals and subdiagonals should be aligned,</span>
<span class="sd">      respectively. There are four possible alignments: &quot;RIGHT_LEFT&quot; (default),</span>
<span class="sd">      &quot;LEFT_RIGHT&quot;, &quot;LEFT_LEFT&quot;, and &quot;RIGHT_RIGHT&quot;. &quot;RIGHT_LEFT&quot; aligns superdiagonals</span>
<span class="sd">      to the right (left-pads the row) and subdiagonals to the left (right-pads the</span>
<span class="sd">      row). It is the packing format LAPACK uses. cuSPARSE uses &quot;LEFT_RIGHT&quot;, which is</span>
<span class="sd">      the opposite alignment.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `diagonal`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;MatrixDiagV3&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span>
        <span class="s2">&quot;align&quot;</span><span class="p">,</span> <span class="n">align</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">matrix_diag_v3_eager_fallback</span><span class="p">(</span>
            <span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="n">align</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">align</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">align</span> <span class="o">=</span> <span class="s2">&quot;RIGHT_LEFT&quot;</span>
  <span class="n">align</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">align</span><span class="p">,</span> <span class="s2">&quot;align&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagV3&quot;</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">num_rows</span><span class="o">=</span><span class="n">num_rows</span><span class="p">,</span>
                        <span class="n">num_cols</span><span class="o">=</span><span class="n">num_cols</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=</span><span class="n">padding_value</span><span class="p">,</span>
                        <span class="n">align</span><span class="o">=</span><span class="n">align</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;align&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;align&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagV3&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">MatrixDiagV3</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.MatrixDiagV3&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">matrix_diag_v3</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">matrix_diag_v3_eager_fallback</span><span class="p">(</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">,</span> <span class="n">align</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">align</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">align</span> <span class="o">=</span> <span class="s2">&quot;RIGHT_LEFT&quot;</span>
  <span class="n">align</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">align</span><span class="p">,</span> <span class="s2">&quot;align&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">num_rows</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">num_cols</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">num_cols</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span> <span class="n">num_cols</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;align&quot;</span><span class="p">,</span> <span class="n">align</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;MatrixDiagV3&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixDiagV3&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">matrix_set_diag</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns a batched matrix tensor with new batched diagonal values.</span>

<span class="sd">  Given `input` and `diagonal`, this operation returns a tensor with the</span>
<span class="sd">  same shape and values as `input`, except for the main diagonal of the</span>
<span class="sd">  innermost matrices.  These will be overwritten by the values in `diagonal`.</span>

<span class="sd">  The output is computed as follows:</span>

<span class="sd">  Assume `input` has `k+1` dimensions `[I, J, K, ..., M, N]` and `diagonal` has</span>
<span class="sd">  `k` dimensions `[I, J, K, ..., min(M, N)]`.  Then the output is a</span>
<span class="sd">  tensor of rank `k+1` with dimensions `[I, J, K, ..., M, N]` where:</span>

<span class="sd">    * `output[i, j, k, ..., m, n] = diagonal[i, j, k, ..., n]` for `m == n`.</span>
<span class="sd">    * `output[i, j, k, ..., m, n] = input[i, j, k, ..., m, n]` for `m != n`.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Rank `k+1`, where `k &gt;= 1`.</span>
<span class="sd">    diagonal: A `Tensor`. Must have the same type as `input`.</span>
<span class="sd">      Rank `k`, where `k &gt;= 1`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;MatrixSetDiag&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">matrix_set_diag_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;MatrixSetDiag&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixSetDiag&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">MatrixSetDiag</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.MatrixSetDiag&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">matrix_set_diag</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">matrix_set_diag_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;MatrixSetDiag&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixSetDiag&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">matrix_set_diag_v2</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns a batched matrix tensor with new batched diagonal values.</span>

<span class="sd">  Given `input` and `diagonal`, this operation returns a tensor with the</span>
<span class="sd">  same shape and values as `input`, except for the specified diagonals of the</span>
<span class="sd">  innermost matrices. These will be overwritten by the values in `diagonal`.</span>

<span class="sd">  `input` has `r+1` dimensions `[I, J, ..., L, M, N]`. When `k` is scalar or</span>
<span class="sd">  `k[0] == k[1]`, `diagonal` has `r` dimensions `[I, J, ..., L, max_diag_len]`.</span>
<span class="sd">  Otherwise, it has `r+1` dimensions `[I, J, ..., L, num_diags, max_diag_len]`.</span>
<span class="sd">  `num_diags` is the number of diagonals, `num_diags = k[1] - k[0] + 1`.</span>
<span class="sd">  `max_diag_len` is the longest diagonal in the range `[k[0], k[1]]`,</span>
<span class="sd">  `max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))`</span>

<span class="sd">  The output is a tensor of rank `k+1` with dimensions `[I, J, ..., L, M, N]`.</span>
<span class="sd">  If `k` is scalar or `k[0] == k[1]`:</span>

<span class="sd">  ```</span>
<span class="sd">  output[i, j, ..., l, m, n]</span>
<span class="sd">    = diagonal[i, j, ..., l, n-max(k[1], 0)] ; if n - m == k[1]</span>
<span class="sd">      input[i, j, ..., l, m, n]              ; otherwise</span>
<span class="sd">  ```</span>

<span class="sd">  Otherwise,</span>

<span class="sd">  ```</span>
<span class="sd">  output[i, j, ..., l, m, n]</span>
<span class="sd">    = diagonal[i, j, ..., l, diag_index, index_in_diag] ; if k[0] &lt;= d &lt;= k[1]</span>
<span class="sd">      input[i, j, ..., l, m, n]                         ; otherwise</span>
<span class="sd">  ```</span>
<span class="sd">  where `d = n - m`, `diag_index = k[1] - d`, and `index_in_diag = n - max(d, 0)`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # The main diagonal.</span>
<span class="sd">  input = np.array([[[7, 7, 7, 7],              # Input shape: (2, 3, 4)</span>
<span class="sd">                     [7, 7, 7, 7],</span>
<span class="sd">                     [7, 7, 7, 7]],</span>
<span class="sd">                    [[7, 7, 7, 7],</span>
<span class="sd">                     [7, 7, 7, 7],</span>
<span class="sd">                     [7, 7, 7, 7]]])</span>
<span class="sd">  diagonal = np.array([[1, 2, 3],               # Diagonal shape: (2, 3)</span>
<span class="sd">                       [4, 5, 6]])</span>
<span class="sd">  tf.matrix_set_diag(diagonal) ==&gt; [[[1, 7, 7, 7],  # Output shape: (2, 3, 4)</span>
<span class="sd">                                     [7, 2, 7, 7],</span>
<span class="sd">                                     [7, 7, 3, 7]],</span>
<span class="sd">                                    [[4, 7, 7, 7],</span>
<span class="sd">                                     [7, 5, 7, 7],</span>
<span class="sd">                                     [7, 7, 6, 7]]]</span>

<span class="sd">  # A superdiagonal (per batch).</span>
<span class="sd">  tf.matrix_set_diag(diagonal, k = 1)</span>
<span class="sd">    ==&gt; [[[7, 1, 7, 7],  # Output shape: (2, 3, 4)</span>
<span class="sd">          [7, 7, 2, 7],</span>
<span class="sd">          [7, 7, 7, 3]],</span>
<span class="sd">         [[7, 4, 7, 7],</span>
<span class="sd">          [7, 7, 5, 7],</span>
<span class="sd">          [7, 7, 7, 6]]]</span>

<span class="sd">  # A band of diagonals.</span>
<span class="sd">  diagonals = np.array([[[1, 2, 3],  # Diagonal shape: (2, 2, 3)</span>
<span class="sd">                         [4, 5, 0]],</span>
<span class="sd">                        [[6, 1, 2],</span>
<span class="sd">                         [3, 4, 0]]])</span>
<span class="sd">  tf.matrix_set_diag(diagonals, k = (-1, 0))</span>
<span class="sd">    ==&gt; [[[1, 7, 7, 7],  # Output shape: (2, 3, 4)</span>
<span class="sd">          [4, 2, 7, 7],</span>
<span class="sd">          [0, 5, 3, 7]],</span>
<span class="sd">         [[6, 7, 7, 7],</span>
<span class="sd">          [3, 1, 7, 7],</span>
<span class="sd">          [7, 4, 2, 7]]]</span>

<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Rank `r+1`, where `r &gt;= 1`.</span>
<span class="sd">    diagonal: A `Tensor`. Must have the same type as `input`.</span>
<span class="sd">      Rank `r` when `k` is an integer or `k[0] == k[1]`. Otherwise, it has rank `r+1`.</span>
<span class="sd">      `k &gt;= 1`.</span>
<span class="sd">    k: A `Tensor` of type `int32`.</span>
<span class="sd">      Diagonal offset(s). Positive value means superdiagonal, 0 refers to the main</span>
<span class="sd">      diagonal, and negative value means subdiagonals. `k` can be a single integer</span>
<span class="sd">      (for a single diagonal) or a pair of integers specifying the low and high ends</span>
<span class="sd">      of a matrix band. `k[0]` must not be larger than `k[1]`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;MatrixSetDiagV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">matrix_set_diag_v2_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;MatrixSetDiagV2&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixSetDiagV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">MatrixSetDiagV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.MatrixSetDiagV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">matrix_set_diag_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">matrix_set_diag_v2_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;MatrixSetDiagV2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixSetDiagV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">matrix_set_diag_v3</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s2">&quot;RIGHT_LEFT&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns a batched matrix tensor with new batched diagonal values.</span>

<span class="sd">  Given `input` and `diagonal`, this operation returns a tensor with the</span>
<span class="sd">  same shape and values as `input`, except for the specified diagonals of the</span>
<span class="sd">  innermost matrices. These will be overwritten by the values in `diagonal`.</span>

<span class="sd">  `input` has `r+1` dimensions `[I, J, ..., L, M, N]`. When `k` is scalar or</span>
<span class="sd">  `k[0] == k[1]`, `diagonal` has `r` dimensions `[I, J, ..., L, max_diag_len]`.</span>
<span class="sd">  Otherwise, it has `r+1` dimensions `[I, J, ..., L, num_diags, max_diag_len]`.</span>
<span class="sd">  `num_diags` is the number of diagonals, `num_diags = k[1] - k[0] + 1`.</span>
<span class="sd">  `max_diag_len` is the longest diagonal in the range `[k[0], k[1]]`,</span>
<span class="sd">  `max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))`</span>

<span class="sd">  The output is a tensor of rank `k+1` with dimensions `[I, J, ..., L, M, N]`.</span>
<span class="sd">  If `k` is scalar or `k[0] == k[1]`:</span>

<span class="sd">  ```</span>
<span class="sd">  output[i, j, ..., l, m, n]</span>
<span class="sd">    = diagonal[i, j, ..., l, n-max(k[1], 0)] ; if n - m == k[1]</span>
<span class="sd">      input[i, j, ..., l, m, n]              ; otherwise</span>
<span class="sd">  ```</span>

<span class="sd">  Otherwise,</span>

<span class="sd">  ```</span>
<span class="sd">  output[i, j, ..., l, m, n]</span>
<span class="sd">    = diagonal[i, j, ..., l, diag_index, index_in_diag] ; if k[0] &lt;= d &lt;= k[1]</span>
<span class="sd">      input[i, j, ..., l, m, n]                         ; otherwise</span>
<span class="sd">  ```</span>
<span class="sd">  where `d = n - m`, `diag_index = k[1] - d`, and</span>
<span class="sd">  `index_in_diag = n - max(d, 0) + offset`.</span>

<span class="sd">  `offset` is zero except when the alignment of the diagonal is to the right.</span>
<span class="sd">  ```</span>
<span class="sd">  offset = max_diag_len - diag_len(d) ; if (`align` in {RIGHT_LEFT, RIGHT_RIGHT}</span>
<span class="sd">                                             and `d &gt;= 0`) or</span>
<span class="sd">                                           (`align` in {LEFT_RIGHT, RIGHT_RIGHT}</span>
<span class="sd">                                             and `d &lt;= 0`)</span>
<span class="sd">           0                          ; otherwise</span>
<span class="sd">  ```</span>
<span class="sd">  where `diag_len(d) = min(cols - max(d, 0), rows + min(d, 0))`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # The main diagonal.</span>
<span class="sd">  input = np.array([[[7, 7, 7, 7],              # Input shape: (2, 3, 4)</span>
<span class="sd">                     [7, 7, 7, 7],</span>
<span class="sd">                     [7, 7, 7, 7]],</span>
<span class="sd">                    [[7, 7, 7, 7],</span>
<span class="sd">                     [7, 7, 7, 7],</span>
<span class="sd">                     [7, 7, 7, 7]]])</span>
<span class="sd">  diagonal = np.array([[1, 2, 3],               # Diagonal shape: (2, 3)</span>
<span class="sd">                       [4, 5, 6]])</span>
<span class="sd">  tf.matrix_set_diag(input, diagonal)</span>
<span class="sd">    ==&gt; [[[1, 7, 7, 7],  # Output shape: (2, 3, 4)</span>
<span class="sd">          [7, 2, 7, 7],</span>
<span class="sd">          [7, 7, 3, 7]],</span>
<span class="sd">         [[4, 7, 7, 7],</span>
<span class="sd">          [7, 5, 7, 7],</span>
<span class="sd">          [7, 7, 6, 7]]]</span>

<span class="sd">  # A superdiagonal (per batch).</span>
<span class="sd">  tf.matrix_set_diag(input, diagonal, k = 1)</span>
<span class="sd">    ==&gt; [[[7, 1, 7, 7],  # Output shape: (2, 3, 4)</span>
<span class="sd">          [7, 7, 2, 7],</span>
<span class="sd">          [7, 7, 7, 3]],</span>
<span class="sd">         [[7, 4, 7, 7],</span>
<span class="sd">          [7, 7, 5, 7],</span>
<span class="sd">          [7, 7, 7, 6]]]</span>

<span class="sd">  # A band of diagonals.</span>
<span class="sd">  diagonals = np.array([[[0, 9, 1],  # Diagonal shape: (2, 4, 3)</span>
<span class="sd">                         [6, 5, 8],</span>
<span class="sd">                         [1, 2, 3],</span>
<span class="sd">                         [4, 5, 0]],</span>
<span class="sd">                        [[0, 1, 2],</span>
<span class="sd">                         [5, 6, 4],</span>
<span class="sd">                         [6, 1, 2],</span>
<span class="sd">                         [3, 4, 0]]])</span>
<span class="sd">  tf.matrix_set_diag(input, diagonals, k = (-1, 2))</span>
<span class="sd">    ==&gt; [[[1, 6, 9, 7],  # Output shape: (2, 3, 4)</span>
<span class="sd">          [4, 2, 5, 1],</span>
<span class="sd">          [7, 5, 3, 8]],</span>
<span class="sd">         [[6, 5, 1, 7],</span>
<span class="sd">          [3, 1, 6, 2],</span>
<span class="sd">          [7, 4, 2, 4]]]</span>

<span class="sd">  # LEFT_RIGHT alignment.</span>
<span class="sd">  diagonals = np.array([[[9, 1, 0],  # Diagonal shape: (2, 4, 3)</span>
<span class="sd">                         [6, 5, 8],</span>
<span class="sd">                         [1, 2, 3],</span>
<span class="sd">                         [0, 4, 5]],</span>
<span class="sd">                        [[1, 2, 0],</span>
<span class="sd">                         [5, 6, 4],</span>
<span class="sd">                         [6, 1, 2],</span>
<span class="sd">                         [0, 3, 4]]])</span>
<span class="sd">  tf.matrix_set_diag(input, diagonals, k = (-1, 2), align=&quot;LEFT_RIGHT&quot;)</span>
<span class="sd">    ==&gt; [[[1, 6, 9, 7],  # Output shape: (2, 3, 4)</span>
<span class="sd">          [4, 2, 5, 1],</span>
<span class="sd">          [7, 5, 3, 8]],</span>
<span class="sd">         [[6, 5, 1, 7],</span>
<span class="sd">          [3, 1, 6, 2],</span>
<span class="sd">          [7, 4, 2, 4]]]</span>

<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Rank `r+1`, where `r &gt;= 1`.</span>
<span class="sd">    diagonal: A `Tensor`. Must have the same type as `input`.</span>
<span class="sd">      Rank `r` when `k` is an integer or `k[0] == k[1]`. Otherwise, it has rank `r+1`.</span>
<span class="sd">      `k &gt;= 1`.</span>
<span class="sd">    k: A `Tensor` of type `int32`.</span>
<span class="sd">      Diagonal offset(s). Positive value means superdiagonal, 0 refers to the main</span>
<span class="sd">      diagonal, and negative value means subdiagonals. `k` can be a single integer</span>
<span class="sd">      (for a single diagonal) or a pair of integers specifying the low and high ends</span>
<span class="sd">      of a matrix band. `k[0]` must not be larger than `k[1]`.</span>
<span class="sd">    align: An optional `string` from: `&quot;LEFT_RIGHT&quot;, &quot;RIGHT_LEFT&quot;, &quot;LEFT_LEFT&quot;, &quot;RIGHT_RIGHT&quot;`. Defaults to `&quot;RIGHT_LEFT&quot;`.</span>
<span class="sd">      Some diagonals are shorter than `max_diag_len` and need to be padded. `align` is</span>
<span class="sd">      a string specifying how superdiagonals and subdiagonals should be aligned,</span>
<span class="sd">      respectively. There are four possible alignments: &quot;RIGHT_LEFT&quot; (default),</span>
<span class="sd">      &quot;LEFT_RIGHT&quot;, &quot;LEFT_LEFT&quot;, and &quot;RIGHT_RIGHT&quot;. &quot;RIGHT_LEFT&quot; aligns superdiagonals</span>
<span class="sd">      to the right (left-pads the row) and subdiagonals to the left (right-pads the</span>
<span class="sd">      row). It is the packing format LAPACK uses. cuSPARSE uses &quot;LEFT_RIGHT&quot;, which is</span>
<span class="sd">      the opposite alignment.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;MatrixSetDiagV3&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="s2">&quot;align&quot;</span><span class="p">,</span> <span class="n">align</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">matrix_set_diag_v3_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="n">align</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">align</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">align</span> <span class="o">=</span> <span class="s2">&quot;RIGHT_LEFT&quot;</span>
  <span class="n">align</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">align</span><span class="p">,</span> <span class="s2">&quot;align&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;MatrixSetDiagV3&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="n">align</span><span class="p">,</span>
                           <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;align&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;align&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixSetDiagV3&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">MatrixSetDiagV3</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.MatrixSetDiagV3&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">matrix_set_diag_v3</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">matrix_set_diag_v3_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">align</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">align</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">align</span> <span class="o">=</span> <span class="s2">&quot;RIGHT_LEFT&quot;</span>
  <span class="n">align</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">align</span><span class="p">,</span> <span class="s2">&quot;align&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;align&quot;</span><span class="p">,</span> <span class="n">align</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;MatrixSetDiagV3&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MatrixSetDiagV3&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">mirror_pad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pads a tensor with mirrored values.</span>

<span class="sd">  This operation pads a `input` with mirrored values according to the `paddings`</span>
<span class="sd">  you specify. `paddings` is an integer tensor with shape `[n, 2]`, where n is</span>
<span class="sd">  the rank of `input`. For each dimension D of `input`, `paddings[D, 0]` indicates</span>
<span class="sd">  how many values to add before the contents of `input` in that dimension, and</span>
<span class="sd">  `paddings[D, 1]` indicates how many values to add after the contents of `input`</span>
<span class="sd">  in that dimension. Both `paddings[D, 0]` and `paddings[D, 1]` must be no greater</span>
<span class="sd">  than `input.dim_size(D)` (or `input.dim_size(D) - 1`) if `copy_border` is true</span>
<span class="sd">  (if false, respectively).</span>

<span class="sd">  The padded size of each dimension D of the output is:</span>

<span class="sd">  `paddings(D, 0) + input.dim_size(D) + paddings(D, 1)`</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;t&#39; is [[1, 2, 3], [4, 5, 6]].</span>
<span class="sd">  # &#39;paddings&#39; is [[1, 1]], [2, 2]].</span>
<span class="sd">  # &#39;mode&#39; is SYMMETRIC.</span>
<span class="sd">  # rank of &#39;t&#39; is 2.</span>
<span class="sd">  pad(t, paddings) ==&gt; [[2, 1, 1, 2, 3, 3, 2]</span>
<span class="sd">                        [2, 1, 1, 2, 3, 3, 2]</span>
<span class="sd">                        [5, 4, 4, 5, 6, 6, 5]</span>
<span class="sd">                        [5, 4, 4, 5, 6, 6, 5]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. The input tensor to be padded.</span>
<span class="sd">    paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A two-column matrix specifying the padding sizes. The number of</span>
<span class="sd">      rows must be the same as the rank of `input`.</span>
<span class="sd">    mode: A `string` from: `&quot;REFLECT&quot;, &quot;SYMMETRIC&quot;`.</span>
<span class="sd">      Either `REFLECT` or `SYMMETRIC`. In reflect mode the padded regions</span>
<span class="sd">      do not include the borders, while in symmetric mode the padded regions</span>
<span class="sd">      do include the borders. For example, if `input` is `[1, 2, 3]` and `paddings`</span>
<span class="sd">      is `[0, 2]`, then the output is `[1, 2, 3, 2, 1]` in reflect mode, and</span>
<span class="sd">      it is `[1, 2, 3, 3, 2]` in symmetric mode.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;MirrorPad&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">mirror_pad_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">mode</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;MirrorPad&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="o">=</span><span class="n">paddings</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tpaddings&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tpaddings&quot;</span><span class="p">),</span> <span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;mode&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MirrorPad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">MirrorPad</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.MirrorPad&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">mirror_pad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">mirror_pad_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">mode</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tpaddings</span><span class="p">,</span> <span class="p">(</span><span class="n">paddings</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">paddings</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tpaddings&quot;</span><span class="p">,</span> <span class="n">_attr_Tpaddings</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;MirrorPad&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MirrorPad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">mirror_pad_grad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Gradient op for `MirrorPad` op. This op folds a mirror-padded tensor.</span>

<span class="sd">  This operation folds the padded areas of `input` by `MirrorPad` according to the</span>
<span class="sd">  `paddings` you specify. `paddings` must be the same as `paddings` argument</span>
<span class="sd">  given to the corresponding `MirrorPad` op.</span>

<span class="sd">  The folded size of each dimension D of the output is:</span>

<span class="sd">  `input.dim_size(D) - paddings(D, 0) - paddings(D, 1)`</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;t&#39; is [[1, 2, 3], [4, 5, 6], [7, 8, 9]].</span>
<span class="sd">  # &#39;paddings&#39; is [[0, 1]], [0, 1]].</span>
<span class="sd">  # &#39;mode&#39; is SYMMETRIC.</span>
<span class="sd">  # rank of &#39;t&#39; is 2.</span>
<span class="sd">  pad(t, paddings) ==&gt; [[ 1,  5]</span>
<span class="sd">                        [11, 28]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. The input tensor to be folded.</span>
<span class="sd">    paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A two-column matrix specifying the padding sizes. The number of</span>
<span class="sd">      rows must be the same as the rank of `input`.</span>
<span class="sd">    mode: A `string` from: `&quot;REFLECT&quot;, &quot;SYMMETRIC&quot;`.</span>
<span class="sd">      The mode used in the `MirrorPad` op.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;MirrorPadGrad&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">mirror_pad_grad_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">mode</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;MirrorPadGrad&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="o">=</span><span class="n">paddings</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tpaddings&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tpaddings&quot;</span><span class="p">),</span> <span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;mode&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MirrorPadGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">MirrorPadGrad</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.MirrorPadGrad&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">mirror_pad_grad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">mirror_pad_grad_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">mode</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tpaddings</span><span class="p">,</span> <span class="p">(</span><span class="n">paddings</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">paddings</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tpaddings&quot;</span><span class="p">,</span> <span class="n">_attr_Tpaddings</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;MirrorPadGrad&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;MirrorPadGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">one_hot</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">on_value</span><span class="p">,</span> <span class="n">off_value</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns a one-hot tensor.</span>

<span class="sd">  The locations represented by indices in `indices` take value `on_value`,</span>
<span class="sd">  while all other locations take value `off_value`.</span>

<span class="sd">  If the input `indices` is rank `N`, the output will have rank `N+1`,</span>
<span class="sd">  The new axis is created at dimension `axis` (default: the new axis is</span>
<span class="sd">  appended at the end).</span>

<span class="sd">  If `indices` is a scalar the output shape will be a vector of length `depth`.</span>

<span class="sd">  If `indices` is a vector of length `features`, the output shape will be:</span>
<span class="sd">  ```</span>
<span class="sd">    features x depth if axis == -1</span>
<span class="sd">    depth x features if axis == 0</span>
<span class="sd">  ```</span>

<span class="sd">  If `indices` is a matrix (batch) with shape `[batch, features]`,</span>
<span class="sd">  the output shape will be:</span>
<span class="sd">  ```</span>
<span class="sd">    batch x features x depth if axis == -1</span>
<span class="sd">    batch x depth x features if axis == 1</span>
<span class="sd">    depth x batch x features if axis == 0</span>
<span class="sd">  ```</span>


<span class="sd">  Examples</span>
<span class="sd">  =========</span>

<span class="sd">  Suppose that</span>
<span class="sd">  ```</span>
<span class="sd">    indices = [0, 2, -1, 1]</span>
<span class="sd">    depth = 3</span>
<span class="sd">    on_value = 5.0</span>
<span class="sd">    off_value = 0.0</span>
<span class="sd">    axis = -1</span>
<span class="sd">  ```</span>

<span class="sd">  Then output is `[4 x 3]`:</span>
<span class="sd">  ```</span>
<span class="sd">  output =</span>
<span class="sd">    [5.0 0.0 0.0]  // one_hot(0)</span>
<span class="sd">    [0.0 0.0 5.0]  // one_hot(2)</span>
<span class="sd">    [0.0 0.0 0.0]  // one_hot(-1)</span>
<span class="sd">    [0.0 5.0 0.0]  // one_hot(1)</span>
<span class="sd">  ```</span>

<span class="sd">  Suppose that</span>
<span class="sd">  ```</span>
<span class="sd">    indices = [0, 2, -1, 1]</span>
<span class="sd">    depth = 3</span>
<span class="sd">    on_value = 0.0</span>
<span class="sd">    off_value = 3.0</span>
<span class="sd">    axis = 0</span>
<span class="sd">  ```</span>

<span class="sd">  Then output is `[3 x 4]`:</span>
<span class="sd">  ```</span>
<span class="sd">  output =</span>
<span class="sd">    [0.0 3.0 3.0 3.0]</span>
<span class="sd">    [3.0 3.0 3.0 0.0]</span>
<span class="sd">    [3.0 3.0 3.0 3.0]</span>
<span class="sd">    [3.0 0.0 3.0 3.0]</span>
<span class="sd">  //  ^                one_hot(0)</span>
<span class="sd">  //      ^            one_hot(2)</span>
<span class="sd">  //          ^        one_hot(-1)</span>
<span class="sd">  //              ^    one_hot(1)</span>
<span class="sd">  ```</span>

<span class="sd">  Suppose that</span>
<span class="sd">  ```</span>
<span class="sd">    indices = [[0, 2], [1, -1]]</span>
<span class="sd">    depth = 3</span>
<span class="sd">    on_value = 1.0</span>
<span class="sd">    off_value = 0.0</span>
<span class="sd">    axis = -1</span>
<span class="sd">  ```</span>

<span class="sd">  Then output is `[2 x 2 x 3]`:</span>
<span class="sd">  ```</span>
<span class="sd">  output =</span>
<span class="sd">    [</span>
<span class="sd">      [1.0, 0.0, 0.0]  // one_hot(0)</span>
<span class="sd">      [0.0, 0.0, 1.0]  // one_hot(2)</span>
<span class="sd">    ][</span>
<span class="sd">      [0.0, 1.0, 0.0]  // one_hot(1)</span>
<span class="sd">      [0.0, 0.0, 0.0]  // one_hot(-1)</span>
<span class="sd">    ]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `uint8`, `int32`, `int64`.</span>
<span class="sd">      A tensor of indices.</span>
<span class="sd">    depth: A `Tensor` of type `int32`.</span>
<span class="sd">      A scalar defining the depth of the one hot dimension.</span>
<span class="sd">    on_value: A `Tensor`.</span>
<span class="sd">      A scalar defining the value to fill in output when `indices[j] = i`.</span>
<span class="sd">    off_value: A `Tensor`. Must have the same type as `on_value`.</span>
<span class="sd">      A scalar defining the value to fill in output when `indices[j] != i`.</span>
<span class="sd">    axis: An optional `int`. Defaults to `-1`.</span>
<span class="sd">      The axis to fill (default: -1, a new inner-most axis).</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `on_value`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;OneHot&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">on_value</span><span class="p">,</span> <span class="n">off_value</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">one_hot_eager_fallback</span><span class="p">(</span>
            <span class="n">indices</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">on_value</span><span class="p">,</span> <span class="n">off_value</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;OneHot&quot;</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span> <span class="n">on_value</span><span class="o">=</span><span class="n">on_value</span><span class="p">,</span>
                  <span class="n">off_value</span><span class="o">=</span><span class="n">off_value</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;axis&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
              <span class="s2">&quot;TI&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;TI&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;OneHot&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">OneHot</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.OneHot&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">one_hot</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">one_hot_eager_fallback</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">on_value</span><span class="p">,</span> <span class="n">off_value</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">on_value</span><span class="p">,</span> <span class="n">off_value</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">on_value</span><span class="p">,</span> <span class="n">off_value</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_attr_TI</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="n">depth</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">indices</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">on_value</span><span class="p">,</span> <span class="n">off_value</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;TI&quot;</span><span class="p">,</span> <span class="n">_attr_TI</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;OneHot&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;OneHot&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns a tensor of ones with the same shape and type as x.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`, `complex64`, `complex128`, `bool`.</span>
<span class="sd">      a tensor of type T.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;OnesLike&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ones_like_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;OnesLike&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;OnesLike&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">OnesLike</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.OnesLike&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">ones_like</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">ones_like_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;OnesLike&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;OnesLike&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">pack</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Packs a list of `N` rank-`R` tensors into one rank-`(R+1)` tensor.</span>

<span class="sd">  Packs the `N` tensors in `values` into a tensor with rank one higher than each</span>
<span class="sd">  tensor in `values`, by packing them along the `axis` dimension.</span>
<span class="sd">  Given a list of tensors of shape `(A, B, C)`;</span>

<span class="sd">  if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.</span>
<span class="sd">  if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.</span>
<span class="sd">  Etc.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;x&#39; is [1, 4]</span>
<span class="sd">  # &#39;y&#39; is [2, 5]</span>
<span class="sd">  # &#39;z&#39; is [3, 6]</span>
<span class="sd">  pack([x, y, z]) =&gt; [[1, 4], [2, 5], [3, 6]]  # Pack along first dim.</span>
<span class="sd">  pack([x, y, z], axis=1) =&gt; [[1, 2, 3], [4, 5, 6]]</span>
<span class="sd">  ```</span>

<span class="sd">  This is the opposite of `unpack`.</span>

<span class="sd">  Args:</span>
<span class="sd">    values: A list of at least 1 `Tensor` objects with the same type.</span>
<span class="sd">      Must be of same shape and type.</span>
<span class="sd">    axis: An optional `int`. Defaults to `0`.</span>
<span class="sd">      Dimension along which to pack.  Negative values wrap around, so the</span>
<span class="sd">      valid range is `[-(R+1), R+1)`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `values`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Pack&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="n">values</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pack_eager_fallback</span><span class="p">(</span>
            <span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;values&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;pack&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">values</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Pack&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
              <span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;axis&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Pack&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Pack</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Pack&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">pack</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">pack_eager_fallback</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;values&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;pack&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">values</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">values</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_attr_N</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Pack&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Pack&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">pad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pads a tensor with zeros.</span>

<span class="sd">  This operation pads a `input` with zeros according to the `paddings` you</span>
<span class="sd">  specify. `paddings` is an integer tensor with shape `[Dn, 2]`, where n is the</span>
<span class="sd">  rank of `input`. For each dimension D of `input`, `paddings[D, 0]` indicates</span>
<span class="sd">  how many zeros to add before the contents of `input` in that dimension, and</span>
<span class="sd">  `paddings[D, 1]` indicates how many zeros to add after the contents of `input`</span>
<span class="sd">  in that dimension.</span>

<span class="sd">  The padded size of each dimension D of the output is:</span>

<span class="sd">  `paddings(D, 0) + input.dim_size(D) + paddings(D, 1)`</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;t&#39; is [[1, 1], [2, 2]]</span>
<span class="sd">  # &#39;paddings&#39; is [[1, 1], [2, 2]]</span>
<span class="sd">  # rank of &#39;t&#39; is 2</span>
<span class="sd">  pad(t, paddings) ==&gt; [[0, 0, 0, 0, 0, 0]</span>
<span class="sd">                        [0, 0, 1, 1, 0, 0]</span>
<span class="sd">                        [0, 0, 2, 2, 0, 0]</span>
<span class="sd">                        [0, 0, 0, 0, 0, 0]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Pad&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pad_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Pad&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="o">=</span><span class="n">paddings</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tpaddings&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tpaddings&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Pad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Pad</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Pad&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">pad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">pad_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tpaddings</span><span class="p">,</span> <span class="p">(</span><span class="n">paddings</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">paddings</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tpaddings&quot;</span><span class="p">,</span> <span class="n">_attr_Tpaddings</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Pad&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Pad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">pad_v2</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">constant_values</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pads a tensor.</span>

<span class="sd">  This operation pads `input` according to the `paddings` and `constant_values`</span>
<span class="sd">  you specify. `paddings` is an integer tensor with shape `[Dn, 2]`, where n is</span>
<span class="sd">  the rank of `input`. For each dimension D of `input`, `paddings[D, 0]` indicates</span>
<span class="sd">  how many padding values to add before the contents of `input` in that dimension,</span>
<span class="sd">  and `paddings[D, 1]` indicates how many padding values to add after the contents</span>
<span class="sd">  of `input` in that dimension. `constant_values` is a scalar tensor of the same</span>
<span class="sd">  type as `input` that indicates the value to use for padding `input`.</span>

<span class="sd">  The padded size of each dimension D of the output is:</span>

<span class="sd">  `paddings(D, 0) + input.dim_size(D) + paddings(D, 1)`</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;t&#39; is [[1, 1], [2, 2]]</span>
<span class="sd">  # &#39;paddings&#39; is [[1, 1], [2, 2]]</span>
<span class="sd">  # &#39;constant_values&#39; is 0</span>
<span class="sd">  # rank of &#39;t&#39; is 2</span>
<span class="sd">  pad(t, paddings) ==&gt; [[0, 0, 0, 0, 0, 0]</span>
<span class="sd">                        [0, 0, 1, 1, 0, 0]</span>
<span class="sd">                        [0, 0, 2, 2, 0, 0]</span>
<span class="sd">                        [0, 0, 0, 0, 0, 0]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    constant_values: A `Tensor`. Must have the same type as `input`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;PadV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">constant_values</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pad_v2_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">constant_values</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;PadV2&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="o">=</span><span class="n">paddings</span><span class="p">,</span>
                 <span class="n">constant_values</span><span class="o">=</span><span class="n">constant_values</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tpaddings&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tpaddings&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;PadV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">PadV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.PadV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">pad_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">pad_v2_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">constant_values</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">constant_values</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">constant_values</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_attr_Tpaddings</span><span class="p">,</span> <span class="p">(</span><span class="n">paddings</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">paddings</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">constant_values</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tpaddings&quot;</span><span class="p">,</span> <span class="n">_attr_Tpaddings</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;PadV2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;PadV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">parallel_concat</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Concatenates a list of `N` tensors along the first dimension.</span>

<span class="sd">  The input tensors are all required to have size 1 in the first dimension.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;x&#39; is [[1, 4]]</span>
<span class="sd">  # &#39;y&#39; is [[2, 5]]</span>
<span class="sd">  # &#39;z&#39; is [[3, 6]]</span>
<span class="sd">  parallel_concat([x, y, z]) =&gt; [[1, 4], [2, 5], [3, 6]]  # Pack along first dim.</span>
<span class="sd">  ```</span>

<span class="sd">  The difference between concat and parallel_concat is that concat requires all</span>
<span class="sd">  of the inputs be computed before the operation will begin but doesn&#39;t require</span>
<span class="sd">  that the input shapes be known during graph construction.  Parallel concat</span>
<span class="sd">  will copy pieces of the input into the output as they become available, in</span>
<span class="sd">  some situations this can provide a performance benefit.</span>

<span class="sd">  Args:</span>
<span class="sd">    values: A list of at least 1 `Tensor` objects with the same type.</span>
<span class="sd">      Tensors to be concatenated. All must have size 1 in the first dimension</span>
<span class="sd">      and same shape.</span>
<span class="sd">    shape: A `tf.TensorShape` or list of `ints`.</span>
<span class="sd">      the final shape of the result; should be equal to the shapes of any input</span>
<span class="sd">      but with the number of input values in the first dimension.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `values`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ParallelConcat&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">parallel_concat_eager_fallback</span><span class="p">(</span>
            <span class="n">values</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;values&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;parallel_concat&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">values</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ParallelConcat&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
              <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ParallelConcat&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ParallelConcat</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ParallelConcat&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">parallel_concat</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">parallel_concat_eager_fallback</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;values&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;parallel_concat&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">values</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">values</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_attr_N</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ParallelConcat&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ParallelConcat&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">placeholder</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;A placeholder op for a value that will be fed into the computation.</span>

<span class="sd">  N.B. This operation will fail with an error if it is executed. It is</span>
<span class="sd">  intended as a way to represent a value that will always be fed, and to</span>
<span class="sd">  provide attrs that enable the fed value to be checked at runtime.</span>

<span class="sd">  Args:</span>
<span class="sd">    dtype: A `tf.DType`. The type of elements in the tensor.</span>
<span class="sd">    shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.</span>
<span class="sd">      (Optional) The shape of the tensor. If the shape has 0 dimensions, the</span>
<span class="sd">      shape is unconstrained.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `dtype`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Placeholder&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">placeholder_eager_fallback</span><span class="p">(</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Placeholder&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">),</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Placeholder&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Placeholder</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Placeholder&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">placeholder</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">placeholder_eager_fallback</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Placeholder&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Placeholder&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">placeholder_v2</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;A placeholder op for a value that will be fed into the computation.</span>

<span class="sd">  N.B. This operation will fail with an error if it is executed. It is</span>
<span class="sd">  intended as a way to represent a value that will always be fed, and to</span>
<span class="sd">  provide attrs that enable the fed value to be checked at runtime.</span>

<span class="sd">  Args:</span>
<span class="sd">    dtype: A `tf.DType`. The type of elements in the tensor.</span>
<span class="sd">    shape: A `tf.TensorShape` or list of `ints`.</span>
<span class="sd">      The shape of the tensor. The shape can be any partially-specified</span>
<span class="sd">      shape.  To be unconstrained, pass in a shape with unknown rank.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `dtype`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;PlaceholderV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">placeholder_v2_eager_fallback</span><span class="p">(</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;PlaceholderV2&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">),</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;PlaceholderV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">PlaceholderV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.PlaceholderV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">placeholder_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">placeholder_v2_eager_fallback</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">)</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;PlaceholderV2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;PlaceholderV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">placeholder_with_default</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;A placeholder op that passes through `input` when its output is not fed.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. The default value to produce when `output` is not fed.</span>
<span class="sd">    shape: A `tf.TensorShape` or list of `ints`.</span>
<span class="sd">      The (possibly partial) shape of the tensor.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;PlaceholderWithDefault&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">placeholder_with_default_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;PlaceholderWithDefault&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">),</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;shape&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;PlaceholderWithDefault&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">PlaceholderWithDefault</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.PlaceholderWithDefault&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">placeholder_with_default</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">placeholder_with_default_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span>
  <span class="n">_attr_dtype</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="n">_attr_dtype</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;PlaceholderWithDefault&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;PlaceholderWithDefault&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">prevent_gradient</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;An identity op that triggers an error if a gradient is requested.</span>

<span class="sd">  When executed in a graph, this op outputs its input tensor as-is.</span>

<span class="sd">  When building ops to compute gradients, the TensorFlow gradient system</span>
<span class="sd">  will return an error when trying to lookup the gradient of this op,</span>
<span class="sd">  because no gradient must ever be registered for this function.  This</span>
<span class="sd">  op exists to prevent subtle bugs from silently returning unimplemented</span>
<span class="sd">  gradients in some corner cases.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. any tensor.</span>
<span class="sd">    message: An optional `string`. Defaults to `&quot;&quot;`.</span>
<span class="sd">      Will be printed in the error when anyone tries to differentiate</span>
<span class="sd">      this operation.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;PreventGradient&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;message&quot;</span><span class="p">,</span> <span class="n">message</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">prevent_gradient_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">message</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">message</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
  <span class="n">message</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="s2">&quot;message&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;PreventGradient&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">message</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;message&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;message&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;PreventGradient&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">PreventGradient</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.PreventGradient&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">prevent_gradient</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">prevent_gradient_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">message</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">message</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
  <span class="n">message</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="s2">&quot;message&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;message&quot;</span><span class="p">,</span> <span class="n">message</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;PreventGradient&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;PreventGradient&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">quantize_and_dequantize</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">signed_input</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">range_given</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">input_min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">input_max</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Use QuantizeAndDequantizeV2 instead.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    signed_input: An optional `bool`. Defaults to `True`.</span>
<span class="sd">    num_bits: An optional `int`. Defaults to `8`.</span>
<span class="sd">    range_given: An optional `bool`. Defaults to `False`.</span>
<span class="sd">    input_min: An optional `float`. Defaults to `0`.</span>
<span class="sd">    input_max: An optional `float`. Defaults to `0`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;QuantizeAndDequantize&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;signed_input&quot;</span><span class="p">,</span> <span class="n">signed_input</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span>
        <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;range_given&quot;</span><span class="p">,</span> <span class="n">range_given</span><span class="p">,</span> <span class="s2">&quot;input_min&quot;</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span>
        <span class="s2">&quot;input_max&quot;</span><span class="p">,</span> <span class="n">input_max</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">quantize_and_dequantize_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">signed_input</span><span class="o">=</span><span class="n">signed_input</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
            <span class="n">range_given</span><span class="o">=</span><span class="n">range_given</span><span class="p">,</span> <span class="n">input_min</span><span class="o">=</span><span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="o">=</span><span class="n">input_max</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">signed_input</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">signed_input</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">signed_input</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">signed_input</span><span class="p">,</span> <span class="s2">&quot;signed_input&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">range_given</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">range_given</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">range_given</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">range_given</span><span class="p">,</span> <span class="s2">&quot;range_given&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">input_min</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">input_min</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">input_min</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">input_min</span><span class="p">,</span> <span class="s2">&quot;input_min&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">input_max</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">input_max</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">input_max</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">input_max</span><span class="p">,</span> <span class="s2">&quot;input_max&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeAndDequantize&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">signed_input</span><span class="o">=</span><span class="n">signed_input</span><span class="p">,</span>
                                 <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span> <span class="n">range_given</span><span class="o">=</span><span class="n">range_given</span><span class="p">,</span>
                                 <span class="n">input_min</span><span class="o">=</span><span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="o">=</span><span class="n">input_max</span><span class="p">,</span>
                                 <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;signed_input&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;signed_input&quot;</span><span class="p">),</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">),</span> <span class="s2">&quot;range_given&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;range_given&quot;</span><span class="p">),</span> <span class="s2">&quot;input_min&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;input_min&quot;</span><span class="p">),</span> <span class="s2">&quot;input_max&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;input_max&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeAndDequantize&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">QuantizeAndDequantize</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.QuantizeAndDequantize&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">quantize_and_dequantize</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">quantize_and_dequantize_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">signed_input</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="n">range_given</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">signed_input</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">signed_input</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">signed_input</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">signed_input</span><span class="p">,</span> <span class="s2">&quot;signed_input&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">range_given</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">range_given</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">range_given</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">range_given</span><span class="p">,</span> <span class="s2">&quot;range_given&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">input_min</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">input_min</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">input_min</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">input_min</span><span class="p">,</span> <span class="s2">&quot;input_min&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">input_max</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">input_max</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">input_max</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">input_max</span><span class="p">,</span> <span class="s2">&quot;input_max&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;signed_input&quot;</span><span class="p">,</span> <span class="n">signed_input</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;range_given&quot;</span><span class="p">,</span>
  <span class="n">range_given</span><span class="p">,</span> <span class="s2">&quot;input_min&quot;</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="s2">&quot;input_max&quot;</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;QuantizeAndDequantize&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeAndDequantize&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">quantize_and_dequantize_v2</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">signed_input</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">range_given</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">round_mode</span><span class="o">=</span><span class="s2">&quot;HALF_TO_EVEN&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Quantizes then dequantizes a tensor.</span>

<span class="sd">  This op simulates the precision loss from the quantized forward pass by:</span>

<span class="sd">  1. Quantizing the tensor to fixed point numbers, which should match the target</span>
<span class="sd">     quantization method when it is used in inference.</span>
<span class="sd">  2. Dequantizing it back to floating point numbers for the following ops, most</span>
<span class="sd">     likely matmul.</span>

<span class="sd">  There are different ways to quantize. This version uses only scaling, so 0.0</span>
<span class="sd">  maps to 0.</span>

<span class="sd">  From the specified &#39;num_bits&#39; in the quantized output type, it determines</span>
<span class="sd">  minimum and maximum representable quantized values.</span>

<span class="sd">  e.g.</span>

<span class="sd">  *   [-128, 127] for signed, num_bits = 8, or</span>
<span class="sd">  *   [0, 255] for unsigned, num_bits = 8.</span>

<span class="sd">  If range_given == False, the initial input_min, input_max will be determined</span>
<span class="sd">  automatically as the minimum and maximum values in the input tensor, otherwise</span>
<span class="sd">  the specified values of input_min, input_max are used.</span>

<span class="sd">  Note: If the input_min, input_max are specified, they do not need to equal the</span>
<span class="sd">  actual minimum and maximum values in the tensor. e.g. in some cases it may be</span>
<span class="sd">  beneficial to specify these values such that the low probability extremes of the</span>
<span class="sd">  input distribution are clipped.</span>

<span class="sd">  This op determines the maximum scale_factor that would map the initial</span>
<span class="sd">  [input_min, input_max] range to a range that lies within the representable</span>
<span class="sd">  quantized range.</span>

<span class="sd">  It determines the scale from one of input_min and input_max, then updates the</span>
<span class="sd">  other one to maximize the representable range.</span>

<span class="sd">  e.g.</span>

<span class="sd">  *   if the output is signed, num_bits = 8, [input_min, input_max] = [-10.0,</span>
<span class="sd">      5.0]: it would use a scale_factor of -128 / -10.0 = 12.8 In this case, it</span>
<span class="sd">      would update input_max to be 127 / 12.8 = 9.921875</span>
<span class="sd">  *   if the output is signed, num_bits = 8, [input_min, input_max] = [-10.0,</span>
<span class="sd">      10.0]: it would use a scale_factor of 127 / 10.0 = 12.7 In this case, it</span>
<span class="sd">      would update input_min to be 128.0 / 12.7 = -10.07874</span>
<span class="sd">  *   if the output is unsigned, input_min is forced to be 0, and only the</span>
<span class="sd">      specified input_max is used.</span>

<span class="sd">  After determining the scale_factor and updating the input range, it applies the</span>
<span class="sd">  following to each value in the &#39;input&#39; tensor.</span>

<span class="sd">  output = round(clamp(value, input_min, input_max) * scale_factor) / scale_factor.</span>

<span class="sd">  The above round function rounds the value based on the given round_mode.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">      Tensor to quantize and then dequantize.</span>
<span class="sd">    input_min: A `Tensor`. Must have the same type as `input`.</span>
<span class="sd">      If `range_given == True`, this specifies the minimum input value that needs to</span>
<span class="sd">      be represented, otherwise it is determined from the min value of the `input`</span>
<span class="sd">      tensor.</span>
<span class="sd">    input_max: A `Tensor`. Must have the same type as `input`.</span>
<span class="sd">      If `range_given == True`, this specifies the maximum input value that needs to</span>
<span class="sd">      be represented, otherwise it is determined from the max value of the `input`</span>
<span class="sd">      tensor.</span>
<span class="sd">    signed_input: An optional `bool`. Defaults to `True`.</span>
<span class="sd">      Whether the quantization is signed or unsigned. (actually this parameter should</span>
<span class="sd">      have been called &lt;b&gt;`signed_output`&lt;/b&gt;)</span>
<span class="sd">    num_bits: An optional `int`. Defaults to `8`.</span>
<span class="sd">      The bitwidth of the quantization.</span>
<span class="sd">    range_given: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      Whether the range is given or should be determined from the `input` tensor.</span>
<span class="sd">    round_mode: An optional `string` from: `&quot;HALF_TO_EVEN&quot;, &quot;HALF_UP&quot;`. Defaults to `&quot;HALF_TO_EVEN&quot;`.</span>
<span class="sd">      The &#39;round_mode&#39; attribute controls which rounding tie-breaking algorithm is</span>
<span class="sd">      used when rounding float values to their quantized equivalents. The following</span>
<span class="sd">      rounding modes are currently supported:</span>

<span class="sd">      *   HALF_TO_EVEN: this is the default round_mode.</span>
<span class="sd">      *   HALF_UP: round towards positive. In this mode 7.5 rounds up to 8 and -7.5</span>
<span class="sd">          rounds up to -7.</span>
<span class="sd">    narrow_range: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If True, then the absolute value of the quantized minimum value is the same as</span>
<span class="sd">      the quantized maximum value, instead of 1 greater.</span>
<span class="sd">      i.e. for 8 bit quantization, the minimum value is -127 instead of -128.</span>
<span class="sd">    axis: An optional `int`. Defaults to `-1`.</span>
<span class="sd">      If specified, this axis is treated as a channel or slice axis, and a separate</span>
<span class="sd">      quantization range is used for each channel or slice along this axis.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;QuantizeAndDequantizeV2&quot;</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="s2">&quot;signed_input&quot;</span><span class="p">,</span>
        <span class="n">signed_input</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;range_given&quot;</span><span class="p">,</span> <span class="n">range_given</span><span class="p">,</span>
        <span class="s2">&quot;round_mode&quot;</span><span class="p">,</span> <span class="n">round_mode</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">quantize_and_dequantize_v2_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">signed_input</span><span class="o">=</span><span class="n">signed_input</span><span class="p">,</span>
            <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span> <span class="n">range_given</span><span class="o">=</span><span class="n">range_given</span><span class="p">,</span> <span class="n">round_mode</span><span class="o">=</span><span class="n">round_mode</span><span class="p">,</span>
            <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">signed_input</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">signed_input</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">signed_input</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">signed_input</span><span class="p">,</span> <span class="s2">&quot;signed_input&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">range_given</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">range_given</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">range_given</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">range_given</span><span class="p">,</span> <span class="s2">&quot;range_given&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">round_mode</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">round_mode</span> <span class="o">=</span> <span class="s2">&quot;HALF_TO_EVEN&quot;</span>
  <span class="n">round_mode</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">round_mode</span><span class="p">,</span> <span class="s2">&quot;round_mode&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeAndDequantizeV2&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="o">=</span><span class="n">input_min</span><span class="p">,</span>
                                   <span class="n">input_max</span><span class="o">=</span><span class="n">input_max</span><span class="p">,</span>
                                   <span class="n">signed_input</span><span class="o">=</span><span class="n">signed_input</span><span class="p">,</span>
                                   <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span> <span class="n">range_given</span><span class="o">=</span><span class="n">range_given</span><span class="p">,</span>
                                   <span class="n">round_mode</span><span class="o">=</span><span class="n">round_mode</span><span class="p">,</span>
                                   <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
                                   <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;signed_input&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;signed_input&quot;</span><span class="p">),</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;num_bits&quot;</span><span class="p">),</span> <span class="s2">&quot;range_given&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;range_given&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
              <span class="s2">&quot;round_mode&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;round_mode&quot;</span><span class="p">),</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;narrow_range&quot;</span><span class="p">),</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;axis&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeAndDequantizeV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">QuantizeAndDequantizeV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.QuantizeAndDequantizeV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">quantize_and_dequantize_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">quantize_and_dequantize_v2_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">signed_input</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="n">range_given</span><span class="p">,</span> <span class="n">round_mode</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">signed_input</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">signed_input</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">signed_input</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">signed_input</span><span class="p">,</span> <span class="s2">&quot;signed_input&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">num_bits</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">num_bits</span> <span class="o">=</span> <span class="mi">8</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">range_given</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">range_given</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">range_given</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">range_given</span><span class="p">,</span> <span class="s2">&quot;range_given&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">round_mode</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">round_mode</span> <span class="o">=</span> <span class="s2">&quot;HALF_TO_EVEN&quot;</span>
  <span class="n">round_mode</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">round_mode</span><span class="p">,</span> <span class="s2">&quot;round_mode&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;signed_input&quot;</span><span class="p">,</span> <span class="n">signed_input</span><span class="p">,</span> <span class="s2">&quot;num_bits&quot;</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="s2">&quot;range_given&quot;</span><span class="p">,</span>
  <span class="n">range_given</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;round_mode&quot;</span><span class="p">,</span> <span class="n">round_mode</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
  <span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;QuantizeAndDequantizeV2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeAndDequantizeV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">quantize_and_dequantize_v3</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="n">signed_input</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">range_given</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Quantizes then dequantizes a tensor.</span>

<span class="sd">  This is almost identical to QuantizeAndDequantizeV2, except that num_bits is a</span>
<span class="sd">  tensor, so its value can change during training.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.</span>
<span class="sd">    input_min: A `Tensor`. Must have the same type as `input`.</span>
<span class="sd">    input_max: A `Tensor`. Must have the same type as `input`.</span>
<span class="sd">    num_bits: A `Tensor` of type `int32`.</span>
<span class="sd">    signed_input: An optional `bool`. Defaults to `True`.</span>
<span class="sd">    range_given: An optional `bool`. Defaults to `True`.</span>
<span class="sd">    narrow_range: An optional `bool`. Defaults to `False`.</span>
<span class="sd">    axis: An optional `int`. Defaults to `-1`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;QuantizeAndDequantizeV3&quot;</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span>
        <span class="s2">&quot;signed_input&quot;</span><span class="p">,</span> <span class="n">signed_input</span><span class="p">,</span> <span class="s2">&quot;range_given&quot;</span><span class="p">,</span> <span class="n">range_given</span><span class="p">,</span>
        <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">quantize_and_dequantize_v3_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="n">signed_input</span><span class="o">=</span><span class="n">signed_input</span><span class="p">,</span>
            <span class="n">range_given</span><span class="o">=</span><span class="n">range_given</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">signed_input</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">signed_input</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">signed_input</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">signed_input</span><span class="p">,</span> <span class="s2">&quot;signed_input&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">range_given</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">range_given</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">range_given</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">range_given</span><span class="p">,</span> <span class="s2">&quot;range_given&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeAndDequantizeV3&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="o">=</span><span class="n">input_min</span><span class="p">,</span>
                                   <span class="n">input_max</span><span class="o">=</span><span class="n">input_max</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="n">num_bits</span><span class="p">,</span>
                                   <span class="n">signed_input</span><span class="o">=</span><span class="n">signed_input</span><span class="p">,</span>
                                   <span class="n">range_given</span><span class="o">=</span><span class="n">range_given</span><span class="p">,</span>
                                   <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
                                   <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;signed_input&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;signed_input&quot;</span><span class="p">),</span>
              <span class="s2">&quot;range_given&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;range_given&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;narrow_range&quot;</span><span class="p">),</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;axis&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeAndDequantizeV3&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">QuantizeAndDequantizeV3</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.QuantizeAndDequantizeV3&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">quantize_and_dequantize_v3</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">quantize_and_dequantize_v3_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">,</span> <span class="n">signed_input</span><span class="p">,</span> <span class="n">range_given</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">signed_input</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">signed_input</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">signed_input</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">signed_input</span><span class="p">,</span> <span class="s2">&quot;signed_input&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">range_given</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">range_given</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="n">range_given</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">range_given</span><span class="p">,</span> <span class="s2">&quot;range_given&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">num_bits</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">num_bits</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">num_bits</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;signed_input&quot;</span><span class="p">,</span> <span class="n">signed_input</span><span class="p">,</span> <span class="s2">&quot;range_given&quot;</span><span class="p">,</span> <span class="n">range_given</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;QuantizeAndDequantizeV3&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeAndDequantizeV3&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_QuantizeV2Output</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;QuantizeV2&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">,</span> <span class="s2">&quot;output_min&quot;</span><span class="p">,</span> <span class="s2">&quot;output_max&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">quantize_v2</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">min_range</span><span class="p">,</span> <span class="n">max_range</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;MIN_COMBINED&quot;</span><span class="p">,</span> <span class="n">round_mode</span><span class="o">=</span><span class="s2">&quot;HALF_AWAY_FROM_ZERO&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">ensure_minimum_range</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Quantize the &#39;input&#39; tensor of type float to &#39;output&#39; tensor of type &#39;T&#39;.</span>

<span class="sd">  [min_range, max_range] are scalar floats that specify the range for</span>
<span class="sd">  the &#39;input&#39; data. The &#39;mode&#39; attribute controls exactly which calculations are</span>
<span class="sd">  used to convert the float values to their quantized equivalents.  The</span>
<span class="sd">  &#39;round_mode&#39; attribute controls which rounding tie-breaking algorithm is used</span>
<span class="sd">  when rounding float values to their quantized equivalents.</span>

<span class="sd">  In &#39;MIN_COMBINED&#39; mode, each value of the tensor will undergo the following:</span>

<span class="sd">  ```</span>
<span class="sd">  out[i] = (in[i] - min_range) * range(T) / (max_range - min_range)</span>
<span class="sd">  if T == qint8: out[i] -= (range(T) + 1) / 2.0</span>
<span class="sd">  ```</span>

<span class="sd">  here `range(T) = numeric_limits&lt;T&gt;::max() - numeric_limits&lt;T&gt;::min()`</span>

<span class="sd">  *MIN_COMBINED Mode Example*</span>

<span class="sd">  Assume the input is type float and has a possible range of [0.0, 6.0] and the</span>
<span class="sd">  output type is quint8 ([0, 255]). The min_range and max_range values should be</span>
<span class="sd">  specified as 0.0 and 6.0. Quantizing from float to quint8 will multiply each</span>
<span class="sd">  value of the input by 255/6 and cast to quint8.</span>

<span class="sd">  If the output type was qint8 ([-128, 127]), the operation will additionally</span>
<span class="sd">  subtract each value by 128 prior to casting, so that the range of values aligns</span>
<span class="sd">  with the range of qint8.</span>

<span class="sd">  If the mode is &#39;MIN_FIRST&#39;, then this approach is used:</span>

<span class="sd">  ```</span>
<span class="sd">  num_discrete_values = 1 &lt;&lt; (# of bits in T)</span>
<span class="sd">  range_adjust = num_discrete_values / (num_discrete_values - 1)</span>
<span class="sd">  range = (range_max - range_min) * range_adjust</span>
<span class="sd">  range_scale = num_discrete_values / range</span>
<span class="sd">  quantized = round(input * range_scale) - round(range_min * range_scale) +</span>
<span class="sd">    numeric_limits&lt;T&gt;::min()</span>
<span class="sd">  quantized = max(quantized, numeric_limits&lt;T&gt;::min())</span>
<span class="sd">  quantized = min(quantized, numeric_limits&lt;T&gt;::max())</span>
<span class="sd">  ```</span>

<span class="sd">  The biggest difference between this and MIN_COMBINED is that the minimum range</span>
<span class="sd">  is rounded first, before it&#39;s subtracted from the rounded value. With</span>
<span class="sd">  MIN_COMBINED, a small bias is introduced where repeated iterations of quantizing</span>
<span class="sd">  and dequantizing will introduce a larger and larger error.</span>

<span class="sd">  *SCALED mode Example*</span>

<span class="sd">  `SCALED` mode matches the quantization approach used in</span>
<span class="sd">  `QuantizeAndDequantize{V2|V3}`.</span>

<span class="sd">  If the mode is `SCALED`, the quantization is performed by multiplying each</span>
<span class="sd">  input value by a scaling_factor.</span>
<span class="sd">  The scaling_factor is determined from `min_range` and `max_range` to be as large</span>
<span class="sd">  as possible such that the range from `min_range` to `max_range` is representable</span>
<span class="sd">  within values of type T.</span>

<span class="sd">  ```c++</span>

<span class="sd">    const int min_T = std::numeric_limits&lt;T&gt;::min();</span>
<span class="sd">    const int max_T = std::numeric_limits&lt;T&gt;::max();</span>
<span class="sd">    const float max_float = std::numeric_limits&lt;float&gt;::max();</span>

<span class="sd">    const float scale_factor_from_min_side =</span>
<span class="sd">        (min_T * min_range &gt; 0) ? min_T / min_range : max_float;</span>
<span class="sd">    const float scale_factor_from_max_side =</span>
<span class="sd">        (max_T * max_range &gt; 0) ? max_T / max_range : max_float;</span>

<span class="sd">    const float scale_factor = std::min(scale_factor_from_min_side,</span>
<span class="sd">                                        scale_factor_from_max_side);</span>
<span class="sd">  ```</span>

<span class="sd">  We next use the scale_factor to adjust min_range and max_range as follows:</span>

<span class="sd">  ```c++</span>
<span class="sd">        min_range = min_T / scale_factor;</span>
<span class="sd">        max_range = max_T / scale_factor;</span>
<span class="sd">  ```</span>


<span class="sd">  e.g. if T = qint8, and initially min_range = -10, and max_range = 9, we would</span>
<span class="sd">  compare -128/-10.0 = 12.8 to 127/9.0 = 14.11, and set scaling_factor = 12.8</span>
<span class="sd">  In this case, min_range would remain -10, but max_range would be adjusted to</span>
<span class="sd">  127 / 12.8 = 9.921875</span>

<span class="sd">  So we will quantize input values in the range (-10, 9.921875) to (-128, 127).</span>

<span class="sd">  The input tensor can now be quantized by clipping values to the range</span>
<span class="sd">  `min_range` to `max_range`, then multiplying by scale_factor as follows:</span>

<span class="sd">  ```c++</span>
<span class="sd">  result = round(min(max_range, max(min_range, input)) * scale_factor)</span>
<span class="sd">  ```</span>

<span class="sd">  The adjusted `min_range` and `max_range` are returned as outputs 2 and 3 of</span>
<span class="sd">  this operation. These outputs should be used as the range for any further</span>
<span class="sd">  calculations.</span>


<span class="sd">  *narrow_range (bool) attribute*</span>

<span class="sd">  If true, we do not use the minimum quantized value.</span>
<span class="sd">  i.e. for int8 the quantized output, it would be restricted to the range</span>
<span class="sd">  -127..127 instead of the full -128..127 range.</span>
<span class="sd">  This is provided for compatibility with certain inference backends.</span>
<span class="sd">  (Only applies to SCALED mode)</span>


<span class="sd">  *axis (int) attribute*</span>

<span class="sd">  An optional `axis` attribute can specify a dimension index of the input tensor,</span>
<span class="sd">  such that quantization ranges will be calculated and applied separately for each</span>
<span class="sd">  slice of the tensor along that dimension. This is useful for per-channel</span>
<span class="sd">  quantization.</span>

<span class="sd">  If axis is specified, min_range and max_range</span>

<span class="sd">  if `axis`=None, per-tensor quantization is performed as normal.</span>


<span class="sd">  *ensure_minimum_range (float) attribute*</span>

<span class="sd">  Ensures the minimum quantization range is at least this value.</span>
<span class="sd">  The legacy default value for this is 0.01, but it is strongly suggested to</span>
<span class="sd">  set it to 0 for new uses.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor` of type `float32`.</span>
<span class="sd">    min_range: A `Tensor` of type `float32`.</span>
<span class="sd">      The minimum value of the quantization range. This value may be adjusted by the</span>
<span class="sd">      op depending on other parameters. The adjusted value is written to `output_min`.</span>
<span class="sd">      If the `axis` attribute is specified, this must be a 1-D tensor whose size</span>
<span class="sd">      matches the `axis` dimension of the input and output tensors.</span>
<span class="sd">    max_range: A `Tensor` of type `float32`.</span>
<span class="sd">      The maximum value of the quantization range. This value may be adjusted by the</span>
<span class="sd">      op depending on other parameters. The adjusted value is written to `output_max`.</span>
<span class="sd">      If the `axis` attribute is specified, this must be a 1-D tensor whose size</span>
<span class="sd">      matches the `axis` dimension of the input and output tensors.</span>
<span class="sd">    T: A `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`.</span>
<span class="sd">    mode: An optional `string` from: `&quot;MIN_COMBINED&quot;, &quot;MIN_FIRST&quot;, &quot;SCALED&quot;`. Defaults to `&quot;MIN_COMBINED&quot;`.</span>
<span class="sd">    round_mode: An optional `string` from: `&quot;HALF_AWAY_FROM_ZERO&quot;, &quot;HALF_TO_EVEN&quot;`. Defaults to `&quot;HALF_AWAY_FROM_ZERO&quot;`.</span>
<span class="sd">    narrow_range: An optional `bool`. Defaults to `False`.</span>
<span class="sd">    axis: An optional `int`. Defaults to `-1`.</span>
<span class="sd">    ensure_minimum_range: An optional `float`. Defaults to `0.01`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (output, output_min, output_max).</span>

<span class="sd">    output: A `Tensor` of type `T`.</span>
<span class="sd">    output_min: A `Tensor` of type `float32`.</span>
<span class="sd">    output_max: A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;QuantizeV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">min_range</span><span class="p">,</span> <span class="n">max_range</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span>
        <span class="s2">&quot;round_mode&quot;</span><span class="p">,</span> <span class="n">round_mode</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span>
        <span class="s2">&quot;ensure_minimum_range&quot;</span><span class="p">,</span> <span class="n">ensure_minimum_range</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizeV2Output</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">quantize_v2_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">min_range</span><span class="p">,</span> <span class="n">max_range</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
            <span class="n">round_mode</span><span class="o">=</span><span class="n">round_mode</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
            <span class="n">ensure_minimum_range</span><span class="o">=</span><span class="n">ensure_minimum_range</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">mode</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;MIN_COMBINED&quot;</span>
  <span class="n">mode</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">round_mode</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">round_mode</span> <span class="o">=</span> <span class="s2">&quot;HALF_AWAY_FROM_ZERO&quot;</span>
  <span class="n">round_mode</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">round_mode</span><span class="p">,</span> <span class="s2">&quot;round_mode&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ensure_minimum_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ensure_minimum_range</span> <span class="o">=</span> <span class="mf">0.01</span>
  <span class="n">ensure_minimum_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">ensure_minimum_range</span><span class="p">,</span> <span class="s2">&quot;ensure_minimum_range&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeV2&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">min_range</span><span class="o">=</span><span class="n">min_range</span><span class="p">,</span> <span class="n">max_range</span><span class="o">=</span><span class="n">max_range</span><span class="p">,</span>
                      <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">round_mode</span><span class="o">=</span><span class="n">round_mode</span><span class="p">,</span>
                      <span class="n">narrow_range</span><span class="o">=</span><span class="n">narrow_range</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
                      <span class="n">ensure_minimum_range</span><span class="o">=</span><span class="n">ensure_minimum_range</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;mode&quot;</span><span class="p">),</span>
              <span class="s2">&quot;round_mode&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;round_mode&quot;</span><span class="p">),</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;narrow_range&quot;</span><span class="p">),</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;axis&quot;</span><span class="p">),</span> <span class="s2">&quot;ensure_minimum_range&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;ensure_minimum_range&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizeV2Output</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">QuantizeV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.QuantizeV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">quantize_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">quantize_v2_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">min_range</span><span class="p">,</span> <span class="n">max_range</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">round_mode</span><span class="p">,</span> <span class="n">narrow_range</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">ensure_minimum_range</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">mode</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;MIN_COMBINED&quot;</span>
  <span class="n">mode</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">round_mode</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">round_mode</span> <span class="o">=</span> <span class="s2">&quot;HALF_AWAY_FROM_ZERO&quot;</span>
  <span class="n">round_mode</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">round_mode</span><span class="p">,</span> <span class="s2">&quot;round_mode&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">narrow_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">narrow_range</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">narrow_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ensure_minimum_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ensure_minimum_range</span> <span class="o">=</span> <span class="mf">0.01</span>
  <span class="n">ensure_minimum_range</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">ensure_minimum_range</span><span class="p">,</span> <span class="s2">&quot;ensure_minimum_range&quot;</span><span class="p">)</span>
  <span class="nb">input</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">min_range</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">min_range</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">max_range</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">max_range</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">min_range</span><span class="p">,</span> <span class="n">max_range</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="s2">&quot;mode&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="s2">&quot;round_mode&quot;</span><span class="p">,</span> <span class="n">round_mode</span><span class="p">,</span> <span class="s2">&quot;narrow_range&quot;</span><span class="p">,</span>
  <span class="n">narrow_range</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;ensure_minimum_range&quot;</span><span class="p">,</span> <span class="n">ensure_minimum_range</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;QuantizeV2&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizeV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizeV2Output</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_QuantizedConcatOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;QuantizedConcat&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">,</span> <span class="s2">&quot;output_min&quot;</span><span class="p">,</span> <span class="s2">&quot;output_max&quot;</span><span class="p">])</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;quantization.quantized_concat&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;quantization.quantized_concat&#39;</span><span class="p">,</span> <span class="s1">&#39;quantized_concat&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;quantized_concat&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">quantized_concat</span><span class="p">(</span><span class="n">concat_dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">input_mins</span><span class="p">,</span> <span class="n">input_maxes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Concatenates quantized tensors along one dimension.</span>

<span class="sd">  Args:</span>
<span class="sd">    concat_dim: A `Tensor` of type `int32`.</span>
<span class="sd">      0-D.  The dimension along which to concatenate.  Must be in the</span>
<span class="sd">      range [0, rank(values)).</span>
<span class="sd">    values: A list of at least 2 `Tensor` objects with the same type.</span>
<span class="sd">      The `N` Tensors to concatenate. Their ranks and types must match,</span>
<span class="sd">      and their sizes must match in all dimensions except `concat_dim`.</span>
<span class="sd">    input_mins: A list with the same length as `values` of `Tensor` objects with type `float32`.</span>
<span class="sd">      The minimum scalar values for each of the input tensors.</span>
<span class="sd">    input_maxes: A list with the same length as `values` of `Tensor` objects with type `float32`.</span>
<span class="sd">      The maximum scalar values for each of the input tensors.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (output, output_min, output_max).</span>

<span class="sd">    output: A `Tensor`. Has the same type as `values`.</span>
<span class="sd">    output_min: A `Tensor` of type `float32`.</span>
<span class="sd">    output_max: A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;QuantizedConcat&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">concat_dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">input_mins</span><span class="p">,</span> <span class="n">input_maxes</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedConcatOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">quantized_concat_eager_fallback</span><span class="p">(</span>
            <span class="n">concat_dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">input_mins</span><span class="p">,</span> <span class="n">input_maxes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">quantized_concat</span><span class="p">,</span> <span class="n">concat_dim</span><span class="o">=</span><span class="n">concat_dim</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span>
                                <span class="n">input_mins</span><span class="o">=</span><span class="n">input_mins</span><span class="p">,</span>
                                <span class="n">input_maxes</span><span class="o">=</span><span class="n">input_maxes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;values&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;quantized_concat&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">values</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_mins</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;input_mins&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;quantized_concat&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">input_mins</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_mins</span><span class="p">)</span> <span class="o">!=</span> <span class="n">_attr_N</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="s2">&quot;List argument &#39;input_mins&#39; to &#39;quantized_concat&#39; Op with length </span><span class="si">%d</span><span class="s2"> &quot;</span>
        <span class="s2">&quot;must match length </span><span class="si">%d</span><span class="s2"> of argument &#39;values&#39;.&quot;</span> <span class="o">%</span>
        <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_mins</span><span class="p">),</span> <span class="n">_attr_N</span><span class="p">))</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_maxes</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;input_maxes&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;quantized_concat&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">input_maxes</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_maxes</span><span class="p">)</span> <span class="o">!=</span> <span class="n">_attr_N</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="s2">&quot;List argument &#39;input_maxes&#39; to &#39;quantized_concat&#39; Op with length </span><span class="si">%d</span><span class="s2"> &quot;</span>
        <span class="s2">&quot;must match length </span><span class="si">%d</span><span class="s2"> of argument &#39;values&#39;.&quot;</span> <span class="o">%</span>
        <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_maxes</span><span class="p">),</span> <span class="n">_attr_N</span><span class="p">))</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedConcat&quot;</span><span class="p">,</span> <span class="n">concat_dim</span><span class="o">=</span><span class="n">concat_dim</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span>
                           <span class="n">input_mins</span><span class="o">=</span><span class="n">input_mins</span><span class="p">,</span> <span class="n">input_maxes</span><span class="o">=</span><span class="n">input_maxes</span><span class="p">,</span>
                           <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">quantized_concat</span><span class="p">,</span> <span class="n">concat_dim</span><span class="o">=</span><span class="n">concat_dim</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span>
                            <span class="n">input_mins</span><span class="o">=</span><span class="n">input_mins</span><span class="p">,</span> <span class="n">input_maxes</span><span class="o">=</span><span class="n">input_maxes</span><span class="p">,</span>
                            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedConcat&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedConcatOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">QuantizedConcat</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.QuantizedConcat&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">quantized_concat</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">quantized_concat_eager_fallback</span><span class="p">(</span><span class="n">concat_dim</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">input_mins</span><span class="p">,</span> <span class="n">input_maxes</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;values&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;quantized_concat&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">values</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_mins</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;input_mins&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;quantized_concat&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">input_mins</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_mins</span><span class="p">)</span> <span class="o">!=</span> <span class="n">_attr_N</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="s2">&quot;List argument &#39;input_mins&#39; to &#39;quantized_concat&#39; Op with length </span><span class="si">%d</span><span class="s2"> &quot;</span>
        <span class="s2">&quot;must match length </span><span class="si">%d</span><span class="s2"> of argument &#39;values&#39;.&quot;</span> <span class="o">%</span>
        <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_mins</span><span class="p">),</span> <span class="n">_attr_N</span><span class="p">))</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_maxes</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;input_maxes&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;quantized_concat&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">input_maxes</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_maxes</span><span class="p">)</span> <span class="o">!=</span> <span class="n">_attr_N</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="s2">&quot;List argument &#39;input_maxes&#39; to &#39;quantized_concat&#39; Op with length </span><span class="si">%d</span><span class="s2"> &quot;</span>
        <span class="s2">&quot;must match length </span><span class="si">%d</span><span class="s2"> of argument &#39;values&#39;.&quot;</span> <span class="o">%</span>
        <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_maxes</span><span class="p">),</span> <span class="n">_attr_N</span><span class="p">))</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">values</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">concat_dim</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">concat_dim</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">input_mins</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_n_to_tensor</span><span class="p">(</span><span class="n">input_mins</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">input_maxes</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_n_to_tensor</span><span class="p">(</span><span class="n">input_maxes</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">concat_dim</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">values</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">input_mins</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">input_maxes</span><span class="p">)</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_attr_N</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;QuantizedConcat&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedConcat&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedConcatOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_QuantizedInstanceNormOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;QuantizedInstanceNorm&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="s2">&quot;y_min&quot;</span><span class="p">,</span> <span class="s2">&quot;y_max&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">quantized_instance_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">output_range_given</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">given_y_min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">given_y_max</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">variance_epsilon</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">min_separation</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Quantized Instance normalization.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.</span>
<span class="sd">      A 4D input Tensor.</span>
<span class="sd">    x_min: A `Tensor` of type `float32`.</span>
<span class="sd">      The value represented by the lowest quantized input.</span>
<span class="sd">    x_max: A `Tensor` of type `float32`.</span>
<span class="sd">      The value represented by the highest quantized input.</span>
<span class="sd">    output_range_given: An optional `bool`. Defaults to `False`.</span>
<span class="sd">      If True, `given_y_min` and `given_y_min`</span>
<span class="sd">      and `given_y_max` are used as the output range. Otherwise,</span>
<span class="sd">      the implementation computes the output range.</span>
<span class="sd">    given_y_min: An optional `float`. Defaults to `0`.</span>
<span class="sd">      Output in `y_min` if `output_range_given` is True.</span>
<span class="sd">    given_y_max: An optional `float`. Defaults to `0`.</span>
<span class="sd">      Output in `y_max` if `output_range_given` is True.</span>
<span class="sd">    variance_epsilon: An optional `float`. Defaults to `1e-05`.</span>
<span class="sd">      A small float number to avoid dividing by 0.</span>
<span class="sd">    min_separation: An optional `float`. Defaults to `0.001`.</span>
<span class="sd">      Minimum value of `y_max - y_min`</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (y, y_min, y_max).</span>

<span class="sd">    y: A `Tensor`. Has the same type as `x`.</span>
<span class="sd">    y_min: A `Tensor` of type `float32`.</span>
<span class="sd">    y_max: A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;QuantizedInstanceNorm&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="s2">&quot;output_range_given&quot;</span><span class="p">,</span>
        <span class="n">output_range_given</span><span class="p">,</span> <span class="s2">&quot;given_y_min&quot;</span><span class="p">,</span> <span class="n">given_y_min</span><span class="p">,</span> <span class="s2">&quot;given_y_max&quot;</span><span class="p">,</span>
        <span class="n">given_y_max</span><span class="p">,</span> <span class="s2">&quot;variance_epsilon&quot;</span><span class="p">,</span> <span class="n">variance_epsilon</span><span class="p">,</span> <span class="s2">&quot;min_separation&quot;</span><span class="p">,</span>
        <span class="n">min_separation</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedInstanceNormOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">quantized_instance_norm_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">output_range_given</span><span class="o">=</span><span class="n">output_range_given</span><span class="p">,</span>
            <span class="n">given_y_min</span><span class="o">=</span><span class="n">given_y_min</span><span class="p">,</span> <span class="n">given_y_max</span><span class="o">=</span><span class="n">given_y_max</span><span class="p">,</span>
            <span class="n">variance_epsilon</span><span class="o">=</span><span class="n">variance_epsilon</span><span class="p">,</span> <span class="n">min_separation</span><span class="o">=</span><span class="n">min_separation</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">output_range_given</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">output_range_given</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">output_range_given</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">output_range_given</span><span class="p">,</span> <span class="s2">&quot;output_range_given&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">given_y_min</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">given_y_min</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">given_y_min</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">given_y_min</span><span class="p">,</span> <span class="s2">&quot;given_y_min&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">given_y_max</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">given_y_max</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">given_y_max</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">given_y_max</span><span class="p">,</span> <span class="s2">&quot;given_y_max&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">variance_epsilon</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">variance_epsilon</span> <span class="o">=</span> <span class="mf">1e-05</span>
  <span class="n">variance_epsilon</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">variance_epsilon</span><span class="p">,</span> <span class="s2">&quot;variance_epsilon&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">min_separation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">min_separation</span> <span class="o">=</span> <span class="mf">0.001</span>
  <span class="n">min_separation</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">min_separation</span><span class="p">,</span> <span class="s2">&quot;min_separation&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedInstanceNorm&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">x_min</span><span class="o">=</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="o">=</span><span class="n">x_max</span><span class="p">,</span>
                                 <span class="n">output_range_given</span><span class="o">=</span><span class="n">output_range_given</span><span class="p">,</span>
                                 <span class="n">given_y_min</span><span class="o">=</span><span class="n">given_y_min</span><span class="p">,</span>
                                 <span class="n">given_y_max</span><span class="o">=</span><span class="n">given_y_max</span><span class="p">,</span>
                                 <span class="n">variance_epsilon</span><span class="o">=</span><span class="n">variance_epsilon</span><span class="p">,</span>
                                 <span class="n">min_separation</span><span class="o">=</span><span class="n">min_separation</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;output_range_given&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_bool</span><span class="p">(</span><span class="s2">&quot;output_range_given&quot;</span><span class="p">),</span> <span class="s2">&quot;given_y_min&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;given_y_min&quot;</span><span class="p">),</span> <span class="s2">&quot;given_y_max&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;given_y_max&quot;</span><span class="p">),</span> <span class="s2">&quot;variance_epsilon&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;variance_epsilon&quot;</span><span class="p">),</span> <span class="s2">&quot;min_separation&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;min_separation&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedInstanceNorm&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedInstanceNormOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">QuantizedInstanceNorm</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.QuantizedInstanceNorm&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">quantized_instance_norm</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">quantized_instance_norm_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">output_range_given</span><span class="p">,</span> <span class="n">given_y_min</span><span class="p">,</span> <span class="n">given_y_max</span><span class="p">,</span> <span class="n">variance_epsilon</span><span class="p">,</span> <span class="n">min_separation</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">output_range_given</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">output_range_given</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">output_range_given</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_bool</span><span class="p">(</span><span class="n">output_range_given</span><span class="p">,</span> <span class="s2">&quot;output_range_given&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">given_y_min</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">given_y_min</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">given_y_min</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">given_y_min</span><span class="p">,</span> <span class="s2">&quot;given_y_min&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">given_y_max</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">given_y_max</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">given_y_max</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">given_y_max</span><span class="p">,</span> <span class="s2">&quot;given_y_max&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">variance_epsilon</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">variance_epsilon</span> <span class="o">=</span> <span class="mf">1e-05</span>
  <span class="n">variance_epsilon</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">variance_epsilon</span><span class="p">,</span> <span class="s2">&quot;variance_epsilon&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">min_separation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">min_separation</span> <span class="o">=</span> <span class="mf">0.001</span>
  <span class="n">min_separation</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_float</span><span class="p">(</span><span class="n">min_separation</span><span class="p">,</span> <span class="s2">&quot;min_separation&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">x_min</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">x_max</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x_max</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;output_range_given&quot;</span><span class="p">,</span> <span class="n">output_range_given</span><span class="p">,</span>
  <span class="s2">&quot;given_y_min&quot;</span><span class="p">,</span> <span class="n">given_y_min</span><span class="p">,</span> <span class="s2">&quot;given_y_max&quot;</span><span class="p">,</span> <span class="n">given_y_max</span><span class="p">,</span> <span class="s2">&quot;variance_epsilon&quot;</span><span class="p">,</span>
  <span class="n">variance_epsilon</span><span class="p">,</span> <span class="s2">&quot;min_separation&quot;</span><span class="p">,</span> <span class="n">min_separation</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;QuantizedInstanceNorm&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedInstanceNorm&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedInstanceNormOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_QuantizedReshapeOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;QuantizedReshape&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">,</span> <span class="s2">&quot;output_min&quot;</span><span class="p">,</span> <span class="s2">&quot;output_max&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">quantized_reshape</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Reshapes a quantized tensor as per the Reshape op.</span>

<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    tensor: A `Tensor`.</span>
<span class="sd">    shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      Defines the shape of the output tensor.</span>
<span class="sd">    input_min: A `Tensor` of type `float32`. The minimum value of the input.</span>
<span class="sd">    input_max: A `Tensor` of type `float32`. The maximum value of the input.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (output, output_min, output_max).</span>

<span class="sd">    output: A `Tensor`. Has the same type as `tensor`.</span>
<span class="sd">    output_min: A `Tensor` of type `float32`.</span>
<span class="sd">    output_max: A `Tensor` of type `float32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;QuantizedReshape&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedReshapeOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">quantized_reshape_eager_fallback</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedReshape&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">input_min</span><span class="o">=</span><span class="n">input_min</span><span class="p">,</span>
                            <span class="n">input_max</span><span class="o">=</span><span class="n">input_max</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tshape&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tshape&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedReshape&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedReshapeOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">QuantizedReshape</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.QuantizedReshape&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">quantized_reshape</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">quantized_reshape_eager_fallback</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">tensor</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">tensor</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tshape</span><span class="p">,</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">shape</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">input_min</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">input_min</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">input_max</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">input_max</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">input_min</span><span class="p">,</span> <span class="n">input_max</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tshape&quot;</span><span class="p">,</span> <span class="n">_attr_Tshape</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;QuantizedReshape&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;QuantizedReshape&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_QuantizedReshapeOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">rank</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the rank of a tensor.</span>

<span class="sd">  This operation returns an integer representing the rank of `input`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;t&#39; is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]</span>
<span class="sd">  # shape of tensor &#39;t&#39; is [2, 2, 3]</span>
<span class="sd">  rank(t) ==&gt; 3</span>
<span class="sd">  ```</span>

<span class="sd">  **Note**: The rank of a tensor is not the same as the rank of a matrix. The rank</span>
<span class="sd">  of a tensor is the number of indices required to uniquely select each element</span>
<span class="sd">  of the tensor. Rank is also known as &quot;order&quot;, &quot;degree&quot;, or &quot;ndims.&quot;</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `int32`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Rank&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">rank_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Rank&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Rank&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Rank</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Rank&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">rank</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">rank_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Rank&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Rank&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">ref_identity</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return the same ref tensor as the input ref tensor.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A mutable `Tensor`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A mutable `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;ref_identity op does not support eager execution. Arg &#39;output&#39; is a ref.&quot;</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;RefIdentity&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;RefIdentity&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">RefIdentity</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.RefIdentity&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">ref_identity</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">ref_identity_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;ref_identity op does not support eager execution. Arg &#39;output&#39; is a ref.&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">reshape</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Reshapes a tensor.</span>

<span class="sd">  Given `tensor`, this operation returns a tensor that has the same values</span>
<span class="sd">  as `tensor` with shape `shape`.</span>

<span class="sd">  If one component of 1-D tensor `shape` is the special value -1, the size of that</span>
<span class="sd">  dimension is computed so that the total size remains constant.  In particular, a</span>
<span class="sd">  `shape` of `[-1]` flattens into 1-D.  At most one component of `shape` may be</span>
<span class="sd">  unknown.</span>

<span class="sd">  The `shape` must be 1-D and the operation returns a tensor with shape</span>
<span class="sd">  `shape` filled with the values of `tensor`. In this case, the number of elements</span>
<span class="sd">  implied by `shape` must be the same as the number of elements in `tensor`.</span>

<span class="sd">  It is an error if `shape` is not 1-D.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;t&#39; is [1, 2, 3, 4, 5, 6, 7, 8, 9]</span>
<span class="sd">  # tensor &#39;t&#39; has shape [9]</span>
<span class="sd">  reshape(t, [3, 3]) ==&gt; [[1, 2, 3],</span>
<span class="sd">                          [4, 5, 6],</span>
<span class="sd">                          [7, 8, 9]]</span>

<span class="sd">  # tensor &#39;t&#39; is [[[1, 1], [2, 2]],</span>
<span class="sd">  #                [[3, 3], [4, 4]]]</span>
<span class="sd">  # tensor &#39;t&#39; has shape [2, 2, 2]</span>
<span class="sd">  reshape(t, [2, 4]) ==&gt; [[1, 1, 2, 2],</span>
<span class="sd">                          [3, 3, 4, 4]]</span>

<span class="sd">  # tensor &#39;t&#39; is [[[1, 1, 1],</span>
<span class="sd">  #                 [2, 2, 2]],</span>
<span class="sd">  #                [[3, 3, 3],</span>
<span class="sd">  #                 [4, 4, 4]],</span>
<span class="sd">  #                [[5, 5, 5],</span>
<span class="sd">  #                 [6, 6, 6]]]</span>
<span class="sd">  # tensor &#39;t&#39; has shape [3, 2, 3]</span>
<span class="sd">  # pass &#39;[-1]&#39; to flatten &#39;t&#39;</span>
<span class="sd">  reshape(t, [-1]) ==&gt; [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]</span>

<span class="sd">  # -1 can also be used to infer the shape</span>

<span class="sd">  # -1 is inferred to be 9:</span>
<span class="sd">  reshape(t, [2, -1]) ==&gt; [[1, 1, 1, 2, 2, 2, 3, 3, 3],</span>
<span class="sd">                           [4, 4, 4, 5, 5, 5, 6, 6, 6]]</span>
<span class="sd">  # -1 is inferred to be 2:</span>
<span class="sd">  reshape(t, [-1, 9]) ==&gt; [[1, 1, 1, 2, 2, 2, 3, 3, 3],</span>
<span class="sd">                           [4, 4, 4, 5, 5, 5, 6, 6, 6]]</span>
<span class="sd">  # -1 is inferred to be 3:</span>
<span class="sd">  reshape(t, [ 2, -1, 3]) ==&gt; [[[1, 1, 1],</span>
<span class="sd">                                [2, 2, 2],</span>
<span class="sd">                                [3, 3, 3]],</span>
<span class="sd">                               [[4, 4, 4],</span>
<span class="sd">                                [5, 5, 5],</span>
<span class="sd">                                [6, 6, 6]]]</span>

<span class="sd">  # tensor &#39;t&#39; is [7]</span>
<span class="sd">  # shape `[]` reshapes to a scalar</span>
<span class="sd">  reshape(t, []) ==&gt; 7</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    tensor: A `Tensor`.</span>
<span class="sd">    shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      Defines the shape of the output tensor.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Reshape&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">reshape_eager_fallback</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Reshape&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tshape&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tshape&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Reshape&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Reshape</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Reshape&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">reshape</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">reshape_eager_fallback</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">tensor</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">tensor</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tshape</span><span class="p">,</span> <span class="p">(</span><span class="n">shape</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">shape</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tshape&quot;</span><span class="p">,</span> <span class="n">_attr_Tshape</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Reshape&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Reshape&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">resource_strided_slice_assign</span><span class="p">(</span><span class="n">ref</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">begin_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">new_axis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Assign `value` to the sliced l-value reference of `ref`.</span>

<span class="sd">  The values of `value` are assigned to the positions in the variable</span>
<span class="sd">  `ref` that are selected by the slice parameters. The slice parameters</span>
<span class="sd">  `begin, `end`, `strides`, etc. work exactly as in `StridedSlice`.</span>

<span class="sd">  NOTE this op currently does not support broadcasting and so `value`&#39;s</span>
<span class="sd">  shape must be exactly the shape produced by the slice of `ref`.</span>

<span class="sd">  Args:</span>
<span class="sd">    ref: A `Tensor` of type `resource`.</span>
<span class="sd">    begin: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    end: A `Tensor`. Must have the same type as `begin`.</span>
<span class="sd">    strides: A `Tensor`. Must have the same type as `begin`.</span>
<span class="sd">    value: A `Tensor`.</span>
<span class="sd">    begin_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    end_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    ellipsis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    new_axis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    shrink_axis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    The created Operation.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ResourceStridedSliceAssign&quot;</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">ref</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">,</span>
        <span class="n">begin_mask</span><span class="p">,</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">,</span> <span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="p">,</span>
        <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">,</span> <span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">resource_strided_slice_assign_eager_fallback</span><span class="p">(</span>
            <span class="n">ref</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">begin_mask</span><span class="o">=</span><span class="n">begin_mask</span><span class="p">,</span>
            <span class="n">end_mask</span><span class="o">=</span><span class="n">end_mask</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="o">=</span><span class="n">ellipsis_mask</span><span class="p">,</span>
            <span class="n">new_axis_mask</span><span class="o">=</span><span class="n">new_axis_mask</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="o">=</span><span class="n">shrink_axis_mask</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">begin_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">begin_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">begin_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">begin_mask</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">end_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">end_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">end_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ellipsis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">ellipsis_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">new_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">shrink_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ResourceStridedSliceAssign&quot;</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">ref</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">end</span><span class="p">,</span>
                                      <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span>
                                      <span class="n">begin_mask</span><span class="o">=</span><span class="n">begin_mask</span><span class="p">,</span>
                                      <span class="n">end_mask</span><span class="o">=</span><span class="n">end_mask</span><span class="p">,</span>
                                      <span class="n">ellipsis_mask</span><span class="o">=</span><span class="n">ellipsis_mask</span><span class="p">,</span>
                                      <span class="n">new_axis_mask</span><span class="o">=</span><span class="n">new_axis_mask</span><span class="p">,</span>
                                      <span class="n">shrink_axis_mask</span><span class="o">=</span><span class="n">shrink_axis_mask</span><span class="p">,</span>
                                      <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_op</span>
<span class="n">ResourceStridedSliceAssign</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ResourceStridedSliceAssign&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">resource_strided_slice_assign</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">resource_strided_slice_assign_eager_fallback</span><span class="p">(</span><span class="n">ref</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">begin_mask</span><span class="p">,</span> <span class="n">end_mask</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="p">,</span> <span class="n">new_axis_mask</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">begin_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">begin_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">begin_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">begin_mask</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">end_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">end_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">end_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ellipsis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">ellipsis_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">new_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">shrink_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">value</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">value</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Index</span><span class="p">,</span> <span class="n">_inputs_Index</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_Index</span>
  <span class="n">ref</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">ref</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">resource</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">ref</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">value</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Index&quot;</span><span class="p">,</span> <span class="n">_attr_Index</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">,</span> <span class="n">begin_mask</span><span class="p">,</span>
  <span class="s2">&quot;end_mask&quot;</span><span class="p">,</span> <span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="p">,</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">,</span>
  <span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ResourceStridedSliceAssign&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="kc">None</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="reverse"><a class="viewcode-back" href="../../../../index.html#tensorflow.reverse">[docs]</a><span class="k">def</span> <span class="nf">reverse</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Reverses specific dimensions of a tensor.</span>

<span class="sd">  Given a `tensor`, and a `bool` tensor `dims` representing the dimensions</span>
<span class="sd">  of `tensor`, this operation reverses each dimension i of `tensor` where</span>
<span class="sd">  `dims[i]` is `True`.</span>

<span class="sd">  `tensor` can have up to 8 dimensions. The number of dimensions</span>
<span class="sd">  of `tensor` must equal the number of elements in `dims`. In other words:</span>

<span class="sd">  `rank(tensor) = size(dims)`</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;t&#39; is [[[[ 0,  1,  2,  3],</span>
<span class="sd">  #                  [ 4,  5,  6,  7],</span>
<span class="sd">  #                  [ 8,  9, 10, 11]],</span>
<span class="sd">  #                 [[12, 13, 14, 15],</span>
<span class="sd">  #                  [16, 17, 18, 19],</span>
<span class="sd">  #                  [20, 21, 22, 23]]]]</span>
<span class="sd">  # tensor &#39;t&#39; shape is [1, 2, 3, 4]</span>

<span class="sd">  # &#39;dims&#39; is [False, False, False, True]</span>
<span class="sd">  reverse(t, dims) ==&gt; [[[[ 3,  2,  1,  0],</span>
<span class="sd">                          [ 7,  6,  5,  4],</span>
<span class="sd">                          [ 11, 10, 9, 8]],</span>
<span class="sd">                         [[15, 14, 13, 12],</span>
<span class="sd">                          [19, 18, 17, 16],</span>
<span class="sd">                          [23, 22, 21, 20]]]]</span>

<span class="sd">  # &#39;dims&#39; is [False, True, False, False]</span>
<span class="sd">  reverse(t, dims) ==&gt; [[[[12, 13, 14, 15],</span>
<span class="sd">                          [16, 17, 18, 19],</span>
<span class="sd">                          [20, 21, 22, 23]</span>
<span class="sd">                         [[ 0,  1,  2,  3],</span>
<span class="sd">                          [ 4,  5,  6,  7],</span>
<span class="sd">                          [ 8,  9, 10, 11]]]]</span>

<span class="sd">  # &#39;dims&#39; is [False, False, True, False]</span>
<span class="sd">  reverse(t, dims) ==&gt; [[[[8, 9, 10, 11],</span>
<span class="sd">                          [4, 5, 6, 7],</span>
<span class="sd">                          [0, 1, 2, 3]]</span>
<span class="sd">                         [[20, 21, 22, 23],</span>
<span class="sd">                          [16, 17, 18, 19],</span>
<span class="sd">                          [12, 13, 14, 15]]]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    tensor: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `bool`, `half`, `float32`, `float64`, `complex64`, `complex128`, `string`.</span>
<span class="sd">      Up to 8-D.</span>
<span class="sd">    dims: A `Tensor` of type `bool`. 1-D. The dimensions to reverse.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Reverse&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">dims</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">reverse_eager_fallback</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Reverse&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Reverse&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Reverse</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Reverse&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">reverse</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">reverse_eager_fallback</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">tensor</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">tensor</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">dims</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">dims</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dims</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Reverse&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Reverse&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">reverse_sequence</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">seq_lengths</span><span class="p">,</span> <span class="n">seq_dim</span><span class="p">,</span> <span class="n">batch_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Reverses variable length slices.</span>

<span class="sd">  This op first slices `input` along the dimension `batch_dim`, and for each</span>
<span class="sd">  slice `i`, reverses the first `seq_lengths[i]` elements along</span>
<span class="sd">  the dimension `seq_dim`.</span>

<span class="sd">  The elements of `seq_lengths` must obey `seq_lengths[i] &lt;= input.dims[seq_dim]`,</span>
<span class="sd">  and `seq_lengths` must be a vector of length `input.dims[batch_dim]`.</span>

<span class="sd">  The output slice `i` along dimension `batch_dim` is then given by input</span>
<span class="sd">  slice `i`, with the first `seq_lengths[i]` slices along dimension</span>
<span class="sd">  `seq_dim` reversed.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # Given this:</span>
<span class="sd">  batch_dim = 0</span>
<span class="sd">  seq_dim = 1</span>
<span class="sd">  input.dims = (4, 8, ...)</span>
<span class="sd">  seq_lengths = [7, 2, 3, 5]</span>

<span class="sd">  # then slices of input are reversed on seq_dim, but only up to seq_lengths:</span>
<span class="sd">  output[0, 0:7, :, ...] = input[0, 7:0:-1, :, ...]</span>
<span class="sd">  output[1, 0:2, :, ...] = input[1, 2:0:-1, :, ...]</span>
<span class="sd">  output[2, 0:3, :, ...] = input[2, 3:0:-1, :, ...]</span>
<span class="sd">  output[3, 0:5, :, ...] = input[3, 5:0:-1, :, ...]</span>

<span class="sd">  # while entries past seq_lens are copied through:</span>
<span class="sd">  output[0, 7:, :, ...] = input[0, 7:, :, ...]</span>
<span class="sd">  output[1, 2:, :, ...] = input[1, 2:, :, ...]</span>
<span class="sd">  output[2, 3:, :, ...] = input[2, 3:, :, ...]</span>
<span class="sd">  output[3, 2:, :, ...] = input[3, 2:, :, ...]</span>
<span class="sd">  ```</span>

<span class="sd">  In contrast, if:</span>

<span class="sd">  ```</span>
<span class="sd">  # Given this:</span>
<span class="sd">  batch_dim = 2</span>
<span class="sd">  seq_dim = 0</span>
<span class="sd">  input.dims = (8, ?, 4, ...)</span>
<span class="sd">  seq_lengths = [7, 2, 3, 5]</span>

<span class="sd">  # then slices of input are reversed on seq_dim, but only up to seq_lengths:</span>
<span class="sd">  output[0:7, :, 0, :, ...] = input[7:0:-1, :, 0, :, ...]</span>
<span class="sd">  output[0:2, :, 1, :, ...] = input[2:0:-1, :, 1, :, ...]</span>
<span class="sd">  output[0:3, :, 2, :, ...] = input[3:0:-1, :, 2, :, ...]</span>
<span class="sd">  output[0:5, :, 3, :, ...] = input[5:0:-1, :, 3, :, ...]</span>

<span class="sd">  # while entries past seq_lens are copied through:</span>
<span class="sd">  output[7:, :, 0, :, ...] = input[7:, :, 0, :, ...]</span>
<span class="sd">  output[2:, :, 1, :, ...] = input[2:, :, 1, :, ...]</span>
<span class="sd">  output[3:, :, 2, :, ...] = input[3:, :, 2, :, ...]</span>
<span class="sd">  output[2:, :, 3, :, ...] = input[2:, :, 3, :, ...]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. The input to reverse.</span>
<span class="sd">    seq_lengths: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      1-D with length `input.dims(batch_dim)` and</span>
<span class="sd">      `max(seq_lengths) &lt;= input.dims(seq_dim)`</span>
<span class="sd">    seq_dim: An `int`. The dimension which is partially reversed.</span>
<span class="sd">    batch_dim: An optional `int`. Defaults to `0`.</span>
<span class="sd">      The dimension along which reversal is performed.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ReverseSequence&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">seq_lengths</span><span class="p">,</span> <span class="s2">&quot;seq_dim&quot;</span><span class="p">,</span> <span class="n">seq_dim</span><span class="p">,</span> <span class="s2">&quot;batch_dim&quot;</span><span class="p">,</span>
        <span class="n">batch_dim</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">reverse_sequence_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">seq_lengths</span><span class="p">,</span> <span class="n">seq_dim</span><span class="o">=</span><span class="n">seq_dim</span><span class="p">,</span> <span class="n">batch_dim</span><span class="o">=</span><span class="n">batch_dim</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">seq_dim</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">seq_dim</span><span class="p">,</span> <span class="s2">&quot;seq_dim&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">batch_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">batch_dim</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">batch_dim</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">batch_dim</span><span class="p">,</span> <span class="s2">&quot;batch_dim&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ReverseSequence&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">seq_lengths</span><span class="o">=</span><span class="n">seq_lengths</span><span class="p">,</span>
                           <span class="n">seq_dim</span><span class="o">=</span><span class="n">seq_dim</span><span class="p">,</span> <span class="n">batch_dim</span><span class="o">=</span><span class="n">batch_dim</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;seq_dim&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;seq_dim&quot;</span><span class="p">),</span> <span class="s2">&quot;batch_dim&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;batch_dim&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
              <span class="s2">&quot;Tlen&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tlen&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ReverseSequence&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ReverseSequence</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ReverseSequence&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">reverse_sequence</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">reverse_sequence_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">seq_lengths</span><span class="p">,</span> <span class="n">seq_dim</span><span class="p">,</span> <span class="n">batch_dim</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">seq_dim</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">seq_dim</span><span class="p">,</span> <span class="s2">&quot;seq_dim&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">batch_dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">batch_dim</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">batch_dim</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">batch_dim</span><span class="p">,</span> <span class="s2">&quot;batch_dim&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tlen</span><span class="p">,</span> <span class="p">(</span><span class="n">seq_lengths</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">seq_lengths</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">seq_lengths</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;seq_dim&quot;</span><span class="p">,</span> <span class="n">seq_dim</span><span class="p">,</span> <span class="s2">&quot;batch_dim&quot;</span><span class="p">,</span> <span class="n">batch_dim</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tlen&quot;</span><span class="p">,</span>
  <span class="n">_attr_Tlen</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ReverseSequence&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ReverseSequence&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;reverse&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;reverse&#39;</span><span class="p">,</span> <span class="s1">&#39;manip.reverse&#39;</span><span class="p">,</span> <span class="s1">&#39;reverse_v2&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;manip.reverse&#39;</span><span class="p">,</span> <span class="s1">&#39;reverse_v2&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">reverse_v2</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Reverses specific dimensions of a tensor.</span>

<span class="sd">  NOTE `tf.reverse` has now changed behavior in preparation for 1.0.</span>
<span class="sd">  `tf.reverse_v2` is currently an alias that will be deprecated before TF 1.0.</span>

<span class="sd">  Given a `tensor`, and a `int32` tensor `axis` representing the set of</span>
<span class="sd">  dimensions of `tensor` to reverse. This operation reverses each dimension</span>
<span class="sd">  `i` for which there exists `j` s.t. `axis[j] == i`.</span>

<span class="sd">  `tensor` can have up to 8 dimensions. The number of dimensions specified</span>
<span class="sd">  in `axis` may be 0 or more entries. If an index is specified more than</span>
<span class="sd">  once, a InvalidArgument error is raised.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;t&#39; is [[[[ 0,  1,  2,  3],</span>
<span class="sd">  #                  [ 4,  5,  6,  7],</span>
<span class="sd">  #                  [ 8,  9, 10, 11]],</span>
<span class="sd">  #                 [[12, 13, 14, 15],</span>
<span class="sd">  #                  [16, 17, 18, 19],</span>
<span class="sd">  #                  [20, 21, 22, 23]]]]</span>
<span class="sd">  # tensor &#39;t&#39; shape is [1, 2, 3, 4]</span>

<span class="sd">  # &#39;dims&#39; is [3] or &#39;dims&#39; is [-1]</span>
<span class="sd">  reverse(t, dims) ==&gt; [[[[ 3,  2,  1,  0],</span>
<span class="sd">                          [ 7,  6,  5,  4],</span>
<span class="sd">                          [ 11, 10, 9, 8]],</span>
<span class="sd">                         [[15, 14, 13, 12],</span>
<span class="sd">                          [19, 18, 17, 16],</span>
<span class="sd">                          [23, 22, 21, 20]]]]</span>

<span class="sd">  # &#39;dims&#39; is &#39;[1]&#39; (or &#39;dims&#39; is &#39;[-3]&#39;)</span>
<span class="sd">  reverse(t, dims) ==&gt; [[[[12, 13, 14, 15],</span>
<span class="sd">                          [16, 17, 18, 19],</span>
<span class="sd">                          [20, 21, 22, 23]</span>
<span class="sd">                         [[ 0,  1,  2,  3],</span>
<span class="sd">                          [ 4,  5,  6,  7],</span>
<span class="sd">                          [ 8,  9, 10, 11]]]]</span>

<span class="sd">  # &#39;dims&#39; is &#39;[2]&#39; (or &#39;dims&#39; is &#39;[-2]&#39;)</span>
<span class="sd">  reverse(t, dims) ==&gt; [[[[8, 9, 10, 11],</span>
<span class="sd">                          [4, 5, 6, 7],</span>
<span class="sd">                          [0, 1, 2, 3]]</span>
<span class="sd">                         [[20, 21, 22, 23],</span>
<span class="sd">                          [16, 17, 18, 19],</span>
<span class="sd">                          [12, 13, 14, 15]]]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    tensor: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `bool`, `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`, `string`.</span>
<span class="sd">      Up to 8-D.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      1-D. The indices of the dimensions to reverse. Must be in the range</span>
<span class="sd">      `[-rank(tensor), rank(tensor))`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ReverseV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">reverse_v2_eager_fallback</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">reverse_v2</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ReverseV2&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">reverse_v2</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ReverseV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ReverseV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ReverseV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">reverse_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">reverse_v2_eager_fallback</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">tensor</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">tensor</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ReverseV2&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ReverseV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="scatter_nd"><a class="viewcode-back" href="../../../../index.html#tensorflow.scatter_nd">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;scatter_nd&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;scatter_nd&#39;</span><span class="p">,</span> <span class="s1">&#39;manip.scatter_nd&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;manip.scatter_nd&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">scatter_nd</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Scatter `updates` into a new tensor according to `indices`.</span>

<span class="sd">  Creates a new tensor by applying sparse `updates` to individual values or</span>
<span class="sd">  slices within a tensor (initially zero for numeric, empty for string) of</span>
<span class="sd">  the given `shape` according to indices.  This operator is the inverse of the</span>
<span class="sd">  `tf.gather_nd` operator which extracts values or slices from a given tensor.</span>

<span class="sd">  This operation is similar to tensor_scatter_add, except that the tensor is</span>
<span class="sd">  zero-initialized. Calling `tf.scatter_nd(indices, values, shape)` is identical</span>
<span class="sd">  to `tensor_scatter_add(tf.zeros(shape, values.dtype), indices, values)`</span>

<span class="sd">  If `indices` contains duplicates, then their updates are accumulated (summed).</span>

<span class="sd">  **WARNING**: The order in which updates are applied is nondeterministic, so the</span>
<span class="sd">  output will be nondeterministic if `indices` contains duplicates -- because</span>
<span class="sd">  of some numerical approximation issues, numbers summed in different order</span>
<span class="sd">  may yield different results.</span>

<span class="sd">  `indices` is an integer tensor containing indices into a new tensor of shape</span>
<span class="sd">  `shape`.  The last dimension of `indices` can be at most the rank of `shape`:</span>

<span class="sd">      indices.shape[-1] &lt;= shape.rank</span>

<span class="sd">  The last dimension of `indices` corresponds to indices into elements</span>
<span class="sd">  (if `indices.shape[-1] = shape.rank`) or slices</span>
<span class="sd">  (if `indices.shape[-1] &lt; shape.rank`) along dimension `indices.shape[-1]` of</span>
<span class="sd">  `shape`.  `updates` is a tensor with shape</span>

<span class="sd">      indices.shape[:-1] + shape[indices.shape[-1]:]</span>

<span class="sd">  The simplest form of scatter is to insert individual elements in a tensor by</span>
<span class="sd">  index. For example, say we want to insert 4 scattered elements in a rank-1</span>
<span class="sd">  tensor with 8 elements.</span>

<span class="sd">  &lt;div style=&quot;width:70%; margin:auto; margin-bottom:10px; margin-top:20px;&quot;&gt;</span>
<span class="sd">  &lt;img style=&quot;width:100%&quot; src=&quot;https://www.tensorflow.org/images/ScatterNd1.png&quot; alt&gt;</span>
<span class="sd">  &lt;/div&gt;</span>

<span class="sd">  In Python, this scatter operation would look like this:</span>

<span class="sd">  ```python</span>
<span class="sd">      indices = tf.constant([[4], [3], [1], [7]])</span>
<span class="sd">      updates = tf.constant([9, 10, 11, 12])</span>
<span class="sd">      shape = tf.constant([8])</span>
<span class="sd">      scatter = tf.scatter_nd(indices, updates, shape)</span>
<span class="sd">      print(scatter)</span>
<span class="sd">  ```</span>

<span class="sd">  The resulting tensor would look like this:</span>

<span class="sd">      [0, 11, 0, 10, 9, 0, 0, 12]</span>

<span class="sd">  We can also, insert entire slices of a higher rank tensor all at once. For</span>
<span class="sd">  example, if we wanted to insert two slices in the first dimension of a</span>
<span class="sd">  rank-3 tensor with two matrices of new values.</span>

<span class="sd">  &lt;div style=&quot;width:70%; margin:auto; margin-bottom:10px; margin-top:20px;&quot;&gt;</span>
<span class="sd">  &lt;img style=&quot;width:100%&quot; src=&quot;https://www.tensorflow.org/images/ScatterNd2.png&quot; alt&gt;</span>
<span class="sd">  &lt;/div&gt;</span>

<span class="sd">  In Python, this scatter operation would look like this:</span>

<span class="sd">  ```python</span>
<span class="sd">      indices = tf.constant([[0], [2]])</span>
<span class="sd">      updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],</span>
<span class="sd">                              [7, 7, 7, 7], [8, 8, 8, 8]],</span>
<span class="sd">                             [[5, 5, 5, 5], [6, 6, 6, 6],</span>
<span class="sd">                              [7, 7, 7, 7], [8, 8, 8, 8]]])</span>
<span class="sd">      shape = tf.constant([4, 4, 4])</span>
<span class="sd">      scatter = tf.scatter_nd(indices, updates, shape)</span>
<span class="sd">      print(scatter)</span>
<span class="sd">  ```</span>

<span class="sd">  The resulting tensor would look like this:</span>

<span class="sd">      [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],</span>
<span class="sd">       [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],</span>
<span class="sd">       [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],</span>
<span class="sd">       [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]]</span>

<span class="sd">  Note that on CPU, if an out of bound index is found, an error is returned.</span>
<span class="sd">  On GPU, if an out of bound index is found, the index is ignored.</span>

<span class="sd">  Args:</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      Index tensor.</span>
<span class="sd">    updates: A `Tensor`. Updates to scatter into output.</span>
<span class="sd">    shape: A `Tensor`. Must have the same type as `indices`.</span>
<span class="sd">      1-D. The shape of the resulting tensor.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `updates`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ScatterNd&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">scatter_nd_eager_fallback</span><span class="p">(</span>
            <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">scatter_nd</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
                          <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ScatterNd&quot;</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">scatter_nd</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
                      <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ScatterNd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">ScatterNd</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ScatterNd&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">scatter_nd</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">scatter_nd_eager_fallback</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">updates</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">updates</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="n">_inputs_Tindices</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">,</span> <span class="n">shape</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_Tindices</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">shape</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ScatterNd&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ScatterNd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">scatter_nd_non_aliasing_add</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Applies sparse addition to `input` using individual values or slices</span>

<span class="sd">  from `updates` according to indices `indices`.  The updates are non-aliasing:</span>
<span class="sd">  `input` is only modified in-place if no other operations will use it.</span>
<span class="sd">  Otherwise, a copy of `input` is made.  This operation has a gradient with</span>
<span class="sd">  respect to both `input` and `updates`.</span>

<span class="sd">  `input` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.</span>

<span class="sd">  `indices` must be integer tensor, containing indices into `input`.</span>
<span class="sd">  It must be shape \\([d_0, ..., d_{Q-2}, K]\\) where `0 &lt; K &lt;= P`.</span>

<span class="sd">  The innermost dimension of `indices` (with length `K`) corresponds to</span>
<span class="sd">  indices into elements (if `K = P`) or `(P-K)`-dimensional slices</span>
<span class="sd">  (if `K &lt; P`) along the `K`th dimension of `input`.</span>

<span class="sd">  `updates` is `Tensor` of rank `Q-1+P-K` with shape:</span>

<span class="sd">  $$[d_0, ..., d_{Q-2}, input.shape[K], ..., input.shape[P-1]].$$</span>

<span class="sd">  For example, say we want to add 4 scattered elements to a rank-1 tensor to 8</span>
<span class="sd">  elements. In Python, that addition would look like this:</span>

<span class="sd">      input = tf.constant([1, 2, 3, 4, 5, 6, 7, 8])</span>
<span class="sd">      indices = tf.constant([[4], [3], [1], [7]])</span>
<span class="sd">      updates = tf.constant([9, 10, 11, 12])</span>
<span class="sd">      output = tf.scatter_nd_non_aliasing_add(input, indices, updates)</span>
<span class="sd">      with tf.Session() as sess:</span>
<span class="sd">        print(sess.run(output))</span>

<span class="sd">  The resulting value `output` would look like this:</span>

<span class="sd">      [1, 13, 3, 14, 14, 6, 7, 20]</span>

<span class="sd">  See `tf.scatter_nd` for more details about how to make updates to slices.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`, `bool`.</span>
<span class="sd">      A Tensor.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A Tensor. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A tensor of indices into `input`.</span>
<span class="sd">    updates: A `Tensor`. Must have the same type as `input`.</span>
<span class="sd">      A Tensor. Must have the same type as ref. A tensor of updated values</span>
<span class="sd">      to add to `input`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ScatterNdNonAliasingAdd&quot;</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">scatter_nd_non_aliasing_add_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ScatterNdNonAliasingAdd&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                                   <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ScatterNdNonAliasingAdd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ScatterNdNonAliasingAdd</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ScatterNdNonAliasingAdd&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">scatter_nd_non_aliasing_add</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">scatter_nd_non_aliasing_add_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">updates</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ScatterNdNonAliasingAdd&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ScatterNdNonAliasingAdd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the shape of a tensor.</span>

<span class="sd">  This operation returns a 1-D integer tensor representing the shape of `input`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;t&#39; is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]</span>
<span class="sd">  shape(t) ==&gt; [2, 2, 3]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    out_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `out_type`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Shape&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">shape_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">out_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Shape&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;out_type&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Shape&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Shape</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Shape&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">shape_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">out_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Shape&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Shape&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">shape_n</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns shape of tensors.</span>

<span class="sd">  This operation returns N 1-D integer tensors representing shape of `input[i]s`.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A list of at least 1 `Tensor` objects with the same type.</span>
<span class="sd">    out_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A list with the same length as `input` of `Tensor` objects with type `out_type`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ShapeN&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">shape_n_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;input&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;shape_n&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="nb">input</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">out_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ShapeN&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
              <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;out_type&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ShapeN&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ShapeN</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ShapeN&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">shape_n</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">shape_n_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;input&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;shape_n&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="nb">input</span><span class="p">)</span>
  <span class="n">_attr_N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">out_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;N&quot;</span><span class="p">,</span> <span class="n">_attr_N</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ShapeN&quot;</span><span class="p">,</span> <span class="n">_attr_N</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ShapeN&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the size of a tensor.</span>

<span class="sd">  This operation returns an integer representing the number of elements in</span>
<span class="sd">  `input`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;t&#39; is [[[1, 1,, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]]</span>
<span class="sd">  size(t) ==&gt; 12</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    out_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `out_type`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Size&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">size_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">out_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Size&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;out_type&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Size&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Size</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Size&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">size</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">size_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">out_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Size&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Size&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">_slice</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return a slice from &#39;input&#39;.</span>

<span class="sd">  The output tensor is a tensor with dimensions described by &#39;size&#39;</span>
<span class="sd">  whose values are extracted from &#39;input&#39; starting at the offsets in</span>
<span class="sd">  &#39;begin&#39;.</span>

<span class="sd">  *Requirements*:</span>
<span class="sd">    0 &lt;= begin[i] &lt;= begin[i] + size[i] &lt;= Di  for i in [0, n)</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    begin: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      begin[i] specifies the offset into the &#39;i&#39;th dimension of</span>
<span class="sd">      &#39;input&#39; to slice from.</span>
<span class="sd">    size: A `Tensor`. Must have the same type as `begin`.</span>
<span class="sd">      size[i] specifies the number of elements of the &#39;i&#39;th dimension</span>
<span class="sd">      of &#39;input&#39; to slice. If size[i] is -1, all remaining elements in dimension</span>
<span class="sd">      i are included in the slice (i.e. this is equivalent to setting</span>
<span class="sd">      size[i] = input.dim_size(i) - begin[i]).</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Slice&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_slice_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Slice&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="n">begin</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Index&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Index&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Slice&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Slice</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Slice&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">_slice</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_slice_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Index</span><span class="p">,</span> <span class="n">_inputs_Index</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">begin</span><span class="p">,</span> <span class="n">size</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">begin</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_Index</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">size</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Index&quot;</span><span class="p">,</span> <span class="n">_attr_Index</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Slice&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Slice&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">snapshot</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns a copy of the input tensor.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Snapshot&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">snapshot_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Snapshot&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Snapshot&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Snapshot</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Snapshot&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">snapshot</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">snapshot_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Snapshot&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Snapshot&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">space_to_batch</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;SpaceToBatch for 4-D tensors of type T.</span>

<span class="sd">  This is a legacy version of the more general SpaceToBatchND.</span>

<span class="sd">  Zero-pads and then rearranges (permutes) blocks of spatial data into batch.</span>
<span class="sd">  More specifically, this op outputs a copy of the input tensor where values from</span>
<span class="sd">  the `height` and `width` dimensions are moved to the `batch` dimension. After</span>
<span class="sd">  the zero-padding, both `height` and `width` of the input must be divisible by the</span>
<span class="sd">  block size.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. 4-D with shape `[batch, height, width, depth]`.</span>
<span class="sd">    paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      2-D tensor of non-negative integers with shape `[2, 2]`. It specifies</span>
<span class="sd">        the padding of the input with zeros across the spatial dimensions as follows:</span>

<span class="sd">            paddings = [[pad_top, pad_bottom], [pad_left, pad_right]]</span>

<span class="sd">        The effective spatial dimensions of the zero-padded input tensor will be:</span>

<span class="sd">            height_pad = pad_top + height + pad_bottom</span>
<span class="sd">            width_pad = pad_left + width + pad_right</span>

<span class="sd">      The attr `block_size` must be greater than one. It indicates the block size.</span>

<span class="sd">        * Non-overlapping blocks of size `block_size x block size` in the height and</span>
<span class="sd">          width dimensions are rearranged into the batch dimension at each location.</span>
<span class="sd">        * The batch of the output tensor is `batch * block_size * block_size`.</span>
<span class="sd">        * Both height_pad and width_pad must be divisible by block_size.</span>

<span class="sd">      The shape of the output will be:</span>

<span class="sd">          [batch*block_size*block_size, height_pad/block_size, width_pad/block_size,</span>
<span class="sd">           depth]</span>

<span class="sd">      Some examples:</span>

<span class="sd">      (1) For the following input of shape `[1, 2, 2, 1]` and block_size of 2:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1], [2]], [[3], [4]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      The output tensor has shape `[4, 1, 1, 1]` and value:</span>

<span class="sd">      ```</span>
<span class="sd">      [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      (2) For the following input of shape `[1, 2, 2, 3]` and block_size of 2:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1, 2, 3], [4, 5, 6]],</span>
<span class="sd">            [[7, 8, 9], [10, 11, 12]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      The output tensor has shape `[4, 1, 1, 3]` and value:</span>

<span class="sd">      ```</span>
<span class="sd">      [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      (3) For the following input of shape `[1, 4, 4, 1]` and block_size of 2:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1],   [2],  [3],  [4]],</span>
<span class="sd">            [[5],   [6],  [7],  [8]],</span>
<span class="sd">            [[9],  [10], [11],  [12]],</span>
<span class="sd">            [[13], [14], [15],  [16]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      The output tensor has shape `[4, 2, 2, 1]` and value:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1], [3]], [[9], [11]]],</span>
<span class="sd">           [[[2], [4]], [[10], [12]]],</span>
<span class="sd">           [[[5], [7]], [[13], [15]]],</span>
<span class="sd">           [[[6], [8]], [[14], [16]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      (4) For the following input of shape `[2, 2, 4, 1]` and block_size of 2:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1],   [2],  [3],  [4]],</span>
<span class="sd">            [[5],   [6],  [7],  [8]]],</span>
<span class="sd">           [[[9],  [10], [11],  [12]],</span>
<span class="sd">            [[13], [14], [15],  [16]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      The output tensor has shape `[8, 1, 2, 1]` and value:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],</span>
<span class="sd">           [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      Among others, this operation is useful for reducing atrous convolution into</span>
<span class="sd">      regular convolution.</span>
<span class="sd">    block_size: An `int` that is `&gt;= 2`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SpaceToBatch&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">,</span> <span class="n">block_size</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">space_to_batch_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">block_size</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SpaceToBatch&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="o">=</span><span class="n">paddings</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span>
                        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tpaddings&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tpaddings&quot;</span><span class="p">),</span> <span class="s2">&quot;block_size&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;block_size&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SpaceToBatch&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SpaceToBatch</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SpaceToBatch&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">space_to_batch</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">space_to_batch_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">block_size</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tpaddings</span><span class="p">,</span> <span class="p">(</span><span class="n">paddings</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">paddings</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">paddings</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tpaddings&quot;</span><span class="p">,</span> <span class="n">_attr_Tpaddings</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">,</span>
  <span class="n">block_size</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SpaceToBatch&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SpaceToBatch&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="space_to_batch_nd"><a class="viewcode-back" href="../../../../index.html#tensorflow.space_to_batch_nd">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;space_to_batch_nd&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;space_to_batch_nd&#39;</span><span class="p">,</span> <span class="s1">&#39;manip.space_to_batch_nd&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;manip.space_to_batch_nd&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">space_to_batch_nd</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;SpaceToBatch for N-D tensors of type T.</span>

<span class="sd">  This operation divides &quot;spatial&quot; dimensions `[1, ..., M]` of the input into a</span>
<span class="sd">  grid of blocks of shape `block_shape`, and interleaves these blocks with the</span>
<span class="sd">  &quot;batch&quot; dimension (0) such that in the output, the spatial dimensions</span>
<span class="sd">  `[1, ..., M]` correspond to the position within the grid, and the batch</span>
<span class="sd">  dimension combines both the position within a spatial block and the original</span>
<span class="sd">  batch position.  Prior to division into blocks, the spatial dimensions of the</span>
<span class="sd">  input are optionally zero padded according to `paddings`.  See below for a</span>
<span class="sd">  precise description.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">      N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,</span>
<span class="sd">      where spatial_shape has `M` dimensions.</span>
<span class="sd">    block_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      1-D with shape `[M]`, all values must be &gt;= 1.</span>
<span class="sd">    paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      2-D with shape `[M, 2]`, all values must be &gt;= 0.</span>
<span class="sd">        `paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension</span>
<span class="sd">        `i + 1`, which corresponds to spatial dimension `i`.  It is required that</span>
<span class="sd">        `block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.</span>

<span class="sd">      This operation is equivalent to the following steps:</span>

<span class="sd">      1. Zero-pad the start and end of dimensions `[1, ..., M]` of the</span>
<span class="sd">         input according to `paddings` to produce `padded` of shape `padded_shape`.</span>

<span class="sd">      2. Reshape `padded` to `reshaped_padded` of shape:</span>

<span class="sd">           [batch] +</span>
<span class="sd">           [padded_shape[1] / block_shape[0],</span>
<span class="sd">             block_shape[0],</span>
<span class="sd">            ...,</span>
<span class="sd">            padded_shape[M] / block_shape[M-1],</span>
<span class="sd">            block_shape[M-1]] +</span>
<span class="sd">           remaining_shape</span>

<span class="sd">      3. Permute dimensions of `reshaped_padded` to produce</span>
<span class="sd">         `permuted_reshaped_padded` of shape:</span>

<span class="sd">           block_shape +</span>
<span class="sd">           [batch] +</span>
<span class="sd">           [padded_shape[1] / block_shape[0],</span>
<span class="sd">            ...,</span>
<span class="sd">            padded_shape[M] / block_shape[M-1]] +</span>
<span class="sd">           remaining_shape</span>

<span class="sd">      4. Reshape `permuted_reshaped_padded` to flatten `block_shape` into the batch</span>
<span class="sd">         dimension, producing an output tensor of shape:</span>

<span class="sd">           [batch * prod(block_shape)] +</span>
<span class="sd">           [padded_shape[1] / block_shape[0],</span>
<span class="sd">            ...,</span>
<span class="sd">            padded_shape[M] / block_shape[M-1]] +</span>
<span class="sd">           remaining_shape</span>

<span class="sd">      Some examples:</span>

<span class="sd">      (1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and</span>
<span class="sd">          `paddings = [[0, 0], [0, 0]]`:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1], [2]], [[3], [4]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      The output tensor has shape `[4, 1, 1, 1]` and value:</span>

<span class="sd">      ```</span>
<span class="sd">      [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      (2) For the following input of shape `[1, 2, 2, 3]`, `block_shape = [2, 2]`, and</span>
<span class="sd">          `paddings = [[0, 0], [0, 0]]`:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1, 2, 3], [4, 5, 6]],</span>
<span class="sd">            [[7, 8, 9], [10, 11, 12]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      The output tensor has shape `[4, 1, 1, 3]` and value:</span>

<span class="sd">      ```</span>
<span class="sd">      [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      (3) For the following input of shape `[1, 4, 4, 1]`, `block_shape = [2, 2]`, and</span>
<span class="sd">          `paddings = [[0, 0], [0, 0]]`:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1],   [2],  [3],  [4]],</span>
<span class="sd">            [[5],   [6],  [7],  [8]],</span>
<span class="sd">            [[9],  [10], [11],  [12]],</span>
<span class="sd">            [[13], [14], [15],  [16]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      The output tensor has shape `[4, 2, 2, 1]` and value:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1], [3]], [[9], [11]]],</span>
<span class="sd">           [[[2], [4]], [[10], [12]]],</span>
<span class="sd">           [[[5], [7]], [[13], [15]]],</span>
<span class="sd">           [[[6], [8]], [[14], [16]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      (4) For the following input of shape `[2, 2, 4, 1]`, block_shape = `[2, 2]`, and</span>
<span class="sd">          paddings = `[[0, 0], [2, 0]]`:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[1],   [2],  [3],  [4]],</span>
<span class="sd">            [[5],   [6],  [7],  [8]]],</span>
<span class="sd">           [[[9],  [10], [11],  [12]],</span>
<span class="sd">            [[13], [14], [15],  [16]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      The output tensor has shape `[8, 1, 3, 1]` and value:</span>

<span class="sd">      ```</span>
<span class="sd">      x = [[[[0], [1], [3]]], [[[0], [9], [11]]],</span>
<span class="sd">           [[[0], [2], [4]]], [[[0], [10], [12]]],</span>
<span class="sd">           [[[0], [5], [7]]], [[[0], [13], [15]]],</span>
<span class="sd">           [[[0], [6], [8]]], [[[0], [14], [16]]]]</span>
<span class="sd">      ```</span>

<span class="sd">      Among others, this operation is useful for reducing atrous convolution into</span>
<span class="sd">      regular convolution.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SpaceToBatchND&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">space_to_batch_nd_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">space_to_batch_nd</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="o">=</span><span class="n">block_shape</span><span class="p">,</span>
                                 <span class="n">paddings</span><span class="o">=</span><span class="n">paddings</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SpaceToBatchND&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="o">=</span><span class="n">block_shape</span><span class="p">,</span>
                          <span class="n">paddings</span><span class="o">=</span><span class="n">paddings</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">space_to_batch_nd</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="o">=</span><span class="n">block_shape</span><span class="p">,</span>
                             <span class="n">paddings</span><span class="o">=</span><span class="n">paddings</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tblock_shape&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tblock_shape&quot;</span><span class="p">),</span> <span class="s2">&quot;Tpaddings&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tpaddings&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SpaceToBatchND&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">SpaceToBatchND</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SpaceToBatchND&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">space_to_batch_nd</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">space_to_batch_nd_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tblock_shape</span><span class="p">,</span> <span class="p">(</span><span class="n">block_shape</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">block_shape</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_attr_Tpaddings</span><span class="p">,</span> <span class="p">(</span><span class="n">paddings</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">paddings</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_shape</span><span class="p">,</span> <span class="n">paddings</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tblock_shape&quot;</span><span class="p">,</span> <span class="n">_attr_Tblock_shape</span><span class="p">,</span> <span class="s2">&quot;Tpaddings&quot;</span><span class="p">,</span>
  <span class="n">_attr_Tpaddings</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SpaceToBatchND&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SpaceToBatchND&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">space_to_depth</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;NHWC&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;SpaceToDepth for tensors of type T.</span>

<span class="sd">  Rearranges blocks of spatial data, into depth. More specifically,</span>
<span class="sd">  this op outputs a copy of the input tensor where values from the `height`</span>
<span class="sd">  and `width` dimensions are moved to the `depth` dimension.</span>
<span class="sd">  The attr `block_size` indicates the input block size.</span>

<span class="sd">    * Non-overlapping blocks of size `block_size x block size` are rearranged</span>
<span class="sd">      into depth at each location.</span>
<span class="sd">    * The depth of the output tensor is `block_size * block_size * input_depth`.</span>
<span class="sd">    * The Y, X coordinates within each block of the input become the high order</span>
<span class="sd">      component of the output channel index.</span>
<span class="sd">    * The input tensor&#39;s height and width must be divisible by block_size.</span>

<span class="sd">  The `data_format` attr specifies the layout of the input and output tensors</span>
<span class="sd">  with the following options:</span>
<span class="sd">    &quot;NHWC&quot;: `[ batch, height, width, channels ]`</span>
<span class="sd">    &quot;NCHW&quot;: `[ batch, channels, height, width ]`</span>
<span class="sd">    &quot;NCHW_VECT_C&quot;:</span>
<span class="sd">        `qint8 [ batch, channels / 4, height, width, 4 ]`</span>

<span class="sd">  It is useful to consider the operation as transforming a 6-D Tensor.</span>
<span class="sd">  e.g. for data_format = NHWC,</span>
<span class="sd">       Each element in the input tensor can be specified via 6 coordinates,</span>
<span class="sd">       ordered by decreasing memory layout significance as:</span>
<span class="sd">       n,oY,bY,oX,bX,iC  (where n=batch index, oX, oY means X or Y coordinates</span>
<span class="sd">                          within the output image, bX, bY means coordinates</span>
<span class="sd">                          within the input block, iC means input channels).</span>
<span class="sd">       The output would be a transpose to the following layout:</span>
<span class="sd">       n,oY,oX,bY,bX,iC</span>

<span class="sd">  This operation is useful for resizing the activations between convolutions</span>
<span class="sd">  (but keeping all data), e.g. instead of pooling. It is also useful for training</span>
<span class="sd">  purely convolutional models.</span>

<span class="sd">  For example, given an input of shape `[1, 2, 2, 1]`, data_format = &quot;NHWC&quot; and</span>
<span class="sd">  block_size = 2:</span>

<span class="sd">  ```</span>
<span class="sd">  x = [[[[1], [2]],</span>
<span class="sd">        [[3], [4]]]]</span>
<span class="sd">  ```</span>

<span class="sd">  This operation will output a tensor of shape `[1, 1, 1, 4]`:</span>

<span class="sd">  ```</span>
<span class="sd">  [[[[1, 2, 3, 4]]]]</span>
<span class="sd">  ```</span>

<span class="sd">  Here, the input has a batch of 1 and each batch element has shape `[2, 2, 1]`,</span>
<span class="sd">  the corresponding output will have a single element (i.e. width and height are</span>
<span class="sd">  both 1) and will have a depth of 4 channels (1 * block_size * block_size).</span>
<span class="sd">  The output element shape is `[1, 1, 4]`.</span>

<span class="sd">  For an input tensor with larger depth, here of shape `[1, 2, 2, 3]`, e.g.</span>

<span class="sd">  ```</span>
<span class="sd">  x = [[[[1, 2, 3], [4, 5, 6]],</span>
<span class="sd">        [[7, 8, 9], [10, 11, 12]]]]</span>
<span class="sd">  ```</span>

<span class="sd">  This operation, for block_size of 2, will return the following tensor of shape</span>
<span class="sd">  `[1, 1, 1, 12]`</span>

<span class="sd">  ```</span>
<span class="sd">  [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]</span>
<span class="sd">  ```</span>

<span class="sd">  Similarly, for the following input of shape `[1 4 4 1]`, and a block size of 2:</span>

<span class="sd">  ```</span>
<span class="sd">  x = [[[[1],   [2],  [5],  [6]],</span>
<span class="sd">        [[3],   [4],  [7],  [8]],</span>
<span class="sd">        [[9],  [10], [13],  [14]],</span>
<span class="sd">        [[11], [12], [15],  [16]]]]</span>
<span class="sd">  ```</span>

<span class="sd">  the operator will return the following tensor of shape `[1 2 2 4]`:</span>

<span class="sd">  ```</span>
<span class="sd">  x = [[[[1, 2, 3, 4],</span>
<span class="sd">         [5, 6, 7, 8]],</span>
<span class="sd">        [[9, 10, 11, 12],</span>
<span class="sd">         [13, 14, 15, 16]]]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    block_size: An `int` that is `&gt;= 2`. The size of the spatial block.</span>
<span class="sd">    data_format: An optional `string` from: `&quot;NHWC&quot;, &quot;NCHW&quot;, &quot;NCHW_VECT_C&quot;`. Defaults to `&quot;NHWC&quot;`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SpaceToDepth&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="s2">&quot;data_format&quot;</span><span class="p">,</span>
        <span class="n">data_format</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">space_to_depth_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">block_size</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">data_format</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">data_format</span> <span class="o">=</span> <span class="s2">&quot;NHWC&quot;</span>
  <span class="n">data_format</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="s2">&quot;data_format&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SpaceToDepth&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">block_size</span><span class="p">,</span>
                        <span class="n">data_format</span><span class="o">=</span><span class="n">data_format</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;block_size&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;block_size&quot;</span><span class="p">),</span> <span class="s2">&quot;data_format&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;data_format&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SpaceToDepth&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SpaceToDepth</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SpaceToDepth&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">space_to_depth</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">space_to_depth_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">data_format</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">block_size</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">block_size</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">data_format</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">data_format</span> <span class="o">=</span> <span class="s2">&quot;NHWC&quot;</span>
  <span class="n">data_format</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_str</span><span class="p">(</span><span class="n">data_format</span><span class="p">,</span> <span class="s2">&quot;data_format&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;block_size&quot;</span><span class="p">,</span> <span class="n">block_size</span><span class="p">,</span> <span class="s2">&quot;data_format&quot;</span><span class="p">,</span>
  <span class="n">data_format</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SpaceToDepth&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SpaceToDepth&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">num_split</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Splits a tensor into `num_split` tensors along one dimension.</span>

<span class="sd">  Args:</span>
<span class="sd">    axis: A `Tensor` of type `int32`.</span>
<span class="sd">      0-D.  The dimension along which to split.  Must be in the range</span>
<span class="sd">      `[-rank(value), rank(value))`.</span>
<span class="sd">    value: A `Tensor`. The tensor to split.</span>
<span class="sd">    num_split: An `int` that is `&gt;= 1`.</span>
<span class="sd">      The number of ways to split.  Must evenly divide</span>
<span class="sd">      `value.shape[split_dim]`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A list of `num_split` `Tensor` objects with the same type as `value`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Split&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="s2">&quot;num_split&quot;</span><span class="p">,</span> <span class="n">num_split</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">split_eager_fallback</span><span class="p">(</span>
            <span class="n">axis</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">num_split</span><span class="o">=</span><span class="n">num_split</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">num_split</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_split</span><span class="p">,</span> <span class="s2">&quot;num_split&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Split&quot;</span><span class="p">,</span> <span class="n">split_dim</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">num_split</span><span class="o">=</span><span class="n">num_split</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;num_split&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;num_split&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Split&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Split</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Split&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">split</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">split_eager_fallback</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">num_split</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">num_split</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_split</span><span class="p">,</span> <span class="s2">&quot;num_split&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">value</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">value</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="p">,</span> <span class="n">value</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;num_split&quot;</span><span class="p">,</span> <span class="n">num_split</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Split&quot;</span><span class="p">,</span> <span class="n">num_split</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Split&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">split_v</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">size_splits</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">num_split</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Splits a tensor into `num_split` tensors along one dimension.</span>

<span class="sd">  Args:</span>
<span class="sd">    value: A `Tensor`. The tensor to split.</span>
<span class="sd">    size_splits: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      list containing the sizes of each output tensor along the split</span>
<span class="sd">      dimension. Must sum to the dimension of value along split_dim.</span>
<span class="sd">      Can contain one -1 indicating that dimension is to be inferred.</span>
<span class="sd">    axis: A `Tensor` of type `int32`.</span>
<span class="sd">      0-D.  The dimension along which to split.  Must be in the range</span>
<span class="sd">      `[-rank(value), rank(value))`.</span>
<span class="sd">    num_split: An `int` that is `&gt;= 1`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A list of `num_split` `Tensor` objects with the same type as `value`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;SplitV&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">size_splits</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;num_split&quot;</span><span class="p">,</span> <span class="n">num_split</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">split_v_eager_fallback</span><span class="p">(</span>
            <span class="n">value</span><span class="p">,</span> <span class="n">size_splits</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">num_split</span><span class="o">=</span><span class="n">num_split</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">num_split</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_split</span><span class="p">,</span> <span class="s2">&quot;num_split&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;SplitV&quot;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">size_splits</span><span class="o">=</span><span class="n">size_splits</span><span class="p">,</span> <span class="n">split_dim</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
                  <span class="n">num_split</span><span class="o">=</span><span class="n">num_split</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;num_split&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;num_split&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tlen&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tlen&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SplitV&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">SplitV</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.SplitV&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">split_v</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">split_v_eager_fallback</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">size_splits</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">num_split</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">num_split</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num_split</span><span class="p">,</span> <span class="s2">&quot;num_split&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">value</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">value</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tlen</span><span class="p">,</span> <span class="p">(</span><span class="n">size_splits</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">size_splits</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="p">,</span> <span class="n">size_splits</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;num_split&quot;</span><span class="p">,</span> <span class="n">num_split</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tlen&quot;</span><span class="p">,</span> <span class="n">_attr_Tlen</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;SplitV&quot;</span><span class="p">,</span> <span class="n">num_split</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;SplitV&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">squeeze</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[],</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Removes dimensions of size 1 from the shape of a tensor.</span>

<span class="sd">  Given a tensor `input`, this operation returns a tensor of the same type with</span>
<span class="sd">  all dimensions of size 1 removed. If you don&#39;t want to remove all size 1</span>
<span class="sd">  dimensions, you can remove specific size 1 dimensions by specifying</span>
<span class="sd">  `axis`.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;t&#39; is a tensor of shape [1, 2, 1, 3, 1, 1]</span>
<span class="sd">  shape(squeeze(t)) ==&gt; [2, 3]</span>
<span class="sd">  ```</span>

<span class="sd">  Or, to remove specific size 1 dimensions:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;t&#39; is a tensor of shape [1, 2, 1, 3, 1, 1]</span>
<span class="sd">  shape(squeeze(t, [2, 4])) ==&gt; [1, 2, 3, 1]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. The `input` to squeeze.</span>
<span class="sd">    axis: An optional list of `ints`. Defaults to `[]`.</span>
<span class="sd">      If specified, only squeezes the dimensions listed. The dimension</span>
<span class="sd">      index starts at 0. It is an error to squeeze a dimension that is not 1. Must</span>
<span class="sd">      be in the range `[-rank(input), rank(input))`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Squeeze&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;squeeze_dims&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">squeeze_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;axis&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;squeeze&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">axis</span><span class="p">)</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">_i</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Squeeze&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">squeeze_dims</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;squeeze_dims&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">get_attr</span><span class="p">(</span><span class="s2">&quot;squeeze_dims&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Squeeze&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Squeeze</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Squeeze&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">squeeze</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">squeeze_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;Expected list for &#39;axis&#39; argument to &quot;</span>
        <span class="s2">&quot;&#39;squeeze&#39; Op, not </span><span class="si">%r</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">axis</span><span class="p">)</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">_i</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_i</span> <span class="ow">in</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;squeeze_dims&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Squeeze&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Squeeze&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="stop_gradient"><a class="viewcode-back" href="../../../../index.html#tensorflow.stop_gradient">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;stop_gradient&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">stop_gradient</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Stops gradient computation.</span>

<span class="sd">  When executed in a graph, this op outputs its input tensor as-is.</span>

<span class="sd">  When building ops to compute gradients, this op prevents the contribution of</span>
<span class="sd">  its inputs to be taken into account.  Normally, the gradient generator adds ops</span>
<span class="sd">  to a graph to compute the derivatives of a specified &#39;loss&#39; by recursively</span>
<span class="sd">  finding out inputs that contributed to its computation.  If you insert this op</span>
<span class="sd">  in the graph it inputs are masked from the gradient generator.  They are not</span>
<span class="sd">  taken into account for computing gradients.</span>

<span class="sd">  This is useful any time you want to compute a value with TensorFlow but need</span>
<span class="sd">  to pretend that the value was a constant. Some examples include:</span>

<span class="sd">  *  The *EM* algorithm where the *M-step* should not involve backpropagation</span>
<span class="sd">     through the output of the *E-step*.</span>
<span class="sd">  *  Contrastive divergence training of Boltzmann machines where, when</span>
<span class="sd">     differentiating the energy function, the training must not backpropagate</span>
<span class="sd">     through the graph that generated the samples from the model.</span>
<span class="sd">  *  Adversarial training, where no backprop should happen through the adversarial</span>
<span class="sd">     example generation process.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;StopGradient&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">stop_gradient_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">stop_gradient</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;StopGradient&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">stop_gradient</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;StopGradient&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">StopGradient</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.StopGradient&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">stop_gradient</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">stop_gradient_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;StopGradient&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;StopGradient&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">strided_slice</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">begin_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">new_axis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return a strided slice from `input`.</span>

<span class="sd">  Note, most python users will want to use the Python `Tensor.__getitem__`</span>
<span class="sd">  or `Variable.__getitem__` rather than this op directly.</span>

<span class="sd">  The goal of this op is to produce a new tensor with a subset of</span>
<span class="sd">  the elements from the `n` dimensional `input` tensor. The subset is chosen using</span>
<span class="sd">  a sequence of `m` sparse range specifications encoded into the arguments</span>
<span class="sd">  of this function. Note, in some cases</span>
<span class="sd">  `m` could be equal to `n`, but this need not be the case. Each</span>
<span class="sd">  range specification entry can be one of the following:</span>

<span class="sd">  - An ellipsis (...). Ellipses are used to imply zero or more</span>
<span class="sd">    dimensions of full-dimension selection and are produced using</span>
<span class="sd">    `ellipsis_mask`. For example, `foo[...]` is the identity slice.</span>

<span class="sd">  - A new axis. This is used to insert a new shape=1 dimension and is</span>
<span class="sd">    produced using `new_axis_mask`. For example, `foo[:, ...]` where</span>
<span class="sd">    `foo` is shape `(3, 4)` produces a `(1, 3, 4)` tensor.</span>


<span class="sd">  - A range `begin:end:stride`. This is used to specify how much to choose from</span>
<span class="sd">    a given dimension. `stride` can be any integer but 0.  `begin` is an integer</span>
<span class="sd">    which represents the index of the first value to select while `end` represents</span>
<span class="sd">    the index of the last value to select. The number of values selected in each</span>
<span class="sd">    dimension is `end - begin` if `stride &gt; 0` and `begin - end` if `stride &lt; 0`.</span>
<span class="sd">    `begin` and `end` can be negative where `-1` is the last element, `-2` is</span>
<span class="sd">    the second to last. `begin_mask` controls whether to replace the explicitly</span>
<span class="sd">    given `begin` with an implicit effective value of `0` if `stride &gt; 0` and</span>
<span class="sd">    `-1` if `stride &lt; 0`. `end_mask` is analogous but produces the number</span>
<span class="sd">    required to create the largest open interval. For example, given a shape</span>
<span class="sd">    `(3,)` tensor `foo[:]`, the effective `begin` and `end` are `0` and `3`. Do</span>
<span class="sd">    not assume this is equivalent to `foo[0:-1]` which has an effective `begin`</span>
<span class="sd">    and `end` of `0` and `2`. Another example is `foo[-2::-1]` which reverses the</span>
<span class="sd">    first dimension of a tensor while dropping the last two (in the original</span>
<span class="sd">    order elements). For example `foo = [1,2,3,4]; foo[-2::-1]` is `[4,3]`.</span>

<span class="sd">  - A single index. This is used to keep only elements that have a given</span>
<span class="sd">    index. For example (`foo[2, :]` on a shape `(5,6)` tensor produces a</span>
<span class="sd">    shape `(6,)` tensor. This is encoded in `begin` and `end` and</span>
<span class="sd">    `shrink_axis_mask`.</span>

<span class="sd">  Each conceptual range specification is encoded in the op&#39;s argument. This</span>
<span class="sd">  encoding is best understand by considering a non-trivial example. In</span>
<span class="sd">  particular,</span>
<span class="sd">  `foo[1, 2:4, None, ..., :-3:-1, :]` will be encoded as</span>

<span class="sd">  ```</span>
<span class="sd">  begin = [1, 2, x, x, 0, x] # x denotes don&#39;t care (usually 0)</span>
<span class="sd">  end = [2, 4, x, x, -3, x]</span>
<span class="sd">  strides = [1, 1, x, x, -1, 1]</span>
<span class="sd">  begin_mask = 1&lt;&lt;4 | 1 &lt;&lt; 5 = 48</span>
<span class="sd">  end_mask = 1&lt;&lt;5 = 32</span>
<span class="sd">  ellipsis_mask = 1&lt;&lt;3 = 8</span>
<span class="sd">  new_axis_mask = 1&lt;&lt;2 4</span>
<span class="sd">  shrink_axis_mask = 1&lt;&lt;0</span>
<span class="sd">  ```</span>

<span class="sd">  In this case if `foo.shape` is (5, 5, 5, 5, 5, 5) the final shape of</span>
<span class="sd">  the slice becomes (2, 1, 5, 5, 2, 5).</span>
<span class="sd">  Let us walk step by step through each argument specification.</span>

<span class="sd">  1.  The first argument in the example slice is turned into `begin = 1` and</span>
<span class="sd">  `end = begin + 1 = 2`. To disambiguate from the original spec `2:4` we</span>
<span class="sd">  also set the appropriate bit in `shrink_axis_mask`.</span>

<span class="sd">  2. `2:4` is contributes 2, 4, 1 to begin, end, and stride. All masks have</span>
<span class="sd">  zero bits contributed.</span>

<span class="sd">  3. None is a synonym for `tf.newaxis`. This means insert a dimension of size 1</span>
<span class="sd">  dimension in the final shape. Dummy values are contributed to begin,</span>
<span class="sd">  end and stride, while the new_axis_mask bit is set.</span>

<span class="sd">  4. `...` grab the full ranges from as many dimensions as needed to</span>
<span class="sd">  fully specify a slice for every dimension of the input shape.</span>

<span class="sd">  5. `:-3:-1` shows the use of negative indices. A negative index `i` associated</span>
<span class="sd">  with a dimension that has shape `s` is converted to a positive index</span>
<span class="sd">  `s + i`. So `-1` becomes `s-1` (i.e. the last element). This conversion</span>
<span class="sd">  is done internally so begin, end and strides receive x, -3, and -1.</span>
<span class="sd">  The appropriate begin_mask bit is set to indicate the start range is the</span>
<span class="sd">  full range (ignoring the x).</span>

<span class="sd">  6. `:` indicates that the entire contents of the corresponding dimension</span>
<span class="sd">  is selected. This is equivalent to `::` or `0::1`. begin, end, and strides</span>
<span class="sd">  receive 0, 0, and 1, respectively. The appropriate bits in `begin_mask` and</span>
<span class="sd">  `end_mask` are also set.</span>

<span class="sd">  *Requirements*:</span>
<span class="sd">    `0 != strides[i] for i in [0, m)`</span>
<span class="sd">    `ellipsis_mask must be a power of two (only one ellipsis)`</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    begin: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      `begin[k]` specifies the offset into the `k`th range specification.</span>
<span class="sd">      The exact dimension this corresponds to will be determined by context.</span>
<span class="sd">      Out-of-bounds values will be silently clamped. If the `k`th bit of</span>
<span class="sd">      `begin_mask` then `begin[k]` is ignored and the full range of the</span>
<span class="sd">      appropriate dimension is used instead. Negative values causes indexing</span>
<span class="sd">      to start from the highest element e.g. If `foo==[1,2,3]` then `foo[-1]==3`.</span>
<span class="sd">    end: A `Tensor`. Must have the same type as `begin`.</span>
<span class="sd">      `end[i]` is like `begin` with the exception that `end_mask` is</span>
<span class="sd">      used to determine full ranges.</span>
<span class="sd">    strides: A `Tensor`. Must have the same type as `begin`.</span>
<span class="sd">      `strides[i]` specifies the increment in the `i`th specification</span>
<span class="sd">      after extracting a given element. Negative indices will reverse</span>
<span class="sd">      the original order. Out or range values are</span>
<span class="sd">      clamped to `[0,dim[i]) if slice[i]&gt;0` or `[-1,dim[i]-1] if slice[i] &lt; 0`</span>
<span class="sd">    begin_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">      a bitmask where a bit i being 1 means to ignore the begin</span>
<span class="sd">      value and instead use the largest interval possible. At runtime</span>
<span class="sd">      begin[i] will be replaced with `[0, n-1)` if `stride[i] &gt; 0` or</span>
<span class="sd">      `[-1, n-1]` if `stride[i] &lt; 0`</span>
<span class="sd">    end_mask: An optional `int`. Defaults to `0`. analogous to `begin_mask`</span>
<span class="sd">    ellipsis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">      a bitmask where bit `i` being 1 means the `i`th</span>
<span class="sd">      position is actually an ellipsis. One bit at most can be 1.</span>
<span class="sd">      If `ellipsis_mask == 0`, then an implicit ellipsis mask of `1 &lt;&lt; (m+1)`</span>
<span class="sd">      is provided. This means that `foo[3:5] == foo[3:5, ...]`. An ellipsis</span>
<span class="sd">      implicitly creates as many range specifications as necessary to fully</span>
<span class="sd">      specify the sliced range for every dimension. For example for a 4-dimensional</span>
<span class="sd">      tensor `foo` the slice `foo[2, ..., 5:8]` implies `foo[2, :, :, 5:8]`.</span>
<span class="sd">    new_axis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">      a bitmask where bit `i` being 1 means the `i`th</span>
<span class="sd">      specification creates a new shape 1 dimension. For example</span>
<span class="sd">      `foo[:4, tf.newaxis, :2]` would produce a shape `(4, 1, 2)` tensor.</span>
<span class="sd">    shrink_axis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">      a bitmask where bit `i` implies that the `i`th</span>
<span class="sd">      specification should shrink the dimensionality. begin and end</span>
<span class="sd">      must imply a slice of size 1 in the dimension. For example in</span>
<span class="sd">      python one might do `foo[:, 3, :]` which would result in</span>
<span class="sd">      `shrink_axis_mask` being 2.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;StridedSlice&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">,</span>
        <span class="n">begin_mask</span><span class="p">,</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">,</span> <span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="p">,</span>
        <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">,</span> <span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">strided_slice_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">begin_mask</span><span class="o">=</span><span class="n">begin_mask</span><span class="p">,</span>
            <span class="n">end_mask</span><span class="o">=</span><span class="n">end_mask</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="o">=</span><span class="n">ellipsis_mask</span><span class="p">,</span>
            <span class="n">new_axis_mask</span><span class="o">=</span><span class="n">new_axis_mask</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="o">=</span><span class="n">shrink_axis_mask</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">begin_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">begin_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">begin_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">begin_mask</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">end_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">end_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">end_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ellipsis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">ellipsis_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">new_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">shrink_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;StridedSlice&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
                        <span class="n">begin_mask</span><span class="o">=</span><span class="n">begin_mask</span><span class="p">,</span> <span class="n">end_mask</span><span class="o">=</span><span class="n">end_mask</span><span class="p">,</span>
                        <span class="n">ellipsis_mask</span><span class="o">=</span><span class="n">ellipsis_mask</span><span class="p">,</span>
                        <span class="n">new_axis_mask</span><span class="o">=</span><span class="n">new_axis_mask</span><span class="p">,</span>
                        <span class="n">shrink_axis_mask</span><span class="o">=</span><span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Index&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Index&quot;</span><span class="p">),</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;begin_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;end_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;new_axis_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;StridedSlice&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">StridedSlice</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.StridedSlice&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">strided_slice</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">strided_slice_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">begin_mask</span><span class="p">,</span> <span class="n">end_mask</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="p">,</span> <span class="n">new_axis_mask</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">begin_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">begin_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">begin_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">begin_mask</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">end_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">end_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">end_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ellipsis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">ellipsis_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">new_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">shrink_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Index</span><span class="p">,</span> <span class="n">_inputs_Index</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_Index</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Index&quot;</span><span class="p">,</span> <span class="n">_attr_Index</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">,</span> <span class="n">begin_mask</span><span class="p">,</span>
  <span class="s2">&quot;end_mask&quot;</span><span class="p">,</span> <span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="p">,</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">,</span>
  <span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;StridedSlice&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;StridedSlice&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">strided_slice_assign</span><span class="p">(</span><span class="n">ref</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">begin_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">new_axis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Assign `value` to the sliced l-value reference of `ref`.</span>

<span class="sd">  The values of `value` are assigned to the positions in the variable</span>
<span class="sd">  `ref` that are selected by the slice parameters. The slice parameters</span>
<span class="sd">  `begin`, `end`, `strides`, etc. work exactly as in `StridedSlice`.</span>

<span class="sd">  NOTE this op currently does not support broadcasting and so `value`&#39;s</span>
<span class="sd">  shape must be exactly the shape produced by the slice of `ref`.</span>

<span class="sd">  Args:</span>
<span class="sd">    ref: A mutable `Tensor`.</span>
<span class="sd">    begin: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    end: A `Tensor`. Must have the same type as `begin`.</span>
<span class="sd">    strides: A `Tensor`. Must have the same type as `begin`.</span>
<span class="sd">    value: A `Tensor`. Must have the same type as `ref`.</span>
<span class="sd">    begin_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    end_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    ellipsis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    new_axis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    shrink_axis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A mutable `Tensor`. Has the same type as `ref`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;strided_slice_assign op does not support eager execution. Arg &#39;output_ref&#39; is a ref.&quot;</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">begin_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">begin_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">begin_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">begin_mask</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">end_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">end_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">end_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ellipsis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">ellipsis_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">new_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">shrink_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;StridedSliceAssign&quot;</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">ref</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span>
                              <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">begin_mask</span><span class="o">=</span><span class="n">begin_mask</span><span class="p">,</span>
                              <span class="n">end_mask</span><span class="o">=</span><span class="n">end_mask</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="o">=</span><span class="n">ellipsis_mask</span><span class="p">,</span>
                              <span class="n">new_axis_mask</span><span class="o">=</span><span class="n">new_axis_mask</span><span class="p">,</span>
                              <span class="n">shrink_axis_mask</span><span class="o">=</span><span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Index&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Index&quot;</span><span class="p">),</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;begin_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;end_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;new_axis_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;StridedSliceAssign&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">StridedSliceAssign</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.StridedSliceAssign&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">strided_slice_assign</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">strided_slice_assign_eager_fallback</span><span class="p">(</span><span class="n">ref</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">begin_mask</span><span class="p">,</span> <span class="n">end_mask</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="p">,</span> <span class="n">new_axis_mask</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;strided_slice_assign op does not support eager execution. Arg &#39;output_ref&#39; is a ref.&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">strided_slice_grad</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">begin_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">new_axis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the gradient of `StridedSlice`.</span>

<span class="sd">  Since `StridedSlice` cuts out pieces of its `input` which is size</span>
<span class="sd">  `shape`, its gradient will have the same shape (which is passed here</span>
<span class="sd">  as `shape`). The gradient will be zero in any element that the slice</span>
<span class="sd">  does not select.</span>

<span class="sd">  Arguments are the same as StridedSliceGrad with the exception that</span>
<span class="sd">  `dy` is the input gradient to be propagated and `shape` is the</span>
<span class="sd">  shape of `StridedSlice`&#39;s `input`.</span>

<span class="sd">  Args:</span>
<span class="sd">    shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    begin: A `Tensor`. Must have the same type as `shape`.</span>
<span class="sd">    end: A `Tensor`. Must have the same type as `shape`.</span>
<span class="sd">    strides: A `Tensor`. Must have the same type as `shape`.</span>
<span class="sd">    dy: A `Tensor`.</span>
<span class="sd">    begin_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    end_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    ellipsis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    new_axis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    shrink_axis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `dy`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;StridedSliceGrad&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">,</span>
        <span class="n">begin_mask</span><span class="p">,</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">,</span> <span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="p">,</span>
        <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">,</span> <span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">strided_slice_grad_eager_fallback</span><span class="p">(</span>
            <span class="n">shape</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">begin_mask</span><span class="o">=</span><span class="n">begin_mask</span><span class="p">,</span>
            <span class="n">end_mask</span><span class="o">=</span><span class="n">end_mask</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="o">=</span><span class="n">ellipsis_mask</span><span class="p">,</span>
            <span class="n">new_axis_mask</span><span class="o">=</span><span class="n">new_axis_mask</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="o">=</span><span class="n">shrink_axis_mask</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">begin_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">begin_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">begin_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">begin_mask</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">end_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">end_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">end_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ellipsis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">ellipsis_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">new_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">shrink_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;StridedSliceGrad&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">end</span><span class="p">,</span>
                            <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="n">dy</span><span class="p">,</span> <span class="n">begin_mask</span><span class="o">=</span><span class="n">begin_mask</span><span class="p">,</span>
                            <span class="n">end_mask</span><span class="o">=</span><span class="n">end_mask</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="o">=</span><span class="n">ellipsis_mask</span><span class="p">,</span>
                            <span class="n">new_axis_mask</span><span class="o">=</span><span class="n">new_axis_mask</span><span class="p">,</span>
                            <span class="n">shrink_axis_mask</span><span class="o">=</span><span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Index&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Index&quot;</span><span class="p">),</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;begin_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;end_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;new_axis_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;StridedSliceGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">StridedSliceGrad</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.StridedSliceGrad&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">strided_slice_grad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">strided_slice_grad_eager_fallback</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">dy</span><span class="p">,</span> <span class="n">begin_mask</span><span class="p">,</span> <span class="n">end_mask</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="p">,</span> <span class="n">new_axis_mask</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">begin_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">begin_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">begin_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">begin_mask</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">end_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">end_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">end_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ellipsis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">ellipsis_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">new_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">shrink_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">dy</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">dy</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Index</span><span class="p">,</span> <span class="n">_inputs_Index</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">shape</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_Index</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">shape</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">dy</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Index&quot;</span><span class="p">,</span> <span class="n">_attr_Index</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">,</span> <span class="n">begin_mask</span><span class="p">,</span>
  <span class="s2">&quot;end_mask&quot;</span><span class="p">,</span> <span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="p">,</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">,</span>
  <span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;StridedSliceGrad&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;StridedSliceGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;tensor_scatter_nd_add&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tensor_scatter_nd_add&#39;</span><span class="p">,</span> <span class="s1">&#39;tensor_scatter_add&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;tensor_scatter_add&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">tensor_scatter_add</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds sparse `updates` to an existing tensor according to `indices`.</span>

<span class="sd">  This operation creates a new tensor by adding sparse `updates` to the passed</span>
<span class="sd">  in `tensor`.</span>
<span class="sd">  This operation is very similar to `tf.scatter_nd_add`, except that the updates</span>
<span class="sd">  are added onto an existing tensor (as opposed to a variable). If the memory</span>
<span class="sd">  for the existing tensor cannot be re-used, a copy is made and updated.</span>

<span class="sd">  `indices` is an integer tensor containing indices into a new tensor of shape</span>
<span class="sd">  `shape`.  The last dimension of `indices` can be at most the rank of `shape`:</span>

<span class="sd">      indices.shape[-1] &lt;= shape.rank</span>

<span class="sd">  The last dimension of `indices` corresponds to indices into elements</span>
<span class="sd">  (if `indices.shape[-1] = shape.rank`) or slices</span>
<span class="sd">  (if `indices.shape[-1] &lt; shape.rank`) along dimension `indices.shape[-1]` of</span>
<span class="sd">  `shape`.  `updates` is a tensor with shape</span>

<span class="sd">      indices.shape[:-1] + shape[indices.shape[-1]:]</span>

<span class="sd">  The simplest form of tensor_scatter_add is to add individual elements to a</span>
<span class="sd">  tensor by index. For example, say we want to add 4 elements in a rank-1</span>
<span class="sd">  tensor with 8 elements.</span>

<span class="sd">  In Python, this scatter add operation would look like this:</span>

<span class="sd">  ```python</span>
<span class="sd">      indices = tf.constant([[4], [3], [1], [7]])</span>
<span class="sd">      updates = tf.constant([9, 10, 11, 12])</span>
<span class="sd">      tensor = tf.ones([8], dtype=tf.int32)</span>
<span class="sd">      updated = tf.tensor_scatter_nd_add(tensor, indices, updates)</span>
<span class="sd">      print(updated)</span>
<span class="sd">  ```</span>

<span class="sd">  The resulting tensor would look like this:</span>

<span class="sd">      [1, 12, 1, 11, 10, 1, 1, 13]</span>

<span class="sd">  We can also, insert entire slices of a higher rank tensor all at once. For</span>
<span class="sd">  example, if we wanted to insert two slices in the first dimension of a</span>
<span class="sd">  rank-3 tensor with two matrices of new values.</span>

<span class="sd">  In Python, this scatter add operation would look like this:</span>

<span class="sd">  ```python</span>
<span class="sd">      indices = tf.constant([[0], [2]])</span>
<span class="sd">      updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],</span>
<span class="sd">                              [7, 7, 7, 7], [8, 8, 8, 8]],</span>
<span class="sd">                             [[5, 5, 5, 5], [6, 6, 6, 6],</span>
<span class="sd">                              [7, 7, 7, 7], [8, 8, 8, 8]]])</span>
<span class="sd">      tensor = tf.ones([4, 4, 4],dtype=tf.int32)</span>
<span class="sd">      updated = tf.tensor_scatter_nd_add(tensor, indices, updates)</span>
<span class="sd">      print(updated)</span>
<span class="sd">  ```</span>

<span class="sd">  The resulting tensor would look like this:</span>

<span class="sd">      [[[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],</span>
<span class="sd">       [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],</span>
<span class="sd">       [[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],</span>
<span class="sd">       [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]</span>

<span class="sd">  Note that on CPU, if an out of bound index is found, an error is returned.</span>
<span class="sd">  On GPU, if an out of bound index is found, the index is ignored.</span>

<span class="sd">  Args:</span>
<span class="sd">    tensor: A `Tensor`. Tensor to copy/update.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      Index tensor.</span>
<span class="sd">    updates: A `Tensor`. Must have the same type as `tensor`.</span>
<span class="sd">      Updates to scatter into output.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;TensorScatterAdd&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensor_scatter_add_eager_fallback</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">tensor_scatter_add</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                                  <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;TensorScatterAdd&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span>
                            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">tensor_scatter_add</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span>
                              <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TensorScatterAdd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">TensorScatterAdd</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.TensorScatterAdd&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">tensor_scatter_add</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">tensor_scatter_add_eager_fallback</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">tensor</span><span class="p">,</span> <span class="n">updates</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;TensorScatterAdd&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TensorScatterAdd&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;tensor_scatter_nd_sub&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tensor_scatter_nd_sub&#39;</span><span class="p">,</span> <span class="s1">&#39;tensor_scatter_sub&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;tensor_scatter_sub&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">tensor_scatter_sub</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Subtracts sparse `updates` from an existing tensor according to `indices`.</span>

<span class="sd">  This operation creates a new tensor by subtracting sparse `updates` from the</span>
<span class="sd">  passed in `tensor`.</span>
<span class="sd">  This operation is very similar to `tf.scatter_nd_sub`, except that the updates</span>
<span class="sd">  are subtracted from an existing tensor (as opposed to a variable). If the memory</span>
<span class="sd">  for the existing tensor cannot be re-used, a copy is made and updated.</span>

<span class="sd">  `indices` is an integer tensor containing indices into a new tensor of shape</span>
<span class="sd">  `shape`.  The last dimension of `indices` can be at most the rank of `shape`:</span>

<span class="sd">      indices.shape[-1] &lt;= shape.rank</span>

<span class="sd">  The last dimension of `indices` corresponds to indices into elements</span>
<span class="sd">  (if `indices.shape[-1] = shape.rank`) or slices</span>
<span class="sd">  (if `indices.shape[-1] &lt; shape.rank`) along dimension `indices.shape[-1]` of</span>
<span class="sd">  `shape`.  `updates` is a tensor with shape</span>

<span class="sd">      indices.shape[:-1] + shape[indices.shape[-1]:]</span>

<span class="sd">  The simplest form of tensor_scatter_sub is to subtract individual elements</span>
<span class="sd">  from a tensor by index. For example, say we want to insert 4 scattered elements</span>
<span class="sd">  in a rank-1 tensor with 8 elements.</span>

<span class="sd">  In Python, this scatter subtract operation would look like this:</span>

<span class="sd">  ```python</span>
<span class="sd">      indices = tf.constant([[4], [3], [1], [7]])</span>
<span class="sd">      updates = tf.constant([9, 10, 11, 12])</span>
<span class="sd">      tensor = tf.ones([8], dtype=tf.int32)</span>
<span class="sd">      updated = tf.tensor_scatter_nd_sub(tensor, indices, updates)</span>
<span class="sd">      print(updated)</span>
<span class="sd">  ```</span>

<span class="sd">  The resulting tensor would look like this:</span>

<span class="sd">      [1, -10, 1, -9, -8, 1, 1, -11]</span>

<span class="sd">  We can also, insert entire slices of a higher rank tensor all at once. For</span>
<span class="sd">  example, if we wanted to insert two slices in the first dimension of a</span>
<span class="sd">  rank-3 tensor with two matrices of new values.</span>

<span class="sd">  In Python, this scatter add operation would look like this:</span>

<span class="sd">  ```python</span>
<span class="sd">      indices = tf.constant([[0], [2]])</span>
<span class="sd">      updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],</span>
<span class="sd">                              [7, 7, 7, 7], [8, 8, 8, 8]],</span>
<span class="sd">                             [[5, 5, 5, 5], [6, 6, 6, 6],</span>
<span class="sd">                              [7, 7, 7, 7], [8, 8, 8, 8]]])</span>
<span class="sd">      tensor = tf.ones([4, 4, 4],dtype=tf.int32)</span>
<span class="sd">      updated = tf.tensor_scatter_nd_sub(tensor, indices, updates)</span>
<span class="sd">      print(updated)</span>
<span class="sd">  ```</span>

<span class="sd">  The resulting tensor would look like this:</span>

<span class="sd">      [[[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],</span>
<span class="sd">       [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],</span>
<span class="sd">       [[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],</span>
<span class="sd">       [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]</span>

<span class="sd">  Note that on CPU, if an out of bound index is found, an error is returned.</span>
<span class="sd">  On GPU, if an out of bound index is found, the index is ignored.</span>

<span class="sd">  Args:</span>
<span class="sd">    tensor: A `Tensor`. Tensor to copy/update.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      Index tensor.</span>
<span class="sd">    updates: A `Tensor`. Must have the same type as `tensor`.</span>
<span class="sd">      Updates to scatter into output.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;TensorScatterSub&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensor_scatter_sub_eager_fallback</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">tensor_scatter_sub</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                                  <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;TensorScatterSub&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span>
                            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">tensor_scatter_sub</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span>
                              <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TensorScatterSub&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">TensorScatterSub</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.TensorScatterSub&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">tensor_scatter_sub</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">tensor_scatter_sub_eager_fallback</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">tensor</span><span class="p">,</span> <span class="n">updates</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;TensorScatterSub&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TensorScatterSub&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;tensor_scatter_nd_update&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tensor_scatter_nd_update&#39;</span><span class="p">,</span> <span class="s1">&#39;tensor_scatter_update&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;tensor_scatter_update&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">tensor_scatter_update</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Scatter `updates` into an existing tensor according to `indices`.</span>

<span class="sd">  This operation creates a new tensor by applying sparse `updates` to the passed</span>
<span class="sd">  in `tensor`.</span>
<span class="sd">  This operation is very similar to `tf.scatter_nd`, except that the updates are</span>
<span class="sd">  scattered onto an existing tensor (as opposed to a zero-tensor). If the memory</span>
<span class="sd">  for the existing tensor cannot be re-used, a copy is made and updated.</span>

<span class="sd">  If `indices` contains duplicates, then their updates are accumulated (summed).</span>

<span class="sd">  **WARNING**: The order in which updates are applied is nondeterministic, so the</span>
<span class="sd">  output will be nondeterministic if `indices` contains duplicates -- because</span>
<span class="sd">  of some numerical approximation issues, numbers summed in different order</span>
<span class="sd">  may yield different results.</span>

<span class="sd">  `indices` is an integer tensor containing indices into a new tensor of shape</span>
<span class="sd">  `shape`.  The last dimension of `indices` can be at most the rank of `shape`:</span>

<span class="sd">      indices.shape[-1] &lt;= shape.rank</span>

<span class="sd">  The last dimension of `indices` corresponds to indices into elements</span>
<span class="sd">  (if `indices.shape[-1] = shape.rank`) or slices</span>
<span class="sd">  (if `indices.shape[-1] &lt; shape.rank`) along dimension `indices.shape[-1]` of</span>
<span class="sd">  `shape`.  `updates` is a tensor with shape</span>

<span class="sd">      indices.shape[:-1] + shape[indices.shape[-1]:]</span>

<span class="sd">  The simplest form of scatter is to insert individual elements in a tensor by</span>
<span class="sd">  index. For example, say we want to insert 4 scattered elements in a rank-1</span>
<span class="sd">  tensor with 8 elements.</span>

<span class="sd">  &lt;div style=&quot;width:70%; margin:auto; margin-bottom:10px; margin-top:20px;&quot;&gt;</span>
<span class="sd">  &lt;img style=&quot;width:100%&quot; src=&quot;https://www.tensorflow.org/images/ScatterNd1.png&quot; alt&gt;</span>
<span class="sd">  &lt;/div&gt;</span>

<span class="sd">  In Python, this scatter operation would look like this:</span>

<span class="sd">      &gt;&gt;&gt; indices = tf.constant([[4], [3], [1], [7]])</span>
<span class="sd">      &gt;&gt;&gt; updates = tf.constant([9, 10, 11, 12])</span>
<span class="sd">      &gt;&gt;&gt; tensor = tf.ones([8], dtype=tf.int32)</span>
<span class="sd">      &gt;&gt;&gt; print(tf.tensor_scatter_nd_update(tensor, indices, updates))</span>
<span class="sd">      tf.Tensor([ 1 11  1 10  9  1  1 12], shape=(8,), dtype=int32)</span>

<span class="sd">  We can also, insert entire slices of a higher rank tensor all at once. For</span>
<span class="sd">  example, if we wanted to insert two slices in the first dimension of a</span>
<span class="sd">  rank-3 tensor with two matrices of new values.</span>

<span class="sd">  In Python, this scatter operation would look like this:</span>

<span class="sd">      &gt;&gt;&gt; indices = tf.constant([[0], [2]])</span>
<span class="sd">      &gt;&gt;&gt; updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],</span>
<span class="sd">      ...                         [7, 7, 7, 7], [8, 8, 8, 8]],</span>
<span class="sd">      ...                        [[5, 5, 5, 5], [6, 6, 6, 6],</span>
<span class="sd">      ...                         [7, 7, 7, 7], [8, 8, 8, 8]]])</span>
<span class="sd">      &gt;&gt;&gt; tensor = tf.ones([4, 4, 4], dtype=tf.int32)</span>
<span class="sd">      &gt;&gt;&gt; print(tf.tensor_scatter_nd_update(tensor, indices, updates).numpy())</span>
<span class="sd">      [[[5 5 5 5]</span>
<span class="sd">        [6 6 6 6]</span>
<span class="sd">        [7 7 7 7]</span>
<span class="sd">        [8 8 8 8]]</span>
<span class="sd">       [[1 1 1 1]</span>
<span class="sd">        [1 1 1 1]</span>
<span class="sd">        [1 1 1 1]</span>
<span class="sd">        [1 1 1 1]]</span>
<span class="sd">       [[5 5 5 5]</span>
<span class="sd">        [6 6 6 6]</span>
<span class="sd">        [7 7 7 7]</span>
<span class="sd">        [8 8 8 8]]</span>
<span class="sd">       [[1 1 1 1]</span>
<span class="sd">        [1 1 1 1]</span>
<span class="sd">        [1 1 1 1]</span>
<span class="sd">        [1 1 1 1]]]</span>

<span class="sd">  Note that on CPU, if an out of bound index is found, an error is returned.</span>
<span class="sd">  On GPU, if an out of bound index is found, the index is ignored.</span>

<span class="sd">  Args:</span>
<span class="sd">    tensor: A `Tensor`. Tensor to copy/update.</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      Index tensor.</span>
<span class="sd">    updates: A `Tensor`. Must have the same type as `tensor`.</span>
<span class="sd">      Updates to scatter into output.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `tensor`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;TensorScatterUpdate&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensor_scatter_update_eager_fallback</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">tensor_scatter_update</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                                     <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;TensorScatterUpdate&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                               <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">tensor_scatter_update</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                                 <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tindices&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TensorScatterUpdate&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">TensorScatterUpdate</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.TensorScatterUpdate&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">tensor_scatter_update</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">tensor_scatter_update_eager_fallback</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">tensor</span><span class="p">,</span> <span class="n">updates</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_attr_Tindices</span><span class="p">,</span> <span class="p">(</span><span class="n">indices</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">updates</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tindices&quot;</span><span class="p">,</span> <span class="n">_attr_Tindices</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;TensorScatterUpdate&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TensorScatterUpdate&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">tensor_strided_slice_update</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">begin_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">new_axis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Assign `value` to the sliced l-value reference of `input`.</span>

<span class="sd">  The values of `value` are assigned to the positions in the tensor `input` that</span>
<span class="sd">  are selected by the slice parameters. The slice parameters `begin` `end`</span>
<span class="sd">  `strides` etc. work exactly as in `StridedSlice`.</span>

<span class="sd">  NOTE this op currently does not support broadcasting and so `value`&#39;s shape</span>
<span class="sd">  must be exactly the shape produced by the slice of `input`.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    begin: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    end: A `Tensor`. Must have the same type as `begin`.</span>
<span class="sd">    strides: A `Tensor`. Must have the same type as `begin`.</span>
<span class="sd">    value: A `Tensor`. Must have the same type as `input`.</span>
<span class="sd">    begin_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    end_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    ellipsis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    new_axis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    shrink_axis_mask: An optional `int`. Defaults to `0`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;TensorStridedSliceUpdate&quot;</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span>
        <span class="s2">&quot;begin_mask&quot;</span><span class="p">,</span> <span class="n">begin_mask</span><span class="p">,</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">,</span> <span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">,</span>
        <span class="n">ellipsis_mask</span><span class="p">,</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">,</span> <span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">,</span>
        <span class="n">shrink_axis_mask</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensor_strided_slice_update_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">begin_mask</span><span class="o">=</span><span class="n">begin_mask</span><span class="p">,</span>
            <span class="n">end_mask</span><span class="o">=</span><span class="n">end_mask</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="o">=</span><span class="n">ellipsis_mask</span><span class="p">,</span>
            <span class="n">new_axis_mask</span><span class="o">=</span><span class="n">new_axis_mask</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="o">=</span><span class="n">shrink_axis_mask</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">begin_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">begin_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">begin_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">begin_mask</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">end_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">end_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">end_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ellipsis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">ellipsis_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">new_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">shrink_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;TensorStridedSliceUpdate&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="o">=</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">end</span><span class="p">,</span>
                                    <span class="n">strides</span><span class="o">=</span><span class="n">strides</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span>
                                    <span class="n">begin_mask</span><span class="o">=</span><span class="n">begin_mask</span><span class="p">,</span> <span class="n">end_mask</span><span class="o">=</span><span class="n">end_mask</span><span class="p">,</span>
                                    <span class="n">ellipsis_mask</span><span class="o">=</span><span class="n">ellipsis_mask</span><span class="p">,</span>
                                    <span class="n">new_axis_mask</span><span class="o">=</span><span class="n">new_axis_mask</span><span class="p">,</span>
                                    <span class="n">shrink_axis_mask</span><span class="o">=</span><span class="n">shrink_axis_mask</span><span class="p">,</span>
                                    <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Index&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Index&quot;</span><span class="p">),</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;begin_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;end_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;new_axis_mask&quot;</span><span class="p">),</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TensorStridedSliceUpdate&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">TensorStridedSliceUpdate</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.TensorStridedSliceUpdate&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">tensor_strided_slice_update</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">tensor_strided_slice_update_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">begin_mask</span><span class="p">,</span> <span class="n">end_mask</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="p">,</span> <span class="n">new_axis_mask</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">begin_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">begin_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">begin_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">begin_mask</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">end_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">end_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">end_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;end_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ellipsis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">ellipsis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">ellipsis_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">new_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">new_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">shrink_axis_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">shrink_axis_mask</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">shrink_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">,</span> <span class="n">value</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_attr_Index</span><span class="p">,</span> <span class="n">_inputs_Index</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_Index</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">begin</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">value</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Index&quot;</span><span class="p">,</span> <span class="n">_attr_Index</span><span class="p">,</span> <span class="s2">&quot;begin_mask&quot;</span><span class="p">,</span> <span class="n">begin_mask</span><span class="p">,</span>
  <span class="s2">&quot;end_mask&quot;</span><span class="p">,</span> <span class="n">end_mask</span><span class="p">,</span> <span class="s2">&quot;ellipsis_mask&quot;</span><span class="p">,</span> <span class="n">ellipsis_mask</span><span class="p">,</span> <span class="s2">&quot;new_axis_mask&quot;</span><span class="p">,</span>
  <span class="n">new_axis_mask</span><span class="p">,</span> <span class="s2">&quot;shrink_axis_mask&quot;</span><span class="p">,</span> <span class="n">shrink_axis_mask</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;TensorStridedSliceUpdate&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                             <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TensorStridedSliceUpdate&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="tile"><a class="viewcode-back" href="../../../../index.html#tensorflow.tile">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;tile&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tile&#39;</span><span class="p">,</span> <span class="s1">&#39;manip.tile&#39;</span><span class="p">])</span>
<span class="nd">@deprecated_endpoints</span><span class="p">(</span><span class="s1">&#39;manip.tile&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">tile</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Constructs a tensor by tiling a given tensor.</span>

<span class="sd">  This operation creates a new tensor by replicating `input` `multiples` times.</span>
<span class="sd">  The output tensor&#39;s i&#39;th dimension has `input.dims(i) * multiples[i]` elements,</span>
<span class="sd">  and the values of `input` are replicated `multiples[i]` times along the &#39;i&#39;th</span>
<span class="sd">  dimension. For example, tiling `[a b c d]` by `[2]` produces</span>
<span class="sd">  `[a b c d a b c d]`.</span>

<span class="sd">  &gt;&gt;&gt; a = tf.constant([[1,2,3],[4,5,6]], tf.int32)</span>
<span class="sd">  &gt;&gt;&gt; b = tf.constant([1,2], tf.int32)</span>
<span class="sd">  &gt;&gt;&gt; tf.tile(a, b)</span>
<span class="sd">  &lt;tf.Tensor: shape=(2, 6), dtype=int32, numpy=</span>
<span class="sd">  array([[1, 2, 3, 1, 2, 3],</span>
<span class="sd">         [4, 5, 6, 4, 5, 6]], dtype=int32)&gt;</span>
<span class="sd">  &gt;&gt;&gt; c = tf.constant([2,1], tf.int32)</span>
<span class="sd">  &gt;&gt;&gt; tf.tile(a, c)</span>
<span class="sd">  &lt;tf.Tensor: shape=(4, 3), dtype=int32, numpy=</span>
<span class="sd">  array([[1, 2, 3],</span>
<span class="sd">         [4, 5, 6],</span>
<span class="sd">         [1, 2, 3],</span>
<span class="sd">         [4, 5, 6]], dtype=int32)&gt;</span>
<span class="sd">  &gt;&gt;&gt; d = tf.constant([2,2], tf.int32)</span>
<span class="sd">  &gt;&gt;&gt; tf.tile(a, d)</span>
<span class="sd">  &lt;tf.Tensor: shape=(4, 6), dtype=int32, numpy=</span>
<span class="sd">  array([[1, 2, 3, 1, 2, 3],</span>
<span class="sd">         [4, 5, 6, 4, 5, 6],</span>
<span class="sd">         [1, 2, 3, 1, 2, 3],</span>
<span class="sd">         [4, 5, 6, 4, 5, 6]], dtype=int32)&gt;</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`. 1-D or higher.</span>
<span class="sd">    multiples: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      1-D. Length must be the same as the number of dimensions in `input`</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Tile&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span>
        <span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tile_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">tile</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="o">=</span><span class="n">multiples</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Tile&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="o">=</span><span class="n">multiples</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">tile</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="o">=</span><span class="n">multiples</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tmultiples&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tmultiples&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Tile&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">Tile</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Tile&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">tile</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">tile_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tmultiples</span><span class="p">,</span> <span class="p">(</span><span class="n">multiples</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">multiples</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tmultiples&quot;</span><span class="p">,</span> <span class="n">_attr_Tmultiples</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Tile&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Tile&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">tile_grad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the gradient of `Tile`.</span>

<span class="sd">  Since `Tile` takes an input and repeats the input `multiples` times</span>
<span class="sd">  along each dimension, `TileGrad` takes in `multiples` and aggregates</span>
<span class="sd">  each repeated tile of `input` into `output`.</span>

<span class="sd">  Args:</span>
<span class="sd">    input: A `Tensor`.</span>
<span class="sd">    multiples: A `Tensor` of type `int32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `input`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;TileGrad&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tile_grad_eager_fallback</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;TileGrad&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="o">=</span><span class="n">multiples</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TileGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">TileGrad</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.TileGrad&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">tile_grad</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">tile_grad_eager_fallback</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">multiples</span> <span class="o">=</span> <span class="n">_ops</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">multiples</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;TileGrad&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;TileGrad&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Shuffle dimensions of x according to a permutation.</span>

<span class="sd">  The output `y` has the same rank as `x`. The shapes of `x` and `y` satisfy:</span>
<span class="sd">    `y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]`</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`.</span>
<span class="sd">    perm: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Transpose&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">transpose_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Transpose&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Tperm&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tperm&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Transpose&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Transpose</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Transpose&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">transpose</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">transpose_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Tperm</span><span class="p">,</span> <span class="p">(</span><span class="n">perm</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">perm</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Tperm&quot;</span><span class="p">,</span> <span class="n">_attr_Tperm</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Transpose&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Transpose&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_UniqueOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;Unique&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="s2">&quot;idx&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">unique</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Finds unique elements in a 1-D tensor.</span>

<span class="sd">  This operation returns a tensor `y` containing all of the unique elements of `x`</span>
<span class="sd">  sorted in the same order that they occur in `x`; `x` does not need to be sorted.</span>
<span class="sd">  This operation also returns a tensor `idx` the same size as `x` that contains</span>
<span class="sd">  the index of each value of `x` in the unique output `y`. In other words:</span>

<span class="sd">  `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`</span>

<span class="sd">  Examples:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;x&#39; is [1, 1, 2, 4, 4, 4, 7, 8, 8]</span>
<span class="sd">  y, idx = unique(x)</span>
<span class="sd">  y ==&gt; [1, 2, 4, 7, 8]</span>
<span class="sd">  idx ==&gt; [0, 0, 1, 2, 2, 2, 3, 4, 4]</span>
<span class="sd">  ```</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;x&#39; is [4, 5, 1, 2, 3, 3, 4, 5]</span>
<span class="sd">  y, idx = unique(x)</span>
<span class="sd">  y ==&gt; [4, 5, 1, 2, 3]</span>
<span class="sd">  idx ==&gt; [0, 1, 2, 3, 4, 4, 0, 1]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. 1-D.</span>
<span class="sd">    out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (y, idx).</span>

<span class="sd">    y: A `Tensor`. Has the same type as `x`.</span>
<span class="sd">    idx: A `Tensor` of type `out_idx`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Unique&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_UniqueOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">unique_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">out_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_idx</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Unique&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;out_idx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Unique&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_UniqueOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Unique</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Unique&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">unique</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">unique_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">out_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_idx</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Unique&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Unique&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_UniqueOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_UniqueV2Output</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;UniqueV2&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="s2">&quot;idx&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">unique_v2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Finds unique elements along an axis of a tensor.</span>

<span class="sd">  This operation either returns a tensor `y` containing unique elements</span>
<span class="sd">  along the `axis` of a tensor. The returned unique elements is sorted</span>
<span class="sd">  in the same order as they occur along `axis` in `x`.</span>
<span class="sd">  This operation also returns a tensor `idx` that is the same size as</span>
<span class="sd">  the number of the elements in `x` along the `axis` dimension. It</span>
<span class="sd">  contains the index in the unique output `y`.</span>
<span class="sd">  In other words, for an `1-D` tensor `x` with `axis = None:</span>

<span class="sd">  `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;x&#39; is [1, 1, 2, 4, 4, 4, 7, 8, 8]</span>
<span class="sd">  y, idx = unique(x)</span>
<span class="sd">  y ==&gt; [1, 2, 4, 7, 8]</span>
<span class="sd">  idx ==&gt; [0, 0, 1, 2, 2, 2, 3, 4, 4]</span>
<span class="sd">  ```</span>

<span class="sd">  For an `2-D` tensor `x` with `axis = 0`:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;x&#39; is [[1, 0, 0],</span>
<span class="sd">  #                [1, 0, 0],</span>
<span class="sd">  #                [2, 0, 0]]</span>
<span class="sd">  y, idx = unique(x, axis=0)</span>
<span class="sd">  y ==&gt; [[1, 0, 0],</span>
<span class="sd">         [2, 0, 0]]</span>
<span class="sd">  idx ==&gt; [0, 0, 1]</span>
<span class="sd">  ```</span>

<span class="sd">  For an `2-D` tensor `x` with `axis = 1`:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;x&#39; is [[1, 0, 0],</span>
<span class="sd">  #                [1, 0, 0],</span>
<span class="sd">  #                [2, 0, 0]]</span>
<span class="sd">  y, idx = unique(x, axis=1)</span>
<span class="sd">  y ==&gt; [[1, 0],</span>
<span class="sd">         [1, 0],</span>
<span class="sd">         [2, 0]]</span>
<span class="sd">  idx ==&gt; [0, 1, 1]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. A `Tensor`.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A `Tensor` of type `int32` (default: None). The axis of the Tensor to</span>
<span class="sd">      find the unique elements.</span>
<span class="sd">    out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (y, idx).</span>

<span class="sd">    y: A `Tensor`. Has the same type as `x`.</span>
<span class="sd">    idx: A `Tensor` of type `out_idx`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;UniqueV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_UniqueV2Output</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">unique_v2_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">out_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_idx</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;UniqueV2&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Taxis&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Taxis&quot;</span><span class="p">),</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;out_idx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UniqueV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_UniqueV2Output</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">UniqueV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.UniqueV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">unique_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">unique_v2_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">out_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_idx</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Taxis</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Taxis&quot;</span><span class="p">,</span> <span class="n">_attr_Taxis</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;UniqueV2&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UniqueV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_UniqueV2Output</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_UniqueWithCountsOutput</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;UniqueWithCounts&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="s2">&quot;idx&quot;</span><span class="p">,</span> <span class="s2">&quot;count&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">unique_with_counts</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Finds unique elements in a 1-D tensor.</span>

<span class="sd">  This operation returns a tensor `y` containing all of the unique elements of `x`</span>
<span class="sd">  sorted in the same order that they occur in `x`. This operation also returns a</span>
<span class="sd">  tensor `idx` the same size as `x` that contains the index of each value of `x`</span>
<span class="sd">  in the unique output `y`. Finally, it returns a third tensor `count` that</span>
<span class="sd">  contains the count of each element of `y` in `x`. In other words:</span>

<span class="sd">  `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;x&#39; is [1, 1, 2, 4, 4, 4, 7, 8, 8]</span>
<span class="sd">  y, idx, count = unique_with_counts(x)</span>
<span class="sd">  y ==&gt; [1, 2, 4, 7, 8]</span>
<span class="sd">  idx ==&gt; [0, 0, 1, 2, 2, 2, 3, 4, 4]</span>
<span class="sd">  count ==&gt; [2, 1, 3, 1, 2]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. 1-D.</span>
<span class="sd">    out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (y, idx, count).</span>

<span class="sd">    y: A `Tensor`. Has the same type as `x`.</span>
<span class="sd">    idx: A `Tensor` of type `out_idx`.</span>
<span class="sd">    count: A `Tensor` of type `out_idx`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;UniqueWithCounts&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_UniqueWithCountsOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">unique_with_counts_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">out_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_idx</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;UniqueWithCounts&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;out_idx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UniqueWithCounts&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_UniqueWithCountsOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">UniqueWithCounts</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.UniqueWithCounts&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">unique_with_counts</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">unique_with_counts_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">out_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_idx</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;UniqueWithCounts&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UniqueWithCounts&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_UniqueWithCountsOutput</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">_UniqueWithCountsV2Output</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;UniqueWithCountsV2&quot;</span><span class="p">,</span>
    <span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="s2">&quot;idx&quot;</span><span class="p">,</span> <span class="s2">&quot;count&quot;</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">unique_with_counts_v2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Finds unique elements along an axis of a tensor.</span>

<span class="sd">  This operation either returns a tensor `y` containing unique elements</span>
<span class="sd">  along the `axis` of a tensor. The returned unique elements is sorted</span>
<span class="sd">  in the same order as they occur along `axis` in `x`.</span>
<span class="sd">  This operation also returns a tensor `idx` and a tensor `count`</span>
<span class="sd">  that are the same size as the number of the elements in `x` along the</span>
<span class="sd">  `axis` dimension. The `idx` contains the index in the unique output `y`</span>
<span class="sd">  and the `count` contains the count in the unique output `y`.</span>
<span class="sd">  In other words, for an `1-D` tensor `x` with `axis = None:</span>

<span class="sd">  `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;x&#39; is [1, 1, 2, 4, 4, 4, 7, 8, 8]</span>
<span class="sd">  y, idx, count = unique_with_counts(x)</span>
<span class="sd">  y ==&gt; [1, 2, 4, 7, 8]</span>
<span class="sd">  idx ==&gt; [0, 0, 1, 2, 2, 2, 3, 4, 4]</span>
<span class="sd">  count ==&gt; [2, 1, 3, 1, 2]</span>
<span class="sd">  ```</span>

<span class="sd">  For an `2-D` tensor `x` with `axis = 0`:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;x&#39; is [[1, 0, 0],</span>
<span class="sd">  #                [1, 0, 0],</span>
<span class="sd">  #                [2, 0, 0]]</span>
<span class="sd">  y, idx, count = unique_with_counts(x, axis=0)</span>
<span class="sd">  y ==&gt; [[1, 0, 0],</span>
<span class="sd">         [2, 0, 0]]</span>
<span class="sd">  idx ==&gt; [0, 0, 1]</span>
<span class="sd">  count ==&gt; [2, 1]</span>
<span class="sd">  ```</span>

<span class="sd">  For an `2-D` tensor `x` with `axis = 1`:</span>

<span class="sd">  ```</span>
<span class="sd">  # tensor &#39;x&#39; is [[1, 0, 0],</span>
<span class="sd">  #                [1, 0, 0],</span>
<span class="sd">  #                [2, 0, 0]]</span>
<span class="sd">  y, idx, count = unique_with_counts(x, axis=1)</span>
<span class="sd">  y ==&gt; [[1, 0],</span>
<span class="sd">         [1, 0],</span>
<span class="sd">         [2, 0]]</span>
<span class="sd">  idx ==&gt; [0, 1, 1]</span>
<span class="sd">  count ==&gt; [1, 2]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. A `Tensor`.</span>
<span class="sd">    axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      A `Tensor` of type `int32` (default: None). The axis of the Tensor to</span>
<span class="sd">      find the unique elements.</span>
<span class="sd">    out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of `Tensor` objects (y, idx, count).</span>

<span class="sd">    y: A `Tensor`. Has the same type as `x`.</span>
<span class="sd">    idx: A `Tensor` of type `out_idx`.</span>
<span class="sd">    count: A `Tensor` of type `out_idx`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;UniqueWithCountsV2&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">)</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">_UniqueWithCountsV2Output</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">unique_with_counts_v2_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">out_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_idx</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;UniqueWithCountsV2&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">out_idx</span><span class="o">=</span><span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;Taxis&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Taxis&quot;</span><span class="p">),</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;out_idx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UniqueWithCountsV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_UniqueWithCountsV2Output</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">UniqueWithCountsV2</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.UniqueWithCountsV2&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">unique_with_counts_v2</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">unique_with_counts_v2_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">out_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_idx</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_idx</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_attr_Taxis</span><span class="p">,</span> <span class="p">(</span><span class="n">axis</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">axis</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;Taxis&quot;</span><span class="p">,</span> <span class="n">_attr_Taxis</span><span class="p">,</span> <span class="s2">&quot;out_idx&quot;</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;UniqueWithCountsV2&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UniqueWithCountsV2&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_UniqueWithCountsV2Output</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">unpack</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Unpacks a given dimension of a rank-`R` tensor into `num` rank-`(R-1)` tensors.</span>

<span class="sd">  Unpacks `num` tensors from `value` by chipping it along the `axis` dimension.</span>
<span class="sd">  For example, given a tensor of shape `(A, B, C, D)`;</span>

<span class="sd">  If `axis == 0` then the i&#39;th tensor in `output` is the slice `value[i, :, :, :]`</span>
<span class="sd">    and each tensor in `output` will have shape `(B, C, D)`. (Note that the</span>
<span class="sd">    dimension unpacked along is gone, unlike `split`).</span>

<span class="sd">  If `axis == 1` then the i&#39;th tensor in `output` is the slice `value[:, i, :, :]`</span>
<span class="sd">    and each tensor in `output` will have shape `(A, C, D)`.</span>
<span class="sd">  Etc.</span>

<span class="sd">  This is the opposite of `pack`.</span>

<span class="sd">  Args:</span>
<span class="sd">    value: A `Tensor`.</span>
<span class="sd">      1-D or higher, with `axis` dimension size equal to `num`.</span>
<span class="sd">    num: An `int` that is `&gt;= 0`.</span>
<span class="sd">    axis: An optional `int`. Defaults to `0`.</span>
<span class="sd">      Dimension along which to unpack.  Negative values wrap around, so the</span>
<span class="sd">      valid range is `[-R, R)`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A list of `num` `Tensor` objects with the same type as `value`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Unpack&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="s2">&quot;num&quot;</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">unpack_eager_fallback</span><span class="p">(</span>
            <span class="n">value</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">num</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">num</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="s2">&quot;num&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Unpack&quot;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">num</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;num&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;num&quot;</span><span class="p">),</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span>
              <span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_int</span><span class="p">(</span><span class="s2">&quot;axis&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Unpack&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Unpack</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Unpack&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">unpack</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">unpack_eager_fallback</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">num</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="s2">&quot;num&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">axis</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_int</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">value</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">value</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">value</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;num&quot;</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;axis&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Unpack&quot;</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Unpack&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_result</span>


<div class="viewcode-block" id="unravel_index"><a class="viewcode-back" href="../../../../index.html#tensorflow.unravel_index">[docs]</a><span class="nd">@_dispatch</span><span class="o">.</span><span class="n">add_dispatch_list</span>
<span class="nd">@tf_export</span><span class="p">(</span><span class="s1">&#39;unravel_index&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">unravel_index</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Converts an array of flat indices into a tuple of coordinate arrays.</span>

<span class="sd">  </span>
<span class="sd">  Example:</span>

<span class="sd">  ```</span>
<span class="sd">  y = tf.unravel_index(indices=[2, 5, 7], dims=[3, 3])</span>
<span class="sd">  # &#39;dims&#39; represent a hypothetical (3, 3) tensor of indices:</span>
<span class="sd">  # [[0, 1, *2*],</span>
<span class="sd">  #  [3, 4, *5*],</span>
<span class="sd">  #  [6, *7*, 8]]</span>
<span class="sd">  # For each entry from &#39;indices&#39;, this operation returns</span>
<span class="sd">  # its coordinates (marked with &#39;*&#39;), such as</span>
<span class="sd">  # 2 ==&gt; (0, 2)</span>
<span class="sd">  # 5 ==&gt; (1, 2)</span>
<span class="sd">  # 7 ==&gt; (2, 1)</span>
<span class="sd">  y ==&gt; [[0, 1, 2], [2, 2, 1]]</span>
<span class="sd">  ```</span>

<span class="sd">  @compatibility(numpy)</span>
<span class="sd">  Equivalent to np.unravel_index</span>
<span class="sd">  @end_compatibility</span>

<span class="sd">  Args:</span>
<span class="sd">    indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.</span>
<span class="sd">      An 0-D or 1-D `int` Tensor whose elements are indices into the</span>
<span class="sd">      flattened version of an array of dimensions dims.</span>
<span class="sd">    dims: A `Tensor`. Must have the same type as `indices`.</span>
<span class="sd">      An 1-D `int` Tensor. The shape of the array to use for unraveling</span>
<span class="sd">      indices.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `indices`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;UnravelIndex&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">dims</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">unravel_index_eager_fallback</span><span class="p">(</span>
            <span class="n">indices</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
      <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
              <span class="n">unravel_index</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>
        <span class="k">raise</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;UnravelIndex&quot;</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
          <span class="n">unravel_index</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">_dispatch</span><span class="o">.</span><span class="n">OpDispatcher</span><span class="o">.</span><span class="n">NOT_SUPPORTED</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">result</span>
    <span class="k">raise</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UnravelIndex&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span></div>

<span class="n">UnravelIndex</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.UnravelIndex&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">unravel_index</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">unravel_index_eager_fallback</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_Tidx</span><span class="p">,</span> <span class="n">_inputs_Tidx</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">indices</span><span class="p">,</span> <span class="n">dims</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">dims</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_Tidx</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">indices</span><span class="p">,</span> <span class="n">dims</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Tidx&quot;</span><span class="p">,</span> <span class="n">_attr_Tidx</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;UnravelIndex&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UnravelIndex&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">upper_bound</span><span class="p">(</span><span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Applies upper_bound(sorted_search_values, values) along each row.</span>

<span class="sd">  Each set of rows with the same index in (sorted_inputs, values) is treated</span>
<span class="sd">  independently.  The resulting row is the equivalent of calling</span>
<span class="sd">  `np.searchsorted(sorted_inputs, values, side=&#39;right&#39;)`.</span>

<span class="sd">  The result is not a global index to the entire</span>
<span class="sd">  `Tensor`, but rather just the index in the last dimension.</span>

<span class="sd">  A 2-D example:</span>
<span class="sd">    sorted_sequence = [[0, 3, 9, 9, 10],</span>
<span class="sd">                       [1, 2, 3, 4, 5]]</span>
<span class="sd">    values = [[2, 4, 9],</span>
<span class="sd">              [0, 2, 6]]</span>

<span class="sd">    result = UpperBound(sorted_sequence, values)</span>

<span class="sd">    result == [[1, 2, 4],</span>
<span class="sd">               [0, 2, 5]]</span>

<span class="sd">  Args:</span>
<span class="sd">    sorted_inputs: A `Tensor`. 2-D Tensor where each row is ordered.</span>
<span class="sd">    values: A `Tensor`. Must have the same type as `sorted_inputs`.</span>
<span class="sd">      2-D Tensor with the same numbers of rows as `sorted_search_values`. Contains</span>
<span class="sd">      the values that will be searched for in `sorted_search_values`.</span>
<span class="sd">    out_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `out_type`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;UpperBound&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">upper_bound_eager_fallback</span><span class="p">(</span>
            <span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="k">if</span> <span class="n">out_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;UpperBound&quot;</span><span class="p">,</span> <span class="n">sorted_inputs</span><span class="o">=</span><span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">values</span><span class="p">,</span>
                      <span class="n">out_type</span><span class="o">=</span><span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">),</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span>
              <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;out_type&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UpperBound&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">UpperBound</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.UpperBound&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">upper_bound</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">upper_bound_eager_fallback</span><span class="p">(</span><span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">out_type</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">out_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">out_type</span> <span class="o">=</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">int32</span>
  <span class="n">out_type</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">make_type</span><span class="p">(</span><span class="n">out_type</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">)</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="n">_inputs_T</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="p">(</span><span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span> <span class="o">=</span> <span class="n">_inputs_T</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">sorted_inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">,</span> <span class="s2">&quot;out_type&quot;</span><span class="p">,</span> <span class="n">out_type</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;UpperBound&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;UpperBound&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">where</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns locations of nonzero / true values in a tensor.</span>

<span class="sd">  This operation returns the coordinates of true elements in `condition`. The</span>
<span class="sd">  coordinates are returned in a 2-D tensor where the first dimension (rows)</span>
<span class="sd">  represents the number of true elements, and the second dimension (columns)</span>
<span class="sd">  represents the coordinates of the true elements. Keep in mind, the shape of</span>
<span class="sd">  the output tensor can vary depending on how many true values there are in</span>
<span class="sd">  `condition`. Indices are output in row-major order.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```</span>
<span class="sd">  # &#39;input&#39; tensor is [[True, False]</span>
<span class="sd">  #                    [True, False]]</span>
<span class="sd">  # &#39;input&#39; has two true values, so output has two coordinates.</span>
<span class="sd">  # &#39;input&#39; has rank of 2, so coordinates have two indices.</span>
<span class="sd">  where(input) ==&gt; [[0, 0],</span>
<span class="sd">                    [1, 0]]</span>

<span class="sd">  # `condition` tensor is [[[True, False]</span>
<span class="sd">  #                     [True, False]]</span>
<span class="sd">  #                    [[False, True]</span>
<span class="sd">  #                     [False, True]]</span>
<span class="sd">  #                    [[False, False]</span>
<span class="sd">  #                     [False, True]]]</span>
<span class="sd">  # &#39;input&#39; has 5 true values, so output has 5 coordinates.</span>
<span class="sd">  # &#39;input&#39; has rank of 3, so coordinates have three indices.</span>
<span class="sd">  where(input) ==&gt; [[0, 0, 0],</span>
<span class="sd">                    [0, 1, 0],</span>
<span class="sd">                    [1, 0, 1],</span>
<span class="sd">                    [1, 1, 1],</span>
<span class="sd">                    [2, 1, 1]]</span>

<span class="sd">  # `condition` tensor is [[[1.5,  0.0]</span>
<span class="sd">  #                     [-0.5, 0.0]]</span>
<span class="sd">  #                    [[0.0,  0.25]</span>
<span class="sd">  #                     [0.0,  0.75]]</span>
<span class="sd">  #                    [[0.0,  0.0]</span>
<span class="sd">  #                     [0.0,  0.01]]]</span>
<span class="sd">  # &#39;input&#39; has 5 nonzero values, so output has 5 coordinates.</span>
<span class="sd">  # &#39;input&#39; has rank of 3, so coordinates have three indices.</span>
<span class="sd">  where(input) ==&gt; [[0, 0, 0],</span>
<span class="sd">                    [0, 1, 0],</span>
<span class="sd">                    [1, 0, 1],</span>
<span class="sd">                    [1, 1, 1],</span>
<span class="sd">                    [2, 1, 1]]</span>

<span class="sd">  # `condition` tensor is [[[1.5 + 0.0j, 0.0  + 0.0j]</span>
<span class="sd">  #                     [0.0 + 0.5j, 0.0  + 0.0j]]</span>
<span class="sd">  #                    [[0.0 + 0.0j, 0.25 + 1.5j]</span>
<span class="sd">  #                     [0.0 + 0.0j, 0.75 + 0.0j]]</span>
<span class="sd">  #                    [[0.0 + 0.0j, 0.0  + 0.0j]</span>
<span class="sd">  #                     [0.0 + 0.0j, 0.01 + 0.0j]]]</span>
<span class="sd">  # &#39;input&#39; has 5 nonzero magnitude values, so output has 5 coordinates.</span>
<span class="sd">  # &#39;input&#39; has rank of 3, so coordinates have three indices.</span>
<span class="sd">  where(input) ==&gt; [[0, 0, 0],</span>
<span class="sd">                    [0, 1, 0],</span>
<span class="sd">                    [1, 0, 1],</span>
<span class="sd">                    [1, 1, 1],</span>
<span class="sd">                    [2, 1, 1]]</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    condition: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`, `bool`.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor` of type `int64`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;Where&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">condition</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">where_eager_fallback</span><span class="p">(</span>
            <span class="n">condition</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;Where&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="n">condition</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Where&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">Where</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.Where&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">where</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">where_eager_fallback</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">condition</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">condition</span><span class="p">],</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">_dtypes</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">condition</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;Where&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span>
                             <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;Where&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>


<span class="k">def</span> <span class="nf">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns a tensor of zeros with the same shape and type as x.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A `Tensor`. a tensor of type T.</span>
<span class="sd">    name: A name for the operation (optional).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `Tensor`. Has the same type as `x`.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">_ctx</span> <span class="o">=</span> <span class="n">_context</span><span class="o">.</span><span class="n">_context</span> <span class="ow">or</span> <span class="n">_context</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
  <span class="n">tld</span> <span class="o">=</span> <span class="n">_ctx</span><span class="o">.</span><span class="n">_thread_local_data</span>
  <span class="k">if</span> <span class="n">tld</span><span class="o">.</span><span class="n">is_eager</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">_result</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_FastPathExecute</span><span class="p">(</span>
        <span class="n">_ctx</span><span class="o">.</span><span class="n">_context_handle</span><span class="p">,</span> <span class="n">tld</span><span class="o">.</span><span class="n">device_name</span><span class="p">,</span> <span class="s2">&quot;ZerosLike&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">.</span><span class="n">op_callbacks</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_result</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_FallbackException</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">zeros_like_eager_fallback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">_ctx</span><span class="p">)</span>
      <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_SymbolicException</span><span class="p">:</span>
        <span class="k">pass</span>  <span class="c1"># Add nodes to the TensorFlow graph.</span>
    <span class="k">except</span> <span class="n">_core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">_ops</span><span class="o">.</span><span class="n">raise_from_not_ok_status</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
  <span class="c1"># Add nodes to the TensorFlow graph.</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_op</span><span class="p">,</span> <span class="n">_outputs</span> <span class="o">=</span> <span class="n">_op_def_library</span><span class="o">.</span><span class="n">_apply_op_helper</span><span class="p">(</span>
        <span class="s2">&quot;ZerosLike&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_outputs</span><span class="p">[:]</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_op</span><span class="o">.</span><span class="n">_get_attr_type</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">))</span>
    <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="n">_op</span><span class="o">.</span><span class="n">inputs</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ZerosLike&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

<span class="n">ZerosLike</span> <span class="o">=</span> <span class="n">tf_export</span><span class="p">(</span><span class="s2">&quot;raw_ops.ZerosLike&quot;</span><span class="p">)(</span><span class="n">_ops</span><span class="o">.</span><span class="n">to_raw_op</span><span class="p">(</span><span class="n">zeros_like</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">zeros_like_eager_fallback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">):</span>
  <span class="n">_attr_T</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">args_to_matching_eager</span><span class="p">([</span><span class="n">x</span><span class="p">],</span> <span class="n">ctx</span><span class="p">)</span>
  <span class="n">_inputs_flat</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">_attrs</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">_attr_T</span><span class="p">)</span>
  <span class="n">_result</span> <span class="o">=</span> <span class="n">_execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="sa">b</span><span class="s2">&quot;ZerosLike&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">_inputs_flat</span><span class="p">,</span>
                             <span class="n">attrs</span><span class="o">=</span><span class="n">_attrs</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">ctx</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">_execute</span><span class="o">.</span><span class="n">must_record_gradient</span><span class="p">():</span>
    <span class="n">_execute</span><span class="o">.</span><span class="n">record_gradient</span><span class="p">(</span>
        <span class="s2">&quot;ZerosLike&quot;</span><span class="p">,</span> <span class="n">_inputs_flat</span><span class="p">,</span> <span class="n">_attrs</span><span class="p">,</span> <span class="n">_result</span><span class="p">)</span>
  <span class="n">_result</span><span class="p">,</span> <span class="o">=</span> <span class="n">_result</span>
  <span class="k">return</span> <span class="n">_result</span>

</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright - Wei MEI (Nick Cafferry).

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>
{"metadata": {"language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"name": "tensorflow-2.1.0", "display_name": "TensorFlow-2.1.0", "language": "python"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "import tensorflow as tf\nimport numpy as np\nfrom tensorflow.python.framework import ops\nops.reset_default_graph()\ntf.compat.v1.disable_eager_execution()\nsess = tf.compat.v1.Session()", "metadata": {}, "execution_count": 1, "outputs": [{"name": "stderr", "text": "/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "identiy_matrix = tf.compat.v1.diag([1.0, 1.0, 1.0])\nprint(sess.run(identiy_matrix))\nA = tf.compat.v1.truncated_normal([2,3])\nprint(sess.run(A))\nB = tf.fill([2,3],5.0)\nprint(sess.run(B))\nC = tf.compat.v1.random_uniform([3,2])\nprint(sess.run(C))\nD = tf.compat.v1.convert_to_tensor(np.array([[1.,2.,3.],[-3.,-7.,-1.],[0.,5.,-2.]]))\nprint(sess.run(D))", "metadata": {}, "execution_count": 2, "outputs": [{"name": "stdout", "text": "[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\n[[ 0.28321186  0.55567586  1.1733472 ]\n [-1.7252342  -0.12275252  1.0689898 ]]\n[[5. 5. 5.]\n [5. 5. 5.]]\n[[0.2804953  0.8541951 ]\n [0.80523515 0.53468   ]\n [0.11972344 0.9267837 ]]\n[[ 1.  2.  3.]\n [-3. -7. -1.]\n [ 0.  5. -2.]]\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "E = tf.zeros([2,3,3])\nprint(sess.run(E))", "metadata": {}, "execution_count": 3, "outputs": [{"name": "stdout", "text": "[[[0. 0. 0.]\n  [0. 0. 0.]\n  [0. 0. 0.]]\n\n [[0. 0. 0.]\n  [0. 0. 0.]\n  [0. 0. 0.]]]\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "print(sess.run(A+B))\nprint(sess.run(B-B))", "metadata": {}, "execution_count": 4, "outputs": [{"name": "stdout", "text": "[[5.5578065 4.384751  5.262491 ]\n [3.542943  6.457121  4.032861 ]]\n[[0. 0. 0.]\n [0. 0. 0.]]\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "print(sess.run(tf.matmul(B, identiy_matrix)))", "metadata": {}, "execution_count": 5, "outputs": [{"name": "stdout", "text": "[[5. 5. 5.]\n [5. 5. 5.]]\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "try:\n    print(sess.run(tf.matmul(A, B)))\nexcept:\n    print(\"ValueError: Dimensions must be equal\")", "metadata": {}, "execution_count": 6, "outputs": [{"name": "stdout", "text": "ValueError: Dimensions must be equal\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "help(tf.matmul);", "metadata": {}, "execution_count": 7, "outputs": [{"name": "stdout", "text": "Help on function matmul in module tensorflow.python.ops.math_ops:\n\nmatmul(a, b, transpose_a=False, transpose_b=False, adjoint_a=False, adjoint_b=False, a_is_sparse=False, b_is_sparse=False, name=None)\n    Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n    \n    The inputs must, following any transpositions, be tensors of rank >= 2\n    where the inner 2 dimensions specify valid matrix multiplication dimensions,\n    and any further outer dimensions specify matching batch size.\n    \n    Both matrices must be of the same type. The supported types are:\n    `float16`, `float32`, `float64`, `int32`, `complex64`, `complex128`.\n    \n    Either matrix can be transposed or adjointed (conjugated and transposed) on\n    the fly by setting one of the corresponding flag to `True`. These are `False`\n    by default.\n    \n    If one or both of the matrices contain a lot of zeros, a more efficient\n    multiplication algorithm can be used by setting the corresponding\n    `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n    This optimization is only available for plain matrices (rank-2 tensors) with\n    datatypes `bfloat16` or `float32`.\n    \n    A simple 2-D tensor matrix multiplication:\n    >>> a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n    >>> a  # 2-D tensor\n    <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n    array([[1, 2, 3],\n           [4, 5, 6]], dtype=int32)>\n    >>> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n    >>> b  # 2-D tensor\n    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n    array([[ 7,  8],\n           [ 9, 10],\n           [11, 12]], dtype=int32)>\n    >>> c = tf.matmul(a, b)\n    >>> c  # `a` * `b`\n    <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n    array([[ 58,  64],\n           [139, 154]], dtype=int32)>\n    \n    A batch matrix multiplication with batch shape [2]\n    >>> a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n    >>> a  # 3-D tensor\n    <tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n    array([[[ 1,  2,  3],\n            [ 4,  5,  6]],\n           [[ 7,  8,  9],\n            [10, 11, 12]]], dtype=int32)>\n    >>> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])\n    >>> b  # 3-D tensor\n    <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n    array([[[13, 14],\n            [15, 16],\n            [17, 18]],\n           [[19, 20],\n            [21, 22],\n            [23, 24]]], dtype=int32)>\n    >>> c = tf.matmul(a, b)\n    >>> c  # `a` * `b`\n    <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n    array([[[ 94, 100],\n            [229, 244]],\n           [[508, 532],\n            [697, 730]]], dtype=int32)>\n    \n    Since python >= 3.5 the @ operator is supported\n    (see [PEP 465](https://www.python.org/dev/peps/pep-0465/)). In TensorFlow,\n    it simply calls the `tf.matmul()` function, so the following lines are\n    equivalent:\n    >>> d = a @ b @ [[10], [11]]\n    >>> d = tf.matmul(tf.matmul(a, b), [[10], [11]])\n    \n    Args:\n      a: `tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,\n        `complex64`, `complex128` and rank > 1.\n      b: `tf.Tensor` with same type and rank as `a`.\n      transpose_a: If `True`, `a` is transposed before multiplication.\n      transpose_b: If `True`, `b` is transposed before multiplication.\n      adjoint_a: If `True`, `a` is conjugated and transposed before\n        multiplication.\n      adjoint_b: If `True`, `b` is conjugated and transposed before\n        multiplication.\n      a_is_sparse: If `True`, `a` is treated as a sparse matrix.\n      b_is_sparse: If `True`, `b` is treated as a sparse matrix.\n      name: Name for the operation (optional).\n    \n    Returns:\n      A `tf.Tensor` of the same type as `a` and `b` where each inner-most matrix\n      is the product of the corresponding matrices in `a` and `b`, e.g. if all\n      transpose or adjoint attributes are `False`:\n    \n      `output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])`,\n      for all indices `i`, `j`.\n    \n      Note: This is matrix product, not element-wise product.\n    \n    \n    Raises:\n      ValueError: If `transpose_a` and `adjoint_a`, or `transpose_b` and\n        `adjoint_b` are both set to `True`.\n\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "print(sess.run(tf.transpose(C)))", "metadata": {}, "execution_count": 8, "outputs": [{"name": "stdout", "text": "[[0.33106422 0.76668906 0.54454565]\n [0.2699653  0.35497868 0.5479125 ]]\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "print(sess.run(tf.compat.v1.matrix_determinant(D)))", "metadata": {}, "execution_count": 9, "outputs": [{"name": "stdout", "text": "-37.99999999999999\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "print(sess.run(tf.compat.v1.matrix_inverse(D)))", "metadata": {}, "execution_count": 10, "outputs": [{"name": "stdout", "text": "[[-0.5        -0.5        -0.5       ]\n [ 0.15789474  0.05263158  0.21052632]\n [ 0.39473684  0.13157895  0.02631579]]\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "print(sess.run(tf.compat.v1.self_adjoint_eig(D)[0]))", "metadata": {}, "execution_count": 11, "outputs": [{"name": "stdout", "text": "[-10.65907521  -0.22750691   2.88658212]\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "print(sess.run(tf.compat.v1.self_adjoint_eig(D)[1]))", "metadata": {}, "execution_count": 12, "outputs": [{"name": "stdout", "text": "[[ 0.21749542  0.63250104 -0.74339638]\n [ 0.84526515  0.2587998   0.46749277]\n [-0.4880805   0.73004459  0.47834331]]\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "print(sess.run(tf.compat.v1.cholesky(identiy_matrix)))", "metadata": {}, "execution_count": 17, "outputs": [{"name": "stdout", "text": "[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "eigenvalues, eigenvectors = sess.run(tf.compat.v1.self_adjoint_eig(D))", "metadata": {}, "execution_count": 18, "outputs": []}, {"cell_type": "code", "source": "eigenvalues", "metadata": {}, "execution_count": 19, "outputs": [{"execution_count": 19, "output_type": "execute_result", "data": {"text/plain": "array([-10.65907521,  -0.22750691,   2.88658212])"}, "metadata": {}}]}, {"cell_type": "code", "source": "eigenvectors", "metadata": {}, "execution_count": 20, "outputs": [{"execution_count": 20, "output_type": "execute_result", "data": {"text/plain": "array([[ 0.21749542,  0.63250104, -0.74339638],\n       [ 0.84526515,  0.2587998 ,  0.46749277],\n       [-0.4880805 ,  0.73004459,  0.47834331]])"}, "metadata": {}}]}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": []}]}